{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for running ERDiff alignment step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Source Domain: Training\n",
    "\n",
    "Code for training is `VAE_Diffusion_CoTrain.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from model_functions.Diffusion import *\n",
    "from model_functions.VAE import *\n",
    "from model_functions.ERDiff_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set loggers to save the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('train_logger')\n",
    "logger.setLevel(level=logging.INFO)\n",
    "handler = logging.FileHandler('train.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "# logger.addHandler(console)\n",
    "logger.info('python logging test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load source domain data\n",
    "\n",
    "- trial spikes: neural firing rates\n",
    "- trial vel: velocity\n",
    "- trial dir: labels of direction, 8 classes\n",
    "\n",
    "<img src=\"images/monkey_data.png\" width=\"15%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the trial length and number of neurons\n",
    "len_trial,num_neurons = 37, 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/Neural_Source.pkl', 'rb') as f:\n",
    "    train_data1 = pickle.load(f)['data']\n",
    "train_trial_spikes1, train_trial_vel1, train_trial_dir1 = train_data1['firing_rates'], train_data1['velocity'], train_data1['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 209 trials, for each trial, the time length to use is 37 (minimal trial length - 1), number of neurons is 187, dimension of velocity is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_trial_spikes1[i].shape[0] for i in range(len(train_trial_spikes1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 37, 187)\n",
      "(209, 37, 2)\n"
     ]
    }
   ],
   "source": [
    "start_pos = 1 \n",
    "end_pos = 1\n",
    "\n",
    "train_trial_spikes_tide1 = np.array([spike[start_pos:len_trial+start_pos, :num_neurons] for spike in train_trial_spikes1])\n",
    "print(np.shape(train_trial_spikes_tide1))\n",
    "\n",
    "train_trial_vel_tide1 = np.array([spike[start_pos:len_trial+start_pos, :] for spike in train_trial_vel1])\n",
    "print(np.shape(train_trial_vel_tide1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209,)\n"
     ]
    }
   ],
   "source": [
    "array_train_trial_dir1 = np.expand_dims(np.array((train_trial_dir1), dtype=object),1)\n",
    "\n",
    "train_trial_spikes_tide = train_trial_spikes_tide1\n",
    "train_trial_vel_tide = train_trial_vel_tide1\n",
    "train_trial_dic_tide = np.squeeze(np.vstack([array_train_trial_dir1]))\n",
    "print(np.shape(train_trial_dic_tide))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data preprocessing\n",
    "\n",
    "Apply gaussian smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431380/2824986634.py:5: DeprecationWarning: Importing gaussian from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.gaussian' or the convenience function 'scipy.signal.get_window' instead.\n",
      "  window = signal.gaussian(kern_sd, kern_sd, sym=True)\n"
     ]
    }
   ],
   "source": [
    "bin_width = float(0.02) * 1000\n",
    "\n",
    "kern_sd_ms = 100\n",
    "kern_sd = int(round(kern_sd_ms / bin_width))\n",
    "window = signal.gaussian(kern_sd, kern_sd, sym=True)\n",
    "window /= np.sum(window)\n",
    "filt = lambda x: np.convolve(x, window, 'same')\n",
    "\n",
    "train_trial_spikes_smoothed = np.apply_along_axis(filt, 1, train_trial_spikes_tide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 37, 187)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trial_spikes_smoothed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize before and after smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuron_id_list = [3, 99, 186]\n",
    "plt.figure(figsize=(20, 7))\n",
    "for i in range(len(neuron_id_list)):\n",
    "    neuron_id = neuron_id_list[i]\n",
    "    ax1 = plt.subplot(2, len(neuron_id_list), i+1)\n",
    "    ax1.plot(train_trial_spikes_tide[0, :, neuron_id])\n",
    "    ax1.set_title(\"Before smoothing, neuron id = \" + str(neuron_id))\n",
    "    ax2 = plt.subplot(2, len(neuron_id_list), i+len(neuron_id_list)+1)\n",
    "    ax2.plot(train_trial_spikes_smoothed[0, :, neuron_id])\n",
    "    ax2.set_title(\"After gaussian smoothing, neuron id = \" + str(neuron_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Randomly shuffle and split to train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_trial_spikes_tide.shape[0])\n",
    "np.random.seed(2023) \n",
    "np.random.shuffle(indices)\n",
    "train_len = round(len(indices) * 0.80)\n",
    "real_train_trial_spikes_smed, val_trial_spikes_smed = train_trial_spikes_smoothed[indices[:train_len]], train_trial_spikes_smoothed[indices[train_len:]]\n",
    "real_train_trial_vel_tide, val_trial_vel_tide = train_trial_vel_tide[indices[:train_len]], train_trial_vel_tide[indices[train_len:]]\n",
    "real_train_trial_dic_tide, val_trial_dic_tide = train_trial_dic_tide[indices[:train_len]], train_trial_dic_tide[indices[train_len:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches: 10\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1\n",
    "n_epochs = 500\n",
    "batch_size = 16\n",
    "ae_res_weight = 10\n",
    "kld_weight = 1\n",
    "n_batches = len(real_train_trial_spikes_smed)//batch_size\n",
    "print(\"number of batches:\", n_batches)\n",
    "\n",
    "mse_criterion = nn.MSELoss()\n",
    "poisson_criterion = nn.PoissonNLLLoss(log_input=False)\n",
    "\n",
    "l_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Build the model\n",
    "\n",
    "<img src=\"images/training.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, spike, emg):\n",
    "    re_sp_, vel_hat_,mu, log_var = model(spike, train_flag= True)\n",
    "    ae_loss = poisson_criterion(re_sp_, spike)\n",
    "    emg_loss = mse_criterion(vel_hat_, emg)\n",
    "    kld_loss = torch.mean(0.5 * (- log_var + mu ** 2 + log_var.exp() - 1))\n",
    "    total_loss = ae_res_weight * ae_loss + emg_loss + kld_weight * kld_loss\n",
    "    # total_loss = ae_res_weight * ae_loss \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "\n",
    "# define beta schedule\n",
    "betas = quadratic_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spikes = np.load(\"npy_files/train_latents.npy\")\n",
    "train_spike_data = np.expand_dims(train_spikes,1).astype(np.float32)\n",
    "train_spike_data = train_spike_data.transpose(0,1,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 1, 8, 37)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spike_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_trial_spikes_stand = (real_train_trial_spikes_smed)\n",
    "val_trial_spikes_stand = (val_trial_spikes_smed)\n",
    "\n",
    "spike_train = Variable(torch.from_numpy(real_train_trial_spikes_stand)).float()\n",
    "spike_val = Variable(torch.from_numpy(val_trial_spikes_stand)).float()\n",
    "\n",
    "emg_train = Variable(torch.from_numpy(real_train_trial_vel_tide)).float()\n",
    "emg_val = Variable(torch.from_numpy(val_trial_vel_tide)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 16\n",
    "dataloader = DataLoader(train_spike_data, batch_size=global_batch_size)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "dm_model = diff_STBlock(input_dim)\n",
    "dm_model.to(device)\n",
    "\n",
    "dm_optimizer = Adam(dm_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_loss = 1e10 # Save the loss\n",
    "\n",
    "pre_total_loss_ = 1e18\n",
    "last_improvement = 0\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431380/3446123673.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(n_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381b4c6d2e73415d9fadddc618b909be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0  Loss: 0.8132175207138062\n",
      "Step 1  Loss: 0.8100867867469788\n",
      "Step 2  Loss: 0.815028727054596\n",
      "Step 3  Loss: 0.7940422296524048\n",
      "Step 4  Loss: 0.8037274479866028\n",
      "Step 5  Loss: 0.7856090664863586\n",
      "Step 6  Loss: 0.7988925576210022\n",
      "Step 7  Loss: 0.759097158908844\n",
      "Step 8  Loss: 0.78489089012146\n",
      "Step 9  Loss: 0.7787379622459412\n",
      "Step 10  Loss: 0.7785270810127258\n",
      "total Loss of epoch  0  is  8.72185742855072\n",
      "Step 0  Loss: 0.7721797227859497\n",
      "Step 1  Loss: 0.7777519822120667\n",
      "Step 2  Loss: 0.7556346654891968\n",
      "Step 3  Loss: 0.7643831372261047\n",
      "Step 4  Loss: 0.7534956932067871\n",
      "Step 5  Loss: 0.7568359375\n",
      "Step 6  Loss: 0.6874943971633911\n",
      "Step 7  Loss: 0.7476314902305603\n",
      "Step 8  Loss: 0.750187337398529\n",
      "Step 9  Loss: 0.6666913628578186\n",
      "Step 10  Loss: 0.6706206798553467\n",
      "total Loss of epoch  1  is  8.10290640592575\n",
      "Step 0  Loss: 0.722862184047699\n",
      "Step 1  Loss: 0.6638414859771729\n",
      "Step 2  Loss: 0.6517336964607239\n",
      "Step 3  Loss: 0.6163535118103027\n",
      "Step 4  Loss: 0.640303373336792\n",
      "Step 5  Loss: 0.6266642212867737\n",
      "Step 6  Loss: 0.6678681969642639\n",
      "Step 7  Loss: 0.6049181222915649\n",
      "Step 8  Loss: 0.6292149424552917\n",
      "Step 9  Loss: 0.6248226761817932\n",
      "Step 10  Loss: 0.7344162464141846\n",
      "total Loss of epoch  2  is  7.1829986572265625\n",
      "Step 0  Loss: 0.5855158567428589\n",
      "Step 1  Loss: 0.5557811260223389\n",
      "Step 2  Loss: 0.5984665155410767\n",
      "Step 3  Loss: 0.5684541463851929\n",
      "Step 4  Loss: 0.6509855389595032\n",
      "Step 5  Loss: 0.6316131949424744\n",
      "Step 6  Loss: 0.5740971565246582\n",
      "Step 7  Loss: 0.508941113948822\n",
      "Step 8  Loss: 0.5564259886741638\n",
      "Step 9  Loss: 0.5295884609222412\n",
      "Step 10  Loss: 0.49420884251594543\n",
      "total Loss of epoch  3  is  6.2540779411792755\n",
      "Step 0  Loss: 0.6627985835075378\n",
      "Step 1  Loss: 0.5442561507225037\n",
      "Step 2  Loss: 0.5179654955863953\n",
      "Step 3  Loss: 0.5598078370094299\n",
      "Step 4  Loss: 0.520146906375885\n",
      "Step 5  Loss: 0.49900999665260315\n",
      "Step 6  Loss: 0.4576256275177002\n",
      "Step 7  Loss: 0.43096885085105896\n",
      "Step 8  Loss: 0.5451064109802246\n",
      "Step 9  Loss: 0.5211852192878723\n",
      "Step 10  Loss: 0.57140052318573\n",
      "total Loss of epoch  4  is  5.830271601676941\n",
      "Step 0  Loss: 0.47860151529312134\n",
      "Step 1  Loss: 0.5463253855705261\n",
      "Step 2  Loss: 0.4640824794769287\n",
      "Step 3  Loss: 0.4995194673538208\n",
      "Step 4  Loss: 0.46400555968284607\n",
      "Step 5  Loss: 0.48599934577941895\n",
      "Step 6  Loss: 0.48662811517715454\n",
      "Step 7  Loss: 0.49021804332733154\n",
      "Step 8  Loss: 0.4558158814907074\n",
      "Step 9  Loss: 0.5156055092811584\n",
      "Step 10  Loss: 0.512175440788269\n",
      "total Loss of epoch  5  is  5.398976743221283\n",
      "Step 0  Loss: 0.4642431437969208\n",
      "Step 1  Loss: 0.5754060745239258\n",
      "Step 2  Loss: 0.451386034488678\n",
      "Step 3  Loss: 0.6759236454963684\n",
      "Step 4  Loss: 0.5035780072212219\n",
      "Step 5  Loss: 0.4346003830432892\n",
      "Step 6  Loss: 0.5316064357757568\n",
      "Step 7  Loss: 0.6006717085838318\n",
      "Step 8  Loss: 0.46112382411956787\n",
      "Step 9  Loss: 0.5895775556564331\n",
      "Step 10  Loss: 0.5628286600112915\n",
      "total Loss of epoch  6  is  5.850945472717285\n",
      "Step 0  Loss: 0.570776641368866\n",
      "Step 1  Loss: 0.5326471328735352\n",
      "Step 2  Loss: 0.5474341511726379\n",
      "Step 3  Loss: 0.39854422211647034\n",
      "Step 4  Loss: 0.4037722051143646\n",
      "Step 5  Loss: 0.5018683671951294\n",
      "Step 6  Loss: 0.5505801439285278\n",
      "Step 7  Loss: 0.43109190464019775\n",
      "Step 8  Loss: 0.4273293614387512\n",
      "Step 9  Loss: 0.5168551802635193\n",
      "Step 10  Loss: 0.49855682253837585\n",
      "total Loss of epoch  7  is  5.379456132650375\n",
      "Step 0  Loss: 0.4102737009525299\n",
      "Step 1  Loss: 0.5119010210037231\n",
      "Step 2  Loss: 0.5283455848693848\n",
      "Step 3  Loss: 0.54054856300354\n",
      "Step 4  Loss: 0.5461592078208923\n",
      "Step 5  Loss: 0.457454651594162\n",
      "Step 6  Loss: 0.5408343076705933\n",
      "Step 7  Loss: 0.4739660322666168\n",
      "Step 8  Loss: 0.6301785111427307\n",
      "Step 9  Loss: 0.42095664143562317\n",
      "Step 10  Loss: 0.5912430882453918\n",
      "total Loss of epoch  8  is  5.651861310005188\n",
      "Step 0  Loss: 0.5442198514938354\n",
      "Step 1  Loss: 0.5980894565582275\n",
      "Step 2  Loss: 0.5033489465713501\n",
      "Step 3  Loss: 0.4787169396877289\n",
      "Step 4  Loss: 0.5307159423828125\n",
      "Step 5  Loss: 0.48480623960494995\n",
      "Step 6  Loss: 0.5370659828186035\n",
      "Step 7  Loss: 0.45919960737228394\n",
      "Step 8  Loss: 0.539596438407898\n",
      "Step 9  Loss: 0.42107704281806946\n",
      "Step 10  Loss: 0.6437847018241882\n",
      "total Loss of epoch  9  is  5.7406211495399475\n",
      "Step 0  Loss: 0.5570430159568787\n",
      "Step 1  Loss: 0.5151507258415222\n",
      "Step 2  Loss: 0.5177521109580994\n",
      "Step 3  Loss: 0.5119715929031372\n",
      "Step 4  Loss: 0.4712999761104584\n",
      "Step 5  Loss: 0.48549044132232666\n",
      "Step 6  Loss: 0.45935720205307007\n",
      "Step 7  Loss: 0.4656224846839905\n",
      "Step 8  Loss: 0.4256158769130707\n",
      "Step 9  Loss: 0.5489023327827454\n",
      "Step 10  Loss: 0.35849663615226746\n",
      "total Loss of epoch  10  is  5.3167023956775665\n",
      "Step 0  Loss: 0.5622599720954895\n",
      "Step 1  Loss: 0.4484643340110779\n",
      "Step 2  Loss: 0.4096761643886566\n",
      "Step 3  Loss: 0.5390247702598572\n",
      "Step 4  Loss: 0.4484761357307434\n",
      "Step 5  Loss: 0.4501982033252716\n",
      "Step 6  Loss: 0.39356228709220886\n",
      "Step 7  Loss: 0.5638990998268127\n",
      "Step 8  Loss: 0.45171913504600525\n",
      "Step 9  Loss: 0.46888425946235657\n",
      "Step 10  Loss: 0.42844006419181824\n",
      "total Loss of epoch  11  is  5.164604425430298\n",
      "Step 0  Loss: 0.4667604863643646\n",
      "Step 1  Loss: 0.5448434352874756\n",
      "Step 2  Loss: 0.5696102976799011\n",
      "Step 3  Loss: 0.42665570974349976\n",
      "Step 4  Loss: 0.5687262415885925\n",
      "Step 5  Loss: 0.44321879744529724\n",
      "Step 6  Loss: 0.521186351776123\n",
      "Step 7  Loss: 0.4591991901397705\n",
      "Step 8  Loss: 0.46337246894836426\n",
      "Step 9  Loss: 0.6116235852241516\n",
      "Step 10  Loss: 0.4032515585422516\n",
      "total Loss of epoch  12  is  5.478448122739792\n",
      "Step 0  Loss: 0.4654763340950012\n",
      "Step 1  Loss: 0.4560513496398926\n",
      "Step 2  Loss: 0.4346829056739807\n",
      "Step 3  Loss: 0.6387239694595337\n",
      "Step 4  Loss: 0.5179254412651062\n",
      "Step 5  Loss: 0.43969011306762695\n",
      "Step 6  Loss: 0.4932602643966675\n",
      "Step 7  Loss: 0.5021906495094299\n",
      "Step 8  Loss: 0.4172872304916382\n",
      "Step 9  Loss: 0.5366186499595642\n",
      "Step 10  Loss: 0.3129168450832367\n",
      "total Loss of epoch  13  is  5.214823752641678\n",
      "Step 0  Loss: 0.5508594512939453\n",
      "Step 1  Loss: 0.43352600932121277\n",
      "Step 2  Loss: 0.4865747392177582\n",
      "Step 3  Loss: 0.48902109265327454\n",
      "Step 4  Loss: 0.3376682698726654\n",
      "Step 5  Loss: 0.5119100213050842\n",
      "Step 6  Loss: 0.4643394351005554\n",
      "Step 7  Loss: 0.45026683807373047\n",
      "Step 8  Loss: 0.5161059498786926\n",
      "Step 9  Loss: 0.4159877598285675\n",
      "Step 10  Loss: 0.5736621022224426\n",
      "total Loss of epoch  14  is  5.229921668767929\n",
      "Step 0  Loss: 0.5611841678619385\n",
      "Step 1  Loss: 0.4893495738506317\n",
      "Step 2  Loss: 0.5124757885932922\n",
      "Step 3  Loss: 0.5169920921325684\n",
      "Step 4  Loss: 0.4200367331504822\n",
      "Step 5  Loss: 0.4784836769104004\n",
      "Step 6  Loss: 0.5254791975021362\n",
      "Step 7  Loss: 0.3587948679924011\n",
      "Step 8  Loss: 0.4918157458305359\n",
      "Step 9  Loss: 0.5578185319900513\n",
      "Step 10  Loss: 0.4572138488292694\n",
      "total Loss of epoch  15  is  5.369644224643707\n",
      "Step 0  Loss: 0.4796302020549774\n",
      "Step 1  Loss: 0.4804774224758148\n",
      "Step 2  Loss: 0.5866367220878601\n",
      "Step 3  Loss: 0.45957469940185547\n",
      "Step 4  Loss: 0.5428488254547119\n",
      "Step 5  Loss: 0.4180341958999634\n",
      "Step 6  Loss: 0.5581017732620239\n",
      "Step 7  Loss: 0.4984334707260132\n",
      "Step 8  Loss: 0.5484061241149902\n",
      "Step 9  Loss: 0.4650615453720093\n",
      "Step 10  Loss: 0.49232640862464905\n",
      "total Loss of epoch  16  is  5.529531389474869\n",
      "Step 0  Loss: 0.47511085867881775\n",
      "Step 1  Loss: 0.5052916407585144\n",
      "Step 2  Loss: 0.48041149973869324\n",
      "Step 3  Loss: 0.5926764011383057\n",
      "Step 4  Loss: 0.5677995681762695\n",
      "Step 5  Loss: 0.43172264099121094\n",
      "Step 6  Loss: 0.5214723348617554\n",
      "Step 7  Loss: 0.5709399580955505\n",
      "Step 8  Loss: 0.5851143598556519\n",
      "Step 9  Loss: 0.4752674698829651\n",
      "Step 10  Loss: 0.35090747475624084\n",
      "total Loss of epoch  17  is  5.556714206933975\n",
      "Step 0  Loss: 0.48450687527656555\n",
      "Step 1  Loss: 0.5247214436531067\n",
      "Step 2  Loss: 0.511725902557373\n",
      "Step 3  Loss: 0.49593162536621094\n",
      "Step 4  Loss: 0.44137945771217346\n",
      "Step 5  Loss: 0.46903228759765625\n",
      "Step 6  Loss: 0.5927451252937317\n",
      "Step 7  Loss: 0.41373294591903687\n",
      "Step 8  Loss: 0.6096620559692383\n",
      "Step 9  Loss: 0.5152313709259033\n",
      "Step 10  Loss: 0.5982556343078613\n",
      "total Loss of epoch  18  is  5.656924724578857\n",
      "Step 0  Loss: 0.4527554512023926\n",
      "Step 1  Loss: 0.5084694027900696\n",
      "Step 2  Loss: 0.43674007058143616\n",
      "Step 3  Loss: 0.4509385824203491\n",
      "Step 4  Loss: 0.5163775682449341\n",
      "Step 5  Loss: 0.5020498633384705\n",
      "Step 6  Loss: 0.5516501665115356\n",
      "Step 7  Loss: 0.5119187831878662\n",
      "Step 8  Loss: 0.4538121819496155\n",
      "Step 9  Loss: 0.5240572690963745\n",
      "Step 10  Loss: 0.3241572380065918\n",
      "total Loss of epoch  19  is  5.232926577329636\n",
      "Step 0  Loss: 0.4203302264213562\n",
      "Step 1  Loss: 0.4993884265422821\n",
      "Step 2  Loss: 0.5740464925765991\n",
      "Step 3  Loss: 0.589870274066925\n",
      "Step 4  Loss: 0.3743259906768799\n",
      "Step 5  Loss: 0.4092845618724823\n",
      "Step 6  Loss: 0.4558018445968628\n",
      "Step 7  Loss: 0.5374305248260498\n",
      "Step 8  Loss: 0.5381537675857544\n",
      "Step 9  Loss: 0.57313472032547\n",
      "Step 10  Loss: 0.4455050826072693\n",
      "total Loss of epoch  20  is  5.417271912097931\n",
      "Step 0  Loss: 0.4463115632534027\n",
      "Step 1  Loss: 0.4406232237815857\n",
      "Step 2  Loss: 0.5692676901817322\n",
      "Step 3  Loss: 0.4883287250995636\n",
      "Step 4  Loss: 0.5104271173477173\n",
      "Step 5  Loss: 0.3959019184112549\n",
      "Step 6  Loss: 0.5660547018051147\n",
      "Step 7  Loss: 0.6044840216636658\n",
      "Step 8  Loss: 0.36740371584892273\n",
      "Step 9  Loss: 0.3745380640029907\n",
      "Step 10  Loss: 0.5522255897521973\n",
      "total Loss of epoch  21  is  5.315566331148148\n",
      "Step 0  Loss: 0.46923381090164185\n",
      "Step 1  Loss: 0.5229243040084839\n",
      "Step 2  Loss: 0.502830982208252\n",
      "Step 3  Loss: 0.5739914178848267\n",
      "Step 4  Loss: 0.428118497133255\n",
      "Step 5  Loss: 0.4744649827480316\n",
      "Step 6  Loss: 0.4982774257659912\n",
      "Step 7  Loss: 0.5513308644294739\n",
      "Step 8  Loss: 0.4513710141181946\n",
      "Step 9  Loss: 0.46390023827552795\n",
      "Step 10  Loss: 0.4097876250743866\n",
      "total Loss of epoch  22  is  5.346231162548065\n",
      "Step 0  Loss: 0.5556499361991882\n",
      "Step 1  Loss: 0.614231288433075\n",
      "Step 2  Loss: 0.4835014343261719\n",
      "Step 3  Loss: 0.4814120829105377\n",
      "Step 4  Loss: 0.44924643635749817\n",
      "Step 5  Loss: 0.409172385931015\n",
      "Step 6  Loss: 0.37700653076171875\n",
      "Step 7  Loss: 0.3820568323135376\n",
      "Step 8  Loss: 0.3005615770816803\n",
      "Step 9  Loss: 0.4626580476760864\n",
      "Step 10  Loss: 0.4494413435459137\n",
      "total Loss of epoch  23  is  4.964937895536423\n",
      "Step 0  Loss: 0.5891737937927246\n",
      "Step 1  Loss: 0.46907421946525574\n",
      "Step 2  Loss: 0.42078354954719543\n",
      "Step 3  Loss: 0.5450412631034851\n",
      "Step 4  Loss: 0.4012306332588196\n",
      "Step 5  Loss: 0.5623846054077148\n",
      "Step 6  Loss: 0.5526450276374817\n",
      "Step 7  Loss: 0.4251205325126648\n",
      "Step 8  Loss: 0.4766257107257843\n",
      "Step 9  Loss: 0.48282790184020996\n",
      "Step 10  Loss: 0.6050426363945007\n",
      "total Loss of epoch  24  is  5.529949873685837\n",
      "Step 0  Loss: 0.4347998797893524\n",
      "Step 1  Loss: 0.3612307012081146\n",
      "Step 2  Loss: 0.4149758219718933\n",
      "Step 3  Loss: 0.5355459451675415\n",
      "Step 4  Loss: 0.5560131669044495\n",
      "Step 5  Loss: 0.44215044379234314\n",
      "Step 6  Loss: 0.5296244621276855\n",
      "Step 7  Loss: 0.5133639574050903\n",
      "Step 8  Loss: 0.4225701689720154\n",
      "Step 9  Loss: 0.5725961327552795\n",
      "Step 10  Loss: 0.3564944863319397\n",
      "total Loss of epoch  25  is  5.139365166425705\n",
      "Step 0  Loss: 0.5458857417106628\n",
      "Step 1  Loss: 0.6058558225631714\n",
      "Step 2  Loss: 0.5548204183578491\n",
      "Step 3  Loss: 0.5698885917663574\n",
      "Step 4  Loss: 0.41069266200065613\n",
      "Step 5  Loss: 0.4824847877025604\n",
      "Step 6  Loss: 0.5700249075889587\n",
      "Step 7  Loss: 0.5597625374794006\n",
      "Step 8  Loss: 0.4426524341106415\n",
      "Step 9  Loss: 0.5913934707641602\n",
      "Step 10  Loss: 0.5342351794242859\n",
      "total Loss of epoch  26  is  5.867696553468704\n",
      "Step 0  Loss: 0.415113240480423\n",
      "Step 1  Loss: 0.4323381185531616\n",
      "Step 2  Loss: 0.604767382144928\n",
      "Step 3  Loss: 0.4875234365463257\n",
      "Step 4  Loss: 0.2939285635948181\n",
      "Step 5  Loss: 0.5577197074890137\n",
      "Step 6  Loss: 0.5903112292289734\n",
      "Step 7  Loss: 0.5356606245040894\n",
      "Step 8  Loss: 0.46529632806777954\n",
      "Step 9  Loss: 0.5114074945449829\n",
      "Step 10  Loss: 0.5090047717094421\n",
      "total Loss of epoch  27  is  5.403070896863937\n",
      "Step 0  Loss: 0.30166003108024597\n",
      "Step 1  Loss: 0.5363610982894897\n",
      "Step 2  Loss: 0.5729321241378784\n",
      "Step 3  Loss: 0.5767335891723633\n",
      "Step 4  Loss: 0.4594723582267761\n",
      "Step 5  Loss: 0.5776621103286743\n",
      "Step 6  Loss: 0.45732375979423523\n",
      "Step 7  Loss: 0.566957950592041\n",
      "Step 8  Loss: 0.440996378660202\n",
      "Step 9  Loss: 0.32548433542251587\n",
      "Step 10  Loss: 0.40029752254486084\n",
      "total Loss of epoch  28  is  5.215881258249283\n",
      "Step 0  Loss: 0.5594042539596558\n",
      "Step 1  Loss: 0.5464015007019043\n",
      "Step 2  Loss: 0.5816348195075989\n",
      "Step 3  Loss: 0.5064852237701416\n",
      "Step 4  Loss: 0.5363202691078186\n",
      "Step 5  Loss: 0.5564452409744263\n",
      "Step 6  Loss: 0.45774954557418823\n",
      "Step 7  Loss: 0.5155301690101624\n",
      "Step 8  Loss: 0.635185956954956\n",
      "Step 9  Loss: 0.3912440836429596\n",
      "Step 10  Loss: 0.6384882926940918\n",
      "total Loss of epoch  29  is  5.924889355897903\n",
      "Step 0  Loss: 0.536514937877655\n",
      "Step 1  Loss: 0.5294317603111267\n",
      "Step 2  Loss: 0.5096818208694458\n",
      "Step 3  Loss: 0.4466208517551422\n",
      "Step 4  Loss: 0.5409687161445618\n",
      "Step 5  Loss: 0.4908512830734253\n",
      "Step 6  Loss: 0.4642871618270874\n",
      "Step 7  Loss: 0.5919104814529419\n",
      "Step 8  Loss: 0.4538307785987854\n",
      "Step 9  Loss: 0.5329394936561584\n",
      "Step 10  Loss: 0.3941367566585541\n",
      "total Loss of epoch  30  is  5.491174042224884\n",
      "Step 0  Loss: 0.5836533308029175\n",
      "Step 1  Loss: 0.557737410068512\n",
      "Step 2  Loss: 0.3467450439929962\n",
      "Step 3  Loss: 0.40505120158195496\n",
      "Step 4  Loss: 0.44731688499450684\n",
      "Step 5  Loss: 0.4557814300060272\n",
      "Step 6  Loss: 0.469630628824234\n",
      "Step 7  Loss: 0.45937231183052063\n",
      "Step 8  Loss: 0.5941436290740967\n",
      "Step 9  Loss: 0.4103793799877167\n",
      "Step 10  Loss: 0.3227141201496124\n",
      "total Loss of epoch  31  is  5.052525371313095\n",
      "Step 0  Loss: 0.4820646345615387\n",
      "Step 1  Loss: 0.4481598734855652\n",
      "Step 2  Loss: 0.5251890420913696\n",
      "Step 3  Loss: 0.43457120656967163\n",
      "Step 4  Loss: 0.4410199820995331\n",
      "Step 5  Loss: 0.4914579391479492\n",
      "Step 6  Loss: 0.3724638521671295\n",
      "Step 7  Loss: 0.6254836916923523\n",
      "Step 8  Loss: 0.4222313165664673\n",
      "Step 9  Loss: 0.40301477909088135\n",
      "Step 10  Loss: 0.469711035490036\n",
      "total Loss of epoch  32  is  5.115367352962494\n",
      "Step 0  Loss: 0.3565824329853058\n",
      "Step 1  Loss: 0.3920133113861084\n",
      "Step 2  Loss: 0.3777865469455719\n",
      "Step 3  Loss: 0.5490157008171082\n",
      "Step 4  Loss: 0.4904911518096924\n",
      "Step 5  Loss: 0.4701719284057617\n",
      "Step 6  Loss: 0.47436824440956116\n",
      "Step 7  Loss: 0.4504717290401459\n",
      "Step 8  Loss: 0.45559605956077576\n",
      "Step 9  Loss: 0.320505291223526\n",
      "Step 10  Loss: 0.5983614325523376\n",
      "total Loss of epoch  33  is  4.935363829135895\n",
      "Step 0  Loss: 0.5468725562095642\n",
      "Step 1  Loss: 0.5380308032035828\n",
      "Step 2  Loss: 0.36862435936927795\n",
      "Step 3  Loss: 0.42226457595825195\n",
      "Step 4  Loss: 0.47416457533836365\n",
      "Step 5  Loss: 0.4684526324272156\n",
      "Step 6  Loss: 0.33481743931770325\n",
      "Step 7  Loss: 0.48978322744369507\n",
      "Step 8  Loss: 0.5059562921524048\n",
      "Step 9  Loss: 0.5124145746231079\n",
      "Step 10  Loss: 0.45220428705215454\n",
      "total Loss of epoch  34  is  5.113585323095322\n",
      "Step 0  Loss: 0.5594474673271179\n",
      "Step 1  Loss: 0.3939659595489502\n",
      "Step 2  Loss: 0.4366195797920227\n",
      "Step 3  Loss: 0.5092596411705017\n",
      "Step 4  Loss: 0.449360728263855\n",
      "Step 5  Loss: 0.39464715123176575\n",
      "Step 6  Loss: 0.6147710084915161\n",
      "Step 7  Loss: 0.5678642988204956\n",
      "Step 8  Loss: 0.47185245156288147\n",
      "Step 9  Loss: 0.5221976637840271\n",
      "Step 10  Loss: 0.4697682559490204\n",
      "total Loss of epoch  35  is  5.389754205942154\n",
      "Step 0  Loss: 0.46934521198272705\n",
      "Step 1  Loss: 0.5170479416847229\n",
      "Step 2  Loss: 0.42442935705184937\n",
      "Step 3  Loss: 0.48845916986465454\n",
      "Step 4  Loss: 0.42765381932258606\n",
      "Step 5  Loss: 0.421697199344635\n",
      "Step 6  Loss: 0.5095008015632629\n",
      "Step 7  Loss: 0.471518874168396\n",
      "Step 8  Loss: 0.36841848492622375\n",
      "Step 9  Loss: 0.5073418617248535\n",
      "Step 10  Loss: 0.4189675748348236\n",
      "total Loss of epoch  36  is  5.024380296468735\n",
      "Step 0  Loss: 0.46881428360939026\n",
      "Step 1  Loss: 0.4706224501132965\n",
      "Step 2  Loss: 0.4840937554836273\n",
      "Step 3  Loss: 0.5150029063224792\n",
      "Step 4  Loss: 0.3851698338985443\n",
      "Step 5  Loss: 0.5482533574104309\n",
      "Step 6  Loss: 0.5603578090667725\n",
      "Step 7  Loss: 0.4495316743850708\n",
      "Step 8  Loss: 0.4161502718925476\n",
      "Step 9  Loss: 0.4816263020038605\n",
      "Step 10  Loss: 0.5252107977867126\n",
      "total Loss of epoch  37  is  5.3048334419727325\n",
      "Step 0  Loss: 0.5078168511390686\n",
      "Step 1  Loss: 0.5061461329460144\n",
      "Step 2  Loss: 0.4718128442764282\n",
      "Step 3  Loss: 0.5551320910453796\n",
      "Step 4  Loss: 0.5844060778617859\n",
      "Step 5  Loss: 0.4741968810558319\n",
      "Step 6  Loss: 0.45510783791542053\n",
      "Step 7  Loss: 0.3921707272529602\n",
      "Step 8  Loss: 0.5340257883071899\n",
      "Step 9  Loss: 0.5309376120567322\n",
      "Step 10  Loss: 0.5052633285522461\n",
      "total Loss of epoch  38  is  5.517016172409058\n",
      "Step 0  Loss: 0.4115825891494751\n",
      "Step 1  Loss: 0.4208364188671112\n",
      "Step 2  Loss: 0.45570889115333557\n",
      "Step 3  Loss: 0.4640040099620819\n",
      "Step 4  Loss: 0.4483759105205536\n",
      "Step 5  Loss: 0.5222674608230591\n",
      "Step 6  Loss: 0.5185695290565491\n",
      "Step 7  Loss: 0.4142633378505707\n",
      "Step 8  Loss: 0.5069092512130737\n",
      "Step 9  Loss: 0.4678471088409424\n",
      "Step 10  Loss: 0.39894920587539673\n",
      "total Loss of epoch  39  is  5.029313713312149\n",
      "Step 0  Loss: 0.38456302881240845\n",
      "Step 1  Loss: 0.52161705493927\n",
      "Step 2  Loss: 0.4881467819213867\n",
      "Step 3  Loss: 0.4283849895000458\n",
      "Step 4  Loss: 0.47531402111053467\n",
      "Step 5  Loss: 0.3373717963695526\n",
      "Step 6  Loss: 0.4958832263946533\n",
      "Step 7  Loss: 0.4969364404678345\n",
      "Step 8  Loss: 0.4803268015384674\n",
      "Step 9  Loss: 0.5291830897331238\n",
      "Step 10  Loss: 0.5390976667404175\n",
      "total Loss of epoch  40  is  5.176824897527695\n",
      "Step 0  Loss: 0.37499144673347473\n",
      "Step 1  Loss: 0.4989235997200012\n",
      "Step 2  Loss: 0.44671064615249634\n",
      "Step 3  Loss: 0.41760769486427307\n",
      "Step 4  Loss: 0.42432790994644165\n",
      "Step 5  Loss: 0.3962174952030182\n",
      "Step 6  Loss: 0.5262019634246826\n",
      "Step 7  Loss: 0.4257645905017853\n",
      "Step 8  Loss: 0.39788514375686646\n",
      "Step 9  Loss: 0.42083895206451416\n",
      "Step 10  Loss: 0.4735738933086395\n",
      "total Loss of epoch  41  is  4.803043335676193\n",
      "Step 0  Loss: 0.3769187033176422\n",
      "Step 1  Loss: 0.4183933734893799\n",
      "Step 2  Loss: 0.46184277534484863\n",
      "Step 3  Loss: 0.4698675572872162\n",
      "Step 4  Loss: 0.5242232084274292\n",
      "Step 5  Loss: 0.32837963104248047\n",
      "Step 6  Loss: 0.3914378881454468\n",
      "Step 7  Loss: 0.5126349329948425\n",
      "Step 8  Loss: 0.48297441005706787\n",
      "Step 9  Loss: 0.369222491979599\n",
      "Step 10  Loss: 0.4539623260498047\n",
      "total Loss of epoch  42  is  4.7898572981357574\n",
      "Step 0  Loss: 0.42568516731262207\n",
      "Step 1  Loss: 0.5353933572769165\n",
      "Step 2  Loss: 0.5266131162643433\n",
      "Step 3  Loss: 0.4523480534553528\n",
      "Step 4  Loss: 0.48120468854904175\n",
      "Step 5  Loss: 0.45100048184394836\n",
      "Step 6  Loss: 0.450334757566452\n",
      "Step 7  Loss: 0.4712030589580536\n",
      "Step 8  Loss: 0.5220569968223572\n",
      "Step 9  Loss: 0.3008919656276703\n",
      "Step 10  Loss: 0.3732517659664154\n",
      "total Loss of epoch  43  is  4.989983409643173\n",
      "Step 0  Loss: 0.4886356294155121\n",
      "Step 1  Loss: 0.4755866825580597\n",
      "Step 2  Loss: 0.3449634313583374\n",
      "Step 3  Loss: 0.4541177749633789\n",
      "Step 4  Loss: 0.3724555969238281\n",
      "Step 5  Loss: 0.6209849715232849\n",
      "Step 6  Loss: 0.5029443502426147\n",
      "Step 7  Loss: 0.39735978841781616\n",
      "Step 8  Loss: 0.4623998701572418\n",
      "Step 9  Loss: 0.42436960339546204\n",
      "Step 10  Loss: 0.4937082529067993\n",
      "total Loss of epoch  44  is  5.037525951862335\n",
      "Step 0  Loss: 0.3809603154659271\n",
      "Step 1  Loss: 0.4632922112941742\n",
      "Step 2  Loss: 0.4444158971309662\n",
      "Step 3  Loss: 0.4243617057800293\n",
      "Step 4  Loss: 0.41661930084228516\n",
      "Step 5  Loss: 0.45453140139579773\n",
      "Step 6  Loss: 0.41891488432884216\n",
      "Step 7  Loss: 0.46267542243003845\n",
      "Step 8  Loss: 0.4855700433254242\n",
      "Step 9  Loss: 0.43249884247779846\n",
      "Step 10  Loss: 0.46141281723976135\n",
      "total Loss of epoch  45  is  4.845252841711044\n",
      "Step 0  Loss: 0.4048523008823395\n",
      "Step 1  Loss: 0.5035995244979858\n",
      "Step 2  Loss: 0.42344930768013\n",
      "Step 3  Loss: 0.47985872626304626\n",
      "Step 4  Loss: 0.5010411143302917\n",
      "Step 5  Loss: 0.4840729236602783\n",
      "Step 6  Loss: 0.42522546648979187\n",
      "Step 7  Loss: 0.4437081217765808\n",
      "Step 8  Loss: 0.30955418944358826\n",
      "Step 9  Loss: 0.3888125717639923\n",
      "Step 10  Loss: 0.5793915390968323\n",
      "total Loss of epoch  46  is  4.943565785884857\n",
      "Step 0  Loss: 0.4328782856464386\n",
      "Step 1  Loss: 0.39080965518951416\n",
      "Step 2  Loss: 0.5003852844238281\n",
      "Step 3  Loss: 0.41147345304489136\n",
      "Step 4  Loss: 0.43282344937324524\n",
      "Step 5  Loss: 0.4834640324115753\n",
      "Step 6  Loss: 0.5277165174484253\n",
      "Step 7  Loss: 0.5230156183242798\n",
      "Step 8  Loss: 0.4147093594074249\n",
      "Step 9  Loss: 0.38389304280281067\n",
      "Step 10  Loss: 0.5382438898086548\n",
      "total Loss of epoch  47  is  5.039412587881088\n",
      "Step 0  Loss: 0.44789567589759827\n",
      "Step 1  Loss: 0.4944758117198944\n",
      "Step 2  Loss: 0.5719440579414368\n",
      "Step 3  Loss: 0.4217911958694458\n",
      "Step 4  Loss: 0.5285617113113403\n",
      "Step 5  Loss: 0.45615118741989136\n",
      "Step 6  Loss: 0.5579383373260498\n",
      "Step 7  Loss: 0.47723254561424255\n",
      "Step 8  Loss: 0.5001770257949829\n",
      "Step 9  Loss: 0.4884878695011139\n",
      "Step 10  Loss: 0.4084615111351013\n",
      "total Loss of epoch  48  is  5.353116929531097\n",
      "Step 0  Loss: 0.48554807901382446\n",
      "Step 1  Loss: 0.39722704887390137\n",
      "Step 2  Loss: 0.411739706993103\n",
      "Step 3  Loss: 0.4289286732673645\n",
      "Step 4  Loss: 0.36408334970474243\n",
      "Step 5  Loss: 0.35513386130332947\n",
      "Step 6  Loss: 0.518291175365448\n",
      "Step 7  Loss: 0.5337960124015808\n",
      "Step 8  Loss: 0.46500417590141296\n",
      "Step 9  Loss: 0.4162602126598358\n",
      "Step 10  Loss: 0.43473055958747864\n",
      "total Loss of epoch  49  is  4.8107428550720215\n",
      "Step 0  Loss: 0.34403446316719055\n",
      "Step 1  Loss: 0.5572511553764343\n",
      "Step 2  Loss: 0.46028468012809753\n",
      "Step 3  Loss: 0.4158414304256439\n",
      "Step 4  Loss: 0.44557851552963257\n",
      "Step 5  Loss: 0.43649324774742126\n",
      "Step 6  Loss: 0.49598318338394165\n",
      "Step 7  Loss: 0.41984403133392334\n",
      "Step 8  Loss: 0.35718804597854614\n",
      "Step 9  Loss: 0.41476333141326904\n",
      "Step 10  Loss: 0.24429285526275635\n",
      "total Loss of epoch  50  is  4.591554939746857\n",
      "Step 0  Loss: 0.45293891429901123\n",
      "Step 1  Loss: 0.4651767611503601\n",
      "Step 2  Loss: 0.4514736533164978\n",
      "Step 3  Loss: 0.46898192167282104\n",
      "Step 4  Loss: 0.40099820494651794\n",
      "Step 5  Loss: 0.36968380212783813\n",
      "Step 6  Loss: 0.44072961807250977\n",
      "Step 7  Loss: 0.4421809911727905\n",
      "Step 8  Loss: 0.578617513179779\n",
      "Step 9  Loss: 0.4207844138145447\n",
      "Step 10  Loss: 0.4765661656856537\n",
      "total Loss of epoch  51  is  4.968131959438324\n",
      "Step 0  Loss: 0.4765619933605194\n",
      "Step 1  Loss: 0.5599459409713745\n",
      "Step 2  Loss: 0.41348525881767273\n",
      "Step 3  Loss: 0.4158809781074524\n",
      "Step 4  Loss: 0.45280227065086365\n",
      "Step 5  Loss: 0.49939796328544617\n",
      "Step 6  Loss: 0.4540467858314514\n",
      "Step 7  Loss: 0.5170378684997559\n",
      "Step 8  Loss: 0.4164571166038513\n",
      "Step 9  Loss: 0.5658731460571289\n",
      "Step 10  Loss: 0.5795392990112305\n",
      "total Loss of epoch  52  is  5.351028621196747\n",
      "Step 0  Loss: 0.3377740681171417\n",
      "Step 1  Loss: 0.3433864712715149\n",
      "Step 2  Loss: 0.21036362648010254\n",
      "Step 3  Loss: 0.4262140989303589\n",
      "Step 4  Loss: 0.550916314125061\n",
      "Step 5  Loss: 0.3160589039325714\n",
      "Step 6  Loss: 0.39376839995384216\n",
      "Step 7  Loss: 0.5263815522193909\n",
      "Step 8  Loss: 0.49896055459976196\n",
      "Step 9  Loss: 0.5080828666687012\n",
      "Step 10  Loss: 0.3849550783634186\n",
      "total Loss of epoch  53  is  4.496861934661865\n",
      "Step 0  Loss: 0.46539461612701416\n",
      "Step 1  Loss: 0.4064262807369232\n",
      "Step 2  Loss: 0.40943363308906555\n",
      "Step 3  Loss: 0.48108649253845215\n",
      "Step 4  Loss: 0.44504523277282715\n",
      "Step 5  Loss: 0.4439241588115692\n",
      "Step 6  Loss: 0.3854263126850128\n",
      "Step 7  Loss: 0.4958650469779968\n",
      "Step 8  Loss: 0.369902640581131\n",
      "Step 9  Loss: 0.32247692346572876\n",
      "Step 10  Loss: 0.4692690968513489\n",
      "total Loss of epoch  54  is  4.69425043463707\n",
      "Step 0  Loss: 0.4709981679916382\n",
      "Step 1  Loss: 0.4311780035495758\n",
      "Step 2  Loss: 0.5497714281082153\n",
      "Step 3  Loss: 0.4892914295196533\n",
      "Step 4  Loss: 0.407600462436676\n",
      "Step 5  Loss: 0.4405067265033722\n",
      "Step 6  Loss: 0.39275428652763367\n",
      "Step 7  Loss: 0.5098927021026611\n",
      "Step 8  Loss: 0.49819061160087585\n",
      "Step 9  Loss: 0.4983679950237274\n",
      "Step 10  Loss: 0.5014979243278503\n",
      "total Loss of epoch  55  is  5.190049737691879\n",
      "Step 0  Loss: 0.4933692514896393\n",
      "Step 1  Loss: 0.506380558013916\n",
      "Step 2  Loss: 0.41623082756996155\n",
      "Step 3  Loss: 0.4367932975292206\n",
      "Step 4  Loss: 0.4309612214565277\n",
      "Step 5  Loss: 0.4001529812812805\n",
      "Step 6  Loss: 0.4178851842880249\n",
      "Step 7  Loss: 0.4718126952648163\n",
      "Step 8  Loss: 0.33310753107070923\n",
      "Step 9  Loss: 0.4130937457084656\n",
      "Step 10  Loss: 0.475425124168396\n",
      "total Loss of epoch  56  is  4.795212417840958\n",
      "Step 0  Loss: 0.40739017724990845\n",
      "Step 1  Loss: 0.42873308062553406\n",
      "Step 2  Loss: 0.35988593101501465\n",
      "Step 3  Loss: 0.3756851553916931\n",
      "Step 4  Loss: 0.5091677904129028\n",
      "Step 5  Loss: 0.497978538274765\n",
      "Step 6  Loss: 0.4607233703136444\n",
      "Step 7  Loss: 0.40458062291145325\n",
      "Step 8  Loss: 0.31166768074035645\n",
      "Step 9  Loss: 0.49753648042678833\n",
      "Step 10  Loss: 0.49406903982162476\n",
      "total Loss of epoch  57  is  4.747417867183685\n",
      "Step 0  Loss: 0.38574349880218506\n",
      "Step 1  Loss: 0.47496435046195984\n",
      "Step 2  Loss: 0.5135026574134827\n",
      "Step 3  Loss: 0.41622039675712585\n",
      "Step 4  Loss: 0.454164981842041\n",
      "Step 5  Loss: 0.47874483466148376\n",
      "Step 6  Loss: 0.42263326048851013\n",
      "Step 7  Loss: 0.5258845090866089\n",
      "Step 8  Loss: 0.3927152454853058\n",
      "Step 9  Loss: 0.43483230471611023\n",
      "Step 10  Loss: 0.46122750639915466\n",
      "total Loss of epoch  58  is  4.960633546113968\n",
      "Step 0  Loss: 0.3684066832065582\n",
      "Step 1  Loss: 0.46841421723365784\n",
      "Step 2  Loss: 0.5069444179534912\n",
      "Step 3  Loss: 0.3468126952648163\n",
      "Step 4  Loss: 0.3726375699043274\n",
      "Step 5  Loss: 0.514191210269928\n",
      "Step 6  Loss: 0.3076499402523041\n",
      "Step 7  Loss: 0.30944085121154785\n",
      "Step 8  Loss: 0.3582295775413513\n",
      "Step 9  Loss: 0.5598466396331787\n",
      "Step 10  Loss: 0.5509639382362366\n",
      "total Loss of epoch  59  is  4.6635377407073975\n",
      "Step 0  Loss: 0.3199934661388397\n",
      "Step 1  Loss: 0.3264516294002533\n",
      "Step 2  Loss: 0.4376431107521057\n",
      "Step 3  Loss: 0.4382247030735016\n",
      "Step 4  Loss: 0.38414448499679565\n",
      "Step 5  Loss: 0.49155572056770325\n",
      "Step 6  Loss: 0.3222500681877136\n",
      "Step 7  Loss: 0.47906216979026794\n",
      "Step 8  Loss: 0.36156025528907776\n",
      "Step 9  Loss: 0.49266862869262695\n",
      "Step 10  Loss: 0.4466852843761444\n",
      "total Loss of epoch  60  is  4.50023952126503\n",
      "Step 0  Loss: 0.3548387885093689\n",
      "Step 1  Loss: 0.47957858443260193\n",
      "Step 2  Loss: 0.42343243956565857\n",
      "Step 3  Loss: 0.4206944704055786\n",
      "Step 4  Loss: 0.33698686957359314\n",
      "Step 5  Loss: 0.4895673394203186\n",
      "Step 6  Loss: 0.44961002469062805\n",
      "Step 7  Loss: 0.3455415964126587\n",
      "Step 8  Loss: 0.44474098086357117\n",
      "Step 9  Loss: 0.389180064201355\n",
      "Step 10  Loss: 0.45108509063720703\n",
      "total Loss of epoch  61  is  4.58525624871254\n",
      "Step 0  Loss: 0.5069818496704102\n",
      "Step 1  Loss: 0.3451494872570038\n",
      "Step 2  Loss: 0.4011848270893097\n",
      "Step 3  Loss: 0.48624250292778015\n",
      "Step 4  Loss: 0.4902840256690979\n",
      "Step 5  Loss: 0.41292908787727356\n",
      "Step 6  Loss: 0.34086450934410095\n",
      "Step 7  Loss: 0.4415777027606964\n",
      "Step 8  Loss: 0.48209232091903687\n",
      "Step 9  Loss: 0.42848122119903564\n",
      "Step 10  Loss: 0.41760513186454773\n",
      "total Loss of epoch  62  is  4.753392666578293\n",
      "Step 0  Loss: 0.449371874332428\n",
      "Step 1  Loss: 0.4864601194858551\n",
      "Step 2  Loss: 0.43480435013771057\n",
      "Step 3  Loss: 0.36431947350502014\n",
      "Step 4  Loss: 0.3421860337257385\n",
      "Step 5  Loss: 0.48615017533302307\n",
      "Step 6  Loss: 0.5372787714004517\n",
      "Step 7  Loss: 0.47178569436073303\n",
      "Step 8  Loss: 0.44101062417030334\n",
      "Step 9  Loss: 0.29436159133911133\n",
      "Step 10  Loss: 0.35747799277305603\n",
      "total Loss of epoch  63  is  4.665206700563431\n",
      "Step 0  Loss: 0.33081376552581787\n",
      "Step 1  Loss: 0.47732746601104736\n",
      "Step 2  Loss: 0.41057246923446655\n",
      "Step 3  Loss: 0.3842739462852478\n",
      "Step 4  Loss: 0.5646079778671265\n",
      "Step 5  Loss: 0.4258285164833069\n",
      "Step 6  Loss: 0.44291141629219055\n",
      "Step 7  Loss: 0.416537344455719\n",
      "Step 8  Loss: 0.47216910123825073\n",
      "Step 9  Loss: 0.5675588846206665\n",
      "Step 10  Loss: 0.44692304730415344\n",
      "total Loss of epoch  64  is  4.939523935317993\n",
      "Step 0  Loss: 0.4036312401294708\n",
      "Step 1  Loss: 0.41546517610549927\n",
      "Step 2  Loss: 0.45033085346221924\n",
      "Step 3  Loss: 0.3832872807979584\n",
      "Step 4  Loss: 0.43029147386550903\n",
      "Step 5  Loss: 0.32534611225128174\n",
      "Step 6  Loss: 0.4223296344280243\n",
      "Step 7  Loss: 0.4823501706123352\n",
      "Step 8  Loss: 0.5015825033187866\n",
      "Step 9  Loss: 0.481910765171051\n",
      "Step 10  Loss: 0.4119076430797577\n",
      "total Loss of epoch  65  is  4.708432853221893\n",
      "Step 0  Loss: 0.2777027487754822\n",
      "Step 1  Loss: 0.4001118540763855\n",
      "Step 2  Loss: 0.31727758049964905\n",
      "Step 3  Loss: 0.5283511281013489\n",
      "Step 4  Loss: 0.38055694103240967\n",
      "Step 5  Loss: 0.4598635137081146\n",
      "Step 6  Loss: 0.3621692657470703\n",
      "Step 7  Loss: 0.3904377520084381\n",
      "Step 8  Loss: 0.4024354815483093\n",
      "Step 9  Loss: 0.502656877040863\n",
      "Step 10  Loss: 0.5707076191902161\n",
      "total Loss of epoch  66  is  4.592270761728287\n",
      "Step 0  Loss: 0.4361680746078491\n",
      "Step 1  Loss: 0.5225995182991028\n",
      "Step 2  Loss: 0.3259733021259308\n",
      "Step 3  Loss: 0.3563280403614044\n",
      "Step 4  Loss: 0.4065597355365753\n",
      "Step 5  Loss: 0.47208982706069946\n",
      "Step 6  Loss: 0.4701246917247772\n",
      "Step 7  Loss: 0.4290889501571655\n",
      "Step 8  Loss: 0.3239815831184387\n",
      "Step 9  Loss: 0.38124963641166687\n",
      "Step 10  Loss: 0.3418462574481964\n",
      "total Loss of epoch  67  is  4.466009616851807\n",
      "Step 0  Loss: 0.39428722858428955\n",
      "Step 1  Loss: 0.40205469727516174\n",
      "Step 2  Loss: 0.43583449721336365\n",
      "Step 3  Loss: 0.46181684732437134\n",
      "Step 4  Loss: 0.39421072602272034\n",
      "Step 5  Loss: 0.353796124458313\n",
      "Step 6  Loss: 0.39176684617996216\n",
      "Step 7  Loss: 0.5000945329666138\n",
      "Step 8  Loss: 0.6058471202850342\n",
      "Step 9  Loss: 0.4580356478691101\n",
      "Step 10  Loss: 0.5347782373428345\n",
      "total Loss of epoch  68  is  4.932522505521774\n",
      "Step 0  Loss: 0.4755312502384186\n",
      "Step 1  Loss: 0.49290549755096436\n",
      "Step 2  Loss: 0.3718748390674591\n",
      "Step 3  Loss: 0.37834420800209045\n",
      "Step 4  Loss: 0.4309152364730835\n",
      "Step 5  Loss: 0.4563119411468506\n",
      "Step 6  Loss: 0.469422847032547\n",
      "Step 7  Loss: 0.2677253782749176\n",
      "Step 8  Loss: 0.42752283811569214\n",
      "Step 9  Loss: 0.5498701930046082\n",
      "Step 10  Loss: 0.5263122916221619\n",
      "total Loss of epoch  69  is  4.846736520528793\n",
      "Step 0  Loss: 0.4316382110118866\n",
      "Step 1  Loss: 0.3885151147842407\n",
      "Step 2  Loss: 0.4824412167072296\n",
      "Step 3  Loss: 0.42142534255981445\n",
      "Step 4  Loss: 0.2853353023529053\n",
      "Step 5  Loss: 0.44391849637031555\n",
      "Step 6  Loss: 0.3593919277191162\n",
      "Step 7  Loss: 0.42956066131591797\n",
      "Step 8  Loss: 0.3933061361312866\n",
      "Step 9  Loss: 0.42070239782333374\n",
      "Step 10  Loss: 0.48642483353614807\n",
      "total Loss of epoch  70  is  4.542659640312195\n",
      "Step 0  Loss: 0.38074159622192383\n",
      "Step 1  Loss: 0.3782004117965698\n",
      "Step 2  Loss: 0.39776647090911865\n",
      "Step 3  Loss: 0.40313720703125\n",
      "Step 4  Loss: 0.30661651492118835\n",
      "Step 5  Loss: 0.46514108777046204\n",
      "Step 6  Loss: 0.4210529625415802\n",
      "Step 7  Loss: 0.3741307854652405\n",
      "Step 8  Loss: 0.4129902720451355\n",
      "Step 9  Loss: 0.35595396161079407\n",
      "Step 10  Loss: 0.5608717203140259\n",
      "total Loss of epoch  71  is  4.456602990627289\n",
      "Step 0  Loss: 0.36782634258270264\n",
      "Step 1  Loss: 0.3510608375072479\n",
      "Step 2  Loss: 0.4334873557090759\n",
      "Step 3  Loss: 0.36140477657318115\n",
      "Step 4  Loss: 0.37872856855392456\n",
      "Step 5  Loss: 0.35529381036758423\n",
      "Step 6  Loss: 0.377652645111084\n",
      "Step 7  Loss: 0.3403950333595276\n",
      "Step 8  Loss: 0.25857868790626526\n",
      "Step 9  Loss: 0.3513318598270416\n",
      "Step 10  Loss: 0.3772784471511841\n",
      "total Loss of epoch  72  is  3.953038364648819\n",
      "Step 0  Loss: 0.45602571964263916\n",
      "Step 1  Loss: 0.35085731744766235\n",
      "Step 2  Loss: 0.42716512084007263\n",
      "Step 3  Loss: 0.4777066111564636\n",
      "Step 4  Loss: 0.5103501081466675\n",
      "Step 5  Loss: 0.47508662939071655\n",
      "Step 6  Loss: 0.4406801164150238\n",
      "Step 7  Loss: 0.4370673894882202\n",
      "Step 8  Loss: 0.4347449243068695\n",
      "Step 9  Loss: 0.5095705986022949\n",
      "Step 10  Loss: 0.36485254764556885\n",
      "total Loss of epoch  73  is  4.884107083082199\n",
      "Step 0  Loss: 0.3770042061805725\n",
      "Step 1  Loss: 0.4254745543003082\n",
      "Step 2  Loss: 0.44739624857902527\n",
      "Step 3  Loss: 0.5034443736076355\n",
      "Step 4  Loss: 0.38744252920150757\n",
      "Step 5  Loss: 0.4628349542617798\n",
      "Step 6  Loss: 0.3102867007255554\n",
      "Step 7  Loss: 0.3978966474533081\n",
      "Step 8  Loss: 0.46914637088775635\n",
      "Step 9  Loss: 0.4582977294921875\n",
      "Step 10  Loss: 0.45619022846221924\n",
      "total Loss of epoch  74  is  4.6954145431518555\n",
      "Step 0  Loss: 0.4912748634815216\n",
      "Step 1  Loss: 0.5244476199150085\n",
      "Step 2  Loss: 0.4630902409553528\n",
      "Step 3  Loss: 0.45325517654418945\n",
      "Step 4  Loss: 0.5640624761581421\n",
      "Step 5  Loss: 0.410590261220932\n",
      "Step 6  Loss: 0.3683241605758667\n",
      "Step 7  Loss: 0.35112571716308594\n",
      "Step 8  Loss: 0.4561140239238739\n",
      "Step 9  Loss: 0.42453277111053467\n",
      "Step 10  Loss: 0.33181750774383545\n",
      "total Loss of epoch  75  is  4.838634818792343\n",
      "Step 0  Loss: 0.4174417555332184\n",
      "Step 1  Loss: 0.3651610314846039\n",
      "Step 2  Loss: 0.37777382135391235\n",
      "Step 3  Loss: 0.395267128944397\n",
      "Step 4  Loss: 0.37427806854248047\n",
      "Step 5  Loss: 0.4612703323364258\n",
      "Step 6  Loss: 0.454233855009079\n",
      "Step 7  Loss: 0.441489040851593\n",
      "Step 8  Loss: 0.4120006263256073\n",
      "Step 9  Loss: 0.40259289741516113\n",
      "Step 10  Loss: 0.33086350560188293\n",
      "total Loss of epoch  76  is  4.432372063398361\n",
      "Step 0  Loss: 0.45867592096328735\n",
      "Step 1  Loss: 0.4891652464866638\n",
      "Step 2  Loss: 0.3645845353603363\n",
      "Step 3  Loss: 0.27208322286605835\n",
      "Step 4  Loss: 0.46810510754585266\n",
      "Step 5  Loss: 0.39353176951408386\n",
      "Step 6  Loss: 0.49590736627578735\n",
      "Step 7  Loss: 0.37018871307373047\n",
      "Step 8  Loss: 0.3886226415634155\n",
      "Step 9  Loss: 0.4352701008319855\n",
      "Step 10  Loss: 0.44085693359375\n",
      "total Loss of epoch  77  is  4.576991558074951\n",
      "Step 0  Loss: 0.5382912158966064\n",
      "Step 1  Loss: 0.3237064480781555\n",
      "Step 2  Loss: 0.3545210063457489\n",
      "Step 3  Loss: 0.33711087703704834\n",
      "Step 4  Loss: 0.4266747832298279\n",
      "Step 5  Loss: 0.3744641840457916\n",
      "Step 6  Loss: 0.3734897971153259\n",
      "Step 7  Loss: 0.5359132885932922\n",
      "Step 8  Loss: 0.3723197281360626\n",
      "Step 9  Loss: 0.4140264689922333\n",
      "Step 10  Loss: 0.5043140649795532\n",
      "total Loss of epoch  78  is  4.554831862449646\n",
      "Step 0  Loss: 0.5107981562614441\n",
      "Step 1  Loss: 0.3702692687511444\n",
      "Step 2  Loss: 0.36862245202064514\n",
      "Step 3  Loss: 0.4619760513305664\n",
      "Step 4  Loss: 0.523107647895813\n",
      "Step 5  Loss: 0.42868125438690186\n",
      "Step 6  Loss: 0.38379934430122375\n",
      "Step 7  Loss: 0.508320152759552\n",
      "Step 8  Loss: 0.49253350496292114\n",
      "Step 9  Loss: 0.3800642192363739\n",
      "Step 10  Loss: 0.544768214225769\n",
      "total Loss of epoch  79  is  4.972940266132355\n",
      "Step 0  Loss: 0.3496304452419281\n",
      "Step 1  Loss: 0.4337482154369354\n",
      "Step 2  Loss: 0.4676082730293274\n",
      "Step 3  Loss: 0.5593185424804688\n",
      "Step 4  Loss: 0.3206639289855957\n",
      "Step 5  Loss: 0.4164220988750458\n",
      "Step 6  Loss: 0.3776529133319855\n",
      "Step 7  Loss: 0.4801487922668457\n",
      "Step 8  Loss: 0.4810749888420105\n",
      "Step 9  Loss: 0.5322785377502441\n",
      "Step 10  Loss: 0.5187665224075317\n",
      "total Loss of epoch  80  is  4.937313258647919\n",
      "Step 0  Loss: 0.35699766874313354\n",
      "Step 1  Loss: 0.4943964183330536\n",
      "Step 2  Loss: 0.4156063199043274\n",
      "Step 3  Loss: 0.33579960465431213\n",
      "Step 4  Loss: 0.41610008478164673\n",
      "Step 5  Loss: 0.38060781359672546\n",
      "Step 6  Loss: 0.39398765563964844\n",
      "Step 7  Loss: 0.374475359916687\n",
      "Step 8  Loss: 0.4673822820186615\n",
      "Step 9  Loss: 0.36074110865592957\n",
      "Step 10  Loss: 0.4630896747112274\n",
      "total Loss of epoch  81  is  4.459183990955353\n",
      "Step 0  Loss: 0.32665032148361206\n",
      "Step 1  Loss: 0.45501410961151123\n",
      "Step 2  Loss: 0.3903658390045166\n",
      "Step 3  Loss: 0.34058326482772827\n",
      "Step 4  Loss: 0.3374335467815399\n",
      "Step 5  Loss: 0.386982262134552\n",
      "Step 6  Loss: 0.47756654024124146\n",
      "Step 7  Loss: 0.4395712912082672\n",
      "Step 8  Loss: 0.44715172052383423\n",
      "Step 9  Loss: 0.3649667799472809\n",
      "Step 10  Loss: 0.46168243885040283\n",
      "total Loss of epoch  82  is  4.427968114614487\n",
      "Step 0  Loss: 0.3130558431148529\n",
      "Step 1  Loss: 0.3815409243106842\n",
      "Step 2  Loss: 0.44783103466033936\n",
      "Step 3  Loss: 0.358254611492157\n",
      "Step 4  Loss: 0.504236102104187\n",
      "Step 5  Loss: 0.5236719846725464\n",
      "Step 6  Loss: 0.3805844485759735\n",
      "Step 7  Loss: 0.4693702161312103\n",
      "Step 8  Loss: 0.40124136209487915\n",
      "Step 9  Loss: 0.45623070001602173\n",
      "Step 10  Loss: 0.5147271156311035\n",
      "total Loss of epoch  83  is  4.750744342803955\n",
      "Step 0  Loss: 0.41370365023612976\n",
      "Step 1  Loss: 0.4724515676498413\n",
      "Step 2  Loss: 0.5287899374961853\n",
      "Step 3  Loss: 0.3787156641483307\n",
      "Step 4  Loss: 0.4084332585334778\n",
      "Step 5  Loss: 0.4682846665382385\n",
      "Step 6  Loss: 0.48206979036331177\n",
      "Step 7  Loss: 0.4668046236038208\n",
      "Step 8  Loss: 0.41605791449546814\n",
      "Step 9  Loss: 0.4587033987045288\n",
      "Step 10  Loss: 0.5244858860969543\n",
      "total Loss of epoch  84  is  5.018500357866287\n",
      "Step 0  Loss: 0.43461495637893677\n",
      "Step 1  Loss: 0.4411775767803192\n",
      "Step 2  Loss: 0.5098382234573364\n",
      "Step 3  Loss: 0.40324845910072327\n",
      "Step 4  Loss: 0.44129180908203125\n",
      "Step 5  Loss: 0.4780266284942627\n",
      "Step 6  Loss: 0.41458258032798767\n",
      "Step 7  Loss: 0.4334627687931061\n",
      "Step 8  Loss: 0.49603694677352905\n",
      "Step 9  Loss: 0.4342114329338074\n",
      "Step 10  Loss: 0.3828528821468353\n",
      "total Loss of epoch  85  is  4.869344264268875\n",
      "Step 0  Loss: 0.3167157769203186\n",
      "Step 1  Loss: 0.36576560139656067\n",
      "Step 2  Loss: 0.44279202818870544\n",
      "Step 3  Loss: 0.4586165249347687\n",
      "Step 4  Loss: 0.36415839195251465\n",
      "Step 5  Loss: 0.3268392086029053\n",
      "Step 6  Loss: 0.40593332052230835\n",
      "Step 7  Loss: 0.4564235806465149\n",
      "Step 8  Loss: 0.45816370844841003\n",
      "Step 9  Loss: 0.5281028747558594\n",
      "Step 10  Loss: 0.2769637405872345\n",
      "total Loss of epoch  86  is  4.4004747569561005\n",
      "Step 0  Loss: 0.44884905219078064\n",
      "Step 1  Loss: 0.48925724625587463\n",
      "Step 2  Loss: 0.39100340008735657\n",
      "Step 3  Loss: 0.3823122978210449\n",
      "Step 4  Loss: 0.43440932035446167\n",
      "Step 5  Loss: 0.3835982382297516\n",
      "Step 6  Loss: 0.3697749674320221\n",
      "Step 7  Loss: 0.44292008876800537\n",
      "Step 8  Loss: 0.37898769974708557\n",
      "Step 9  Loss: 0.53495854139328\n",
      "Step 10  Loss: 0.3536505401134491\n",
      "total Loss of epoch  87  is  4.609721392393112\n",
      "Step 0  Loss: 0.4778405427932739\n",
      "Step 1  Loss: 0.4921821653842926\n",
      "Step 2  Loss: 0.38530418276786804\n",
      "Step 3  Loss: 0.4289930760860443\n",
      "Step 4  Loss: 0.4622659981250763\n",
      "Step 5  Loss: 0.355790913105011\n",
      "Step 6  Loss: 0.4605470597743988\n",
      "Step 7  Loss: 0.47307392954826355\n",
      "Step 8  Loss: 0.4078080952167511\n",
      "Step 9  Loss: 0.351780503988266\n",
      "Step 10  Loss: 0.4976021349430084\n",
      "total Loss of epoch  88  is  4.793188601732254\n",
      "Step 0  Loss: 0.4596850574016571\n",
      "Step 1  Loss: 0.31559860706329346\n",
      "Step 2  Loss: 0.36837491393089294\n",
      "Step 3  Loss: 0.3751317262649536\n",
      "Step 4  Loss: 0.39790990948677063\n",
      "Step 5  Loss: 0.3934520184993744\n",
      "Step 6  Loss: 0.42342516779899597\n",
      "Step 7  Loss: 0.42688190937042236\n",
      "Step 8  Loss: 0.3955935537815094\n",
      "Step 9  Loss: 0.4093664884567261\n",
      "Step 10  Loss: 0.3713107109069824\n",
      "total Loss of epoch  89  is  4.336730062961578\n",
      "Step 0  Loss: 0.4639357626438141\n",
      "Step 1  Loss: 0.5143914222717285\n",
      "Step 2  Loss: 0.33656036853790283\n",
      "Step 3  Loss: 0.3063833713531494\n",
      "Step 4  Loss: 0.3846591114997864\n",
      "Step 5  Loss: 0.3806420564651489\n",
      "Step 6  Loss: 0.3481051027774811\n",
      "Step 7  Loss: 0.34462299942970276\n",
      "Step 8  Loss: 0.48619359731674194\n",
      "Step 9  Loss: 0.47223803400993347\n",
      "Step 10  Loss: 0.42739182710647583\n",
      "total Loss of epoch  90  is  4.465123653411865\n",
      "Step 0  Loss: 0.455576628446579\n",
      "Step 1  Loss: 0.46850183606147766\n",
      "Step 2  Loss: 0.43505194783210754\n",
      "Step 3  Loss: 0.42275238037109375\n",
      "Step 4  Loss: 0.4164334535598755\n",
      "Step 5  Loss: 0.3213077485561371\n",
      "Step 6  Loss: 0.43764713406562805\n",
      "Step 7  Loss: 0.473497599363327\n",
      "Step 8  Loss: 0.5061548352241516\n",
      "Step 9  Loss: 0.41900137066841125\n",
      "Step 10  Loss: 0.3799300491809845\n",
      "total Loss of epoch  91  is  4.735854983329773\n",
      "Step 0  Loss: 0.4951852560043335\n",
      "Step 1  Loss: 0.3203786015510559\n",
      "Step 2  Loss: 0.48691311478614807\n",
      "Step 3  Loss: 0.33917784690856934\n",
      "Step 4  Loss: 0.4059284031391144\n",
      "Step 5  Loss: 0.424595445394516\n",
      "Step 6  Loss: 0.43502727150917053\n",
      "Step 7  Loss: 0.3617795407772064\n",
      "Step 8  Loss: 0.41841205954551697\n",
      "Step 9  Loss: 0.44017598032951355\n",
      "Step 10  Loss: 0.2699134647846222\n",
      "total Loss of epoch  92  is  4.397486984729767\n",
      "Step 0  Loss: 0.38329243659973145\n",
      "Step 1  Loss: 0.32091444730758667\n",
      "Step 2  Loss: 0.43754860758781433\n",
      "Step 3  Loss: 0.46808069944381714\n",
      "Step 4  Loss: 0.48207202553749084\n",
      "Step 5  Loss: 0.44024741649627686\n",
      "Step 6  Loss: 0.41775673627853394\n",
      "Step 7  Loss: 0.37584877014160156\n",
      "Step 8  Loss: 0.42396876215934753\n",
      "Step 9  Loss: 0.3788156807422638\n",
      "Step 10  Loss: 0.44366776943206787\n",
      "total Loss of epoch  93  is  4.572213351726532\n",
      "Step 0  Loss: 0.44614437222480774\n",
      "Step 1  Loss: 0.3823312222957611\n",
      "Step 2  Loss: 0.515477180480957\n",
      "Step 3  Loss: 0.546495795249939\n",
      "Step 4  Loss: 0.5334920287132263\n",
      "Step 5  Loss: 0.4030669927597046\n",
      "Step 6  Loss: 0.35493770241737366\n",
      "Step 7  Loss: 0.395233154296875\n",
      "Step 8  Loss: 0.41547733545303345\n",
      "Step 9  Loss: 0.4489518404006958\n",
      "Step 10  Loss: 0.4900103211402893\n",
      "total Loss of epoch  94  is  4.931617945432663\n",
      "Step 0  Loss: 0.4173176884651184\n",
      "Step 1  Loss: 0.5956125259399414\n",
      "Step 2  Loss: 0.44269561767578125\n",
      "Step 3  Loss: 0.3257867097854614\n",
      "Step 4  Loss: 0.46276310086250305\n",
      "Step 5  Loss: 0.3607419729232788\n",
      "Step 6  Loss: 0.40420013666152954\n",
      "Step 7  Loss: 0.46721118688583374\n",
      "Step 8  Loss: 0.41632765531539917\n",
      "Step 9  Loss: 0.38311877846717834\n",
      "Step 10  Loss: 0.41650018095970154\n",
      "total Loss of epoch  95  is  4.692275553941727\n",
      "Step 0  Loss: 0.49098485708236694\n",
      "Step 1  Loss: 0.4041235148906708\n",
      "Step 2  Loss: 0.4213981032371521\n",
      "Step 3  Loss: 0.5293899178504944\n",
      "Step 4  Loss: 0.3315373957157135\n",
      "Step 5  Loss: 0.4598485827445984\n",
      "Step 6  Loss: 0.38321438431739807\n",
      "Step 7  Loss: 0.44928988814353943\n",
      "Step 8  Loss: 0.4352707862854004\n",
      "Step 9  Loss: 0.4572879672050476\n",
      "Step 10  Loss: 0.41645094752311707\n",
      "total Loss of epoch  96  is  4.778796344995499\n",
      "Step 0  Loss: 0.44807693362236023\n",
      "Step 1  Loss: 0.39876237511634827\n",
      "Step 2  Loss: 0.4471626281738281\n",
      "Step 3  Loss: 0.44990622997283936\n",
      "Step 4  Loss: 0.42057129740715027\n",
      "Step 5  Loss: 0.4339975416660309\n",
      "Step 6  Loss: 0.3998416066169739\n",
      "Step 7  Loss: 0.3063756227493286\n",
      "Step 8  Loss: 0.3353300392627716\n",
      "Step 9  Loss: 0.4481087923049927\n",
      "Step 10  Loss: 0.49878740310668945\n",
      "total Loss of epoch  97  is  4.586920469999313\n",
      "Step 0  Loss: 0.36531922221183777\n",
      "Step 1  Loss: 0.39148658514022827\n",
      "Step 2  Loss: 0.48876646161079407\n",
      "Step 3  Loss: 0.45913103222846985\n",
      "Step 4  Loss: 0.4391782283782959\n",
      "Step 5  Loss: 0.5014876127243042\n",
      "Step 6  Loss: 0.5088508725166321\n",
      "Step 7  Loss: 0.4398563504219055\n",
      "Step 8  Loss: 0.3861190378665924\n",
      "Step 9  Loss: 0.44948238134384155\n",
      "Step 10  Loss: 0.38492655754089355\n",
      "total Loss of epoch  98  is  4.814604341983795\n",
      "Step 0  Loss: 0.5214880108833313\n",
      "Step 1  Loss: 0.40277206897735596\n",
      "Step 2  Loss: 0.3008934259414673\n",
      "Step 3  Loss: 0.338566392660141\n",
      "Step 4  Loss: 0.44688794016838074\n",
      "Step 5  Loss: 0.48866066336631775\n",
      "Step 6  Loss: 0.4120917022228241\n",
      "Step 7  Loss: 0.4635013937950134\n",
      "Step 8  Loss: 0.5626193284988403\n",
      "Step 9  Loss: 0.4118965268135071\n",
      "Step 10  Loss: 0.517536997795105\n",
      "total Loss of epoch  99  is  4.866914451122284\n",
      "Step 0  Loss: 0.459481418132782\n",
      "Step 1  Loss: 0.3935950994491577\n",
      "Step 2  Loss: 0.3998948931694031\n",
      "Step 3  Loss: 0.4310436546802521\n",
      "Step 4  Loss: 0.40987318754196167\n",
      "Step 5  Loss: 0.4322384297847748\n",
      "Step 6  Loss: 0.306986927986145\n",
      "Step 7  Loss: 0.4842877984046936\n",
      "Step 8  Loss: 0.3956349194049835\n",
      "Step 9  Loss: 0.4013822376728058\n",
      "Step 10  Loss: 0.3301909863948822\n",
      "total Loss of epoch  100  is  4.444609552621841\n",
      "Step 0  Loss: 0.4155481159687042\n",
      "Step 1  Loss: 0.536872386932373\n",
      "Step 2  Loss: 0.4082663357257843\n",
      "Step 3  Loss: 0.47168195247650146\n",
      "Step 4  Loss: 0.3936764895915985\n",
      "Step 5  Loss: 0.4417060613632202\n",
      "Step 6  Loss: 0.44277191162109375\n",
      "Step 7  Loss: 0.3887782096862793\n",
      "Step 8  Loss: 0.5026980638504028\n",
      "Step 9  Loss: 0.5013675093650818\n",
      "Step 10  Loss: 0.37338021397590637\n",
      "total Loss of epoch  101  is  4.876747250556946\n",
      "Step 0  Loss: 0.5200538635253906\n",
      "Step 1  Loss: 0.3818904757499695\n",
      "Step 2  Loss: 0.46113720536231995\n",
      "Step 3  Loss: 0.4849211275577545\n",
      "Step 4  Loss: 0.43987181782722473\n",
      "Step 5  Loss: 0.46681734919548035\n",
      "Step 6  Loss: 0.3741689920425415\n",
      "Step 7  Loss: 0.41272637248039246\n",
      "Step 8  Loss: 0.2782377302646637\n",
      "Step 9  Loss: 0.373908132314682\n",
      "Step 10  Loss: 0.3729311525821686\n",
      "total Loss of epoch  102  is  4.566664218902588\n",
      "Step 0  Loss: 0.3975900411605835\n",
      "Step 1  Loss: 0.36396080255508423\n",
      "Step 2  Loss: 0.4057067632675171\n",
      "Step 3  Loss: 0.34330981969833374\n",
      "Step 4  Loss: 0.4295518696308136\n",
      "Step 5  Loss: 0.40501102805137634\n",
      "Step 6  Loss: 0.31320348381996155\n",
      "Step 7  Loss: 0.45479637384414673\n",
      "Step 8  Loss: 0.3298516571521759\n",
      "Step 9  Loss: 0.398110568523407\n",
      "Step 10  Loss: 0.4376824200153351\n",
      "total Loss of epoch  103  is  4.278774827718735\n",
      "Step 0  Loss: 0.40525034070014954\n",
      "Step 1  Loss: 0.4126153588294983\n",
      "Step 2  Loss: 0.24587075412273407\n",
      "Step 3  Loss: 0.3460317552089691\n",
      "Step 4  Loss: 0.3325005769729614\n",
      "Step 5  Loss: 0.44752976298332214\n",
      "Step 6  Loss: 0.4006059467792511\n",
      "Step 7  Loss: 0.5336039662361145\n",
      "Step 8  Loss: 0.41624999046325684\n",
      "Step 9  Loss: 0.40312865376472473\n",
      "Step 10  Loss: 0.5580883622169495\n",
      "total Loss of epoch  104  is  4.501475468277931\n",
      "Step 0  Loss: 0.5004200339317322\n",
      "Step 1  Loss: 0.4216573238372803\n",
      "Step 2  Loss: 0.3824591338634491\n",
      "Step 3  Loss: 0.4404558837413788\n",
      "Step 4  Loss: 0.5048069357872009\n",
      "Step 5  Loss: 0.3951531648635864\n",
      "Step 6  Loss: 0.3644123673439026\n",
      "Step 7  Loss: 0.48462873697280884\n",
      "Step 8  Loss: 0.4689832329750061\n",
      "Step 9  Loss: 0.4739525318145752\n",
      "Step 10  Loss: 0.47480061650276184\n",
      "total Loss of epoch  105  is  4.911729961633682\n",
      "Step 0  Loss: 0.3513213098049164\n",
      "Step 1  Loss: 0.32159754633903503\n",
      "Step 2  Loss: 0.3890993297100067\n",
      "Step 3  Loss: 0.5423933863639832\n",
      "Step 4  Loss: 0.49959295988082886\n",
      "Step 5  Loss: 0.3277532756328583\n",
      "Step 6  Loss: 0.3098120391368866\n",
      "Step 7  Loss: 0.4766656160354614\n",
      "Step 8  Loss: 0.5469168424606323\n",
      "Step 9  Loss: 0.30262771248817444\n",
      "Step 10  Loss: 0.30795156955718994\n",
      "total Loss of epoch  106  is  4.375731587409973\n",
      "Step 0  Loss: 0.4392458498477936\n",
      "Step 1  Loss: 0.3879896104335785\n",
      "Step 2  Loss: 0.3817855417728424\n",
      "Step 3  Loss: 0.4808163046836853\n",
      "Step 4  Loss: 0.25080469250679016\n",
      "Step 5  Loss: 0.43140262365341187\n",
      "Step 6  Loss: 0.3682763874530792\n",
      "Step 7  Loss: 0.4407947361469269\n",
      "Step 8  Loss: 0.3184089958667755\n",
      "Step 9  Loss: 0.4906288981437683\n",
      "Step 10  Loss: 0.4418344497680664\n",
      "total Loss of epoch  107  is  4.431988090276718\n",
      "Step 0  Loss: 0.3495675325393677\n",
      "Step 1  Loss: 0.41823866963386536\n",
      "Step 2  Loss: 0.39817509055137634\n",
      "Step 3  Loss: 0.4227876663208008\n",
      "Step 4  Loss: 0.395106703042984\n",
      "Step 5  Loss: 0.42168253660202026\n",
      "Step 6  Loss: 0.42788922786712646\n",
      "Step 7  Loss: 0.5135409235954285\n",
      "Step 8  Loss: 0.4537408649921417\n",
      "Step 9  Loss: 0.5458483695983887\n",
      "Step 10  Loss: 0.4148998260498047\n",
      "total Loss of epoch  108  is  4.761477410793304\n",
      "Step 0  Loss: 0.3974515199661255\n",
      "Step 1  Loss: 0.4413911998271942\n",
      "Step 2  Loss: 0.43240028619766235\n",
      "Step 3  Loss: 0.3535107970237732\n",
      "Step 4  Loss: 0.3072347939014435\n",
      "Step 5  Loss: 0.3769557476043701\n",
      "Step 6  Loss: 0.3921835720539093\n",
      "Step 7  Loss: 0.35704460740089417\n",
      "Step 8  Loss: 0.3101407289505005\n",
      "Step 9  Loss: 0.25797003507614136\n",
      "Step 10  Loss: 0.4722807705402374\n",
      "total Loss of epoch  109  is  4.098564058542252\n",
      "Step 0  Loss: 0.3971138596534729\n",
      "Step 1  Loss: 0.4311501383781433\n",
      "Step 2  Loss: 0.3575737178325653\n",
      "Step 3  Loss: 0.4485154151916504\n",
      "Step 4  Loss: 0.4368142783641815\n",
      "Step 5  Loss: 0.3831329047679901\n",
      "Step 6  Loss: 0.42990243434906006\n",
      "Step 7  Loss: 0.4964050352573395\n",
      "Step 8  Loss: 0.42349883913993835\n",
      "Step 9  Loss: 0.26517611742019653\n",
      "Step 10  Loss: 0.345913827419281\n",
      "total Loss of epoch  110  is  4.415196567773819\n",
      "Step 0  Loss: 0.45182856917381287\n",
      "Step 1  Loss: 0.5493636727333069\n",
      "Step 2  Loss: 0.4319698214530945\n",
      "Step 3  Loss: 0.31156113743782043\n",
      "Step 4  Loss: 0.4165068566799164\n",
      "Step 5  Loss: 0.4341771900653839\n",
      "Step 6  Loss: 0.4223257005214691\n",
      "Step 7  Loss: 0.3839592933654785\n",
      "Step 8  Loss: 0.437654048204422\n",
      "Step 9  Loss: 0.410232812166214\n",
      "Step 10  Loss: 0.3500196933746338\n",
      "total Loss of epoch  111  is  4.599598795175552\n",
      "Step 0  Loss: 0.44688230752944946\n",
      "Step 1  Loss: 0.4348926246166229\n",
      "Step 2  Loss: 0.4288352131843567\n",
      "Step 3  Loss: 0.43390166759490967\n",
      "Step 4  Loss: 0.32241225242614746\n",
      "Step 5  Loss: 0.5295443534851074\n",
      "Step 6  Loss: 0.38941022753715515\n",
      "Step 7  Loss: 0.38327860832214355\n",
      "Step 8  Loss: 0.47523078322410583\n",
      "Step 9  Loss: 0.33989855647087097\n",
      "Step 10  Loss: 0.5084304809570312\n",
      "total Loss of epoch  112  is  4.6927170753479\n",
      "Step 0  Loss: 0.4064055383205414\n",
      "Step 1  Loss: 0.32054147124290466\n",
      "Step 2  Loss: 0.4787384271621704\n",
      "Step 3  Loss: 0.3650626242160797\n",
      "Step 4  Loss: 0.3100215792655945\n",
      "Step 5  Loss: 0.4747546911239624\n",
      "Step 6  Loss: 0.4334842264652252\n",
      "Step 7  Loss: 0.3240847885608673\n",
      "Step 8  Loss: 0.2725915014743805\n",
      "Step 9  Loss: 0.4433484971523285\n",
      "Step 10  Loss: 0.564957857131958\n",
      "total Loss of epoch  113  is  4.393991202116013\n",
      "Step 0  Loss: 0.4346042573451996\n",
      "Step 1  Loss: 0.3484281301498413\n",
      "Step 2  Loss: 0.48498329520225525\n",
      "Step 3  Loss: 0.37993448972702026\n",
      "Step 4  Loss: 0.3740081489086151\n",
      "Step 5  Loss: 0.39551395177841187\n",
      "Step 6  Loss: 0.49459943175315857\n",
      "Step 7  Loss: 0.45021647214889526\n",
      "Step 8  Loss: 0.37500303983688354\n",
      "Step 9  Loss: 0.4915410876274109\n",
      "Step 10  Loss: 0.4733707904815674\n",
      "total Loss of epoch  114  is  4.702203094959259\n",
      "Step 0  Loss: 0.4197049140930176\n",
      "Step 1  Loss: 0.2637776732444763\n",
      "Step 2  Loss: 0.34677696228027344\n",
      "Step 3  Loss: 0.4033569395542145\n",
      "Step 4  Loss: 0.44219714403152466\n",
      "Step 5  Loss: 0.30219635367393494\n",
      "Step 6  Loss: 0.4002959430217743\n",
      "Step 7  Loss: 0.3660741448402405\n",
      "Step 8  Loss: 0.44939929246902466\n",
      "Step 9  Loss: 0.48000603914260864\n",
      "Step 10  Loss: 0.34952694177627563\n",
      "total Loss of epoch  115  is  4.223312348127365\n",
      "Step 0  Loss: 0.4678705632686615\n",
      "Step 1  Loss: 0.46633005142211914\n",
      "Step 2  Loss: 0.5158811211585999\n",
      "Step 3  Loss: 0.47192418575286865\n",
      "Step 4  Loss: 0.47850629687309265\n",
      "Step 5  Loss: 0.4694732427597046\n",
      "Step 6  Loss: 0.4164291322231293\n",
      "Step 7  Loss: 0.4178294241428375\n",
      "Step 8  Loss: 0.38573330640792847\n",
      "Step 9  Loss: 0.4772203862667084\n",
      "Step 10  Loss: 0.38060981035232544\n",
      "total Loss of epoch  116  is  4.9478075206279755\n",
      "Step 0  Loss: 0.42680180072784424\n",
      "Step 1  Loss: 0.4298535883426666\n",
      "Step 2  Loss: 0.37982895970344543\n",
      "Step 3  Loss: 0.29271161556243896\n",
      "Step 4  Loss: 0.388624370098114\n",
      "Step 5  Loss: 0.49653512239456177\n",
      "Step 6  Loss: 0.3969309628009796\n",
      "Step 7  Loss: 0.4251802861690521\n",
      "Step 8  Loss: 0.44287192821502686\n",
      "Step 9  Loss: 0.3895667791366577\n",
      "Step 10  Loss: 0.444014310836792\n",
      "total Loss of epoch  117  is  4.512919723987579\n",
      "Step 0  Loss: 0.3011796474456787\n",
      "Step 1  Loss: 0.3730306029319763\n",
      "Step 2  Loss: 0.42130202054977417\n",
      "Step 3  Loss: 0.3140902817249298\n",
      "Step 4  Loss: 0.5186401605606079\n",
      "Step 5  Loss: 0.3854620158672333\n",
      "Step 6  Loss: 0.2860379219055176\n",
      "Step 7  Loss: 0.3333042860031128\n",
      "Step 8  Loss: 0.3727733790874481\n",
      "Step 9  Loss: 0.3808051645755768\n",
      "Step 10  Loss: 0.6804829835891724\n",
      "total Loss of epoch  118  is  4.367108464241028\n",
      "Step 0  Loss: 0.3356952369213104\n",
      "Step 1  Loss: 0.5058909058570862\n",
      "Step 2  Loss: 0.38871556520462036\n",
      "Step 3  Loss: 0.4148455560207367\n",
      "Step 4  Loss: 0.38467463850975037\n",
      "Step 5  Loss: 0.3399708867073059\n",
      "Step 6  Loss: 0.4238578975200653\n",
      "Step 7  Loss: 0.45308634638786316\n",
      "Step 8  Loss: 0.5192107558250427\n",
      "Step 9  Loss: 0.4222617447376251\n",
      "Step 10  Loss: 0.3357364237308502\n",
      "total Loss of epoch  119  is  4.5239459574222565\n",
      "Step 0  Loss: 0.472888708114624\n",
      "Step 1  Loss: 0.4378802478313446\n",
      "Step 2  Loss: 0.4249846041202545\n",
      "Step 3  Loss: 0.507560133934021\n",
      "Step 4  Loss: 0.34611940383911133\n",
      "Step 5  Loss: 0.41975897550582886\n",
      "Step 6  Loss: 0.3540074825286865\n",
      "Step 7  Loss: 0.23853467404842377\n",
      "Step 8  Loss: 0.30464375019073486\n",
      "Step 9  Loss: 0.32056936621665955\n",
      "Step 10  Loss: 0.4051917493343353\n",
      "total Loss of epoch  120  is  4.232139095664024\n",
      "Step 0  Loss: 0.3652822971343994\n",
      "Step 1  Loss: 0.3863427937030792\n",
      "Step 2  Loss: 0.3052480220794678\n",
      "Step 3  Loss: 0.2914179265499115\n",
      "Step 4  Loss: 0.2755276560783386\n",
      "Step 5  Loss: 0.363625168800354\n",
      "Step 6  Loss: 0.40984711050987244\n",
      "Step 7  Loss: 0.45200690627098083\n",
      "Step 8  Loss: 0.37566325068473816\n",
      "Step 9  Loss: 0.3920084238052368\n",
      "Step 10  Loss: 0.5421720743179321\n",
      "total Loss of epoch  121  is  4.159141629934311\n",
      "Step 0  Loss: 0.40392521023750305\n",
      "Step 1  Loss: 0.4991346001625061\n",
      "Step 2  Loss: 0.33669859170913696\n",
      "Step 3  Loss: 0.3634902238845825\n",
      "Step 4  Loss: 0.3425227999687195\n",
      "Step 5  Loss: 0.4532144069671631\n",
      "Step 6  Loss: 0.38539355993270874\n",
      "Step 7  Loss: 0.3600844442844391\n",
      "Step 8  Loss: 0.3679889738559723\n",
      "Step 9  Loss: 0.3388357162475586\n",
      "Step 10  Loss: 0.39729124307632446\n",
      "total Loss of epoch  122  is  4.248579770326614\n",
      "Step 0  Loss: 0.5235108137130737\n",
      "Step 1  Loss: 0.41846880316734314\n",
      "Step 2  Loss: 0.3922117054462433\n",
      "Step 3  Loss: 0.34325823187828064\n",
      "Step 4  Loss: 0.42855721712112427\n",
      "Step 5  Loss: 0.37345996499061584\n",
      "Step 6  Loss: 0.3222023546695709\n",
      "Step 7  Loss: 0.4226475954055786\n",
      "Step 8  Loss: 0.5060200095176697\n",
      "Step 9  Loss: 0.3878052830696106\n",
      "Step 10  Loss: 0.28507375717163086\n",
      "total Loss of epoch  123  is  4.403215736150742\n",
      "Step 0  Loss: 0.40726718306541443\n",
      "Step 1  Loss: 0.5134028792381287\n",
      "Step 2  Loss: 0.40196698904037476\n",
      "Step 3  Loss: 0.3268994390964508\n",
      "Step 4  Loss: 0.43169036507606506\n",
      "Step 5  Loss: 0.3037334084510803\n",
      "Step 6  Loss: 0.3878832757472992\n",
      "Step 7  Loss: 0.5298247337341309\n",
      "Step 8  Loss: 0.39334648847579956\n",
      "Step 9  Loss: 0.4418121576309204\n",
      "Step 10  Loss: 0.4294387698173523\n",
      "total Loss of epoch  124  is  4.567265689373016\n",
      "Step 0  Loss: 0.4116394519805908\n",
      "Step 1  Loss: 0.34859463572502136\n",
      "Step 2  Loss: 0.37494319677352905\n",
      "Step 3  Loss: 0.3578327000141144\n",
      "Step 4  Loss: 0.413945734500885\n",
      "Step 5  Loss: 0.5409931540489197\n",
      "Step 6  Loss: 0.35092893242836\n",
      "Step 7  Loss: 0.36078372597694397\n",
      "Step 8  Loss: 0.36086952686309814\n",
      "Step 9  Loss: 0.4677707254886627\n",
      "Step 10  Loss: 0.4871060252189636\n",
      "total Loss of epoch  125  is  4.475407809019089\n",
      "Step 0  Loss: 0.4261064827442169\n",
      "Step 1  Loss: 0.38915207982063293\n",
      "Step 2  Loss: 0.3485126197338104\n",
      "Step 3  Loss: 0.4287469685077667\n",
      "Step 4  Loss: 0.49854639172554016\n",
      "Step 5  Loss: 0.5008219480514526\n",
      "Step 6  Loss: 0.4576127827167511\n",
      "Step 7  Loss: 0.3955644369125366\n",
      "Step 8  Loss: 0.4368651211261749\n",
      "Step 9  Loss: 0.3883233666419983\n",
      "Step 10  Loss: 0.41846737265586853\n",
      "total Loss of epoch  126  is  4.688719570636749\n",
      "Step 0  Loss: 0.48547327518463135\n",
      "Step 1  Loss: 0.34164801239967346\n",
      "Step 2  Loss: 0.4407515227794647\n",
      "Step 3  Loss: 0.3896232843399048\n",
      "Step 4  Loss: 0.3754105567932129\n",
      "Step 5  Loss: 0.4038573205471039\n",
      "Step 6  Loss: 0.37436625361442566\n",
      "Step 7  Loss: 0.29510578513145447\n",
      "Step 8  Loss: 0.4462239146232605\n",
      "Step 9  Loss: 0.3541005849838257\n",
      "Step 10  Loss: 0.3432232439517975\n",
      "total Loss of epoch  127  is  4.249783754348755\n",
      "Step 0  Loss: 0.40957188606262207\n",
      "Step 1  Loss: 0.41332435607910156\n",
      "Step 2  Loss: 0.4962120056152344\n",
      "Step 3  Loss: 0.4424259066581726\n",
      "Step 4  Loss: 0.41840121150016785\n",
      "Step 5  Loss: 0.3912152945995331\n",
      "Step 6  Loss: 0.31581398844718933\n",
      "Step 7  Loss: 0.4314540922641754\n",
      "Step 8  Loss: 0.44777917861938477\n",
      "Step 9  Loss: 0.3942330479621887\n",
      "Step 10  Loss: 0.4049152731895447\n",
      "total Loss of epoch  128  is  4.5653462409973145\n",
      "Step 0  Loss: 0.3177560567855835\n",
      "Step 1  Loss: 0.41868242621421814\n",
      "Step 2  Loss: 0.46675652265548706\n",
      "Step 3  Loss: 0.3915332853794098\n",
      "Step 4  Loss: 0.3318631649017334\n",
      "Step 5  Loss: 0.4587816298007965\n",
      "Step 6  Loss: 0.4227106273174286\n",
      "Step 7  Loss: 0.49726250767707825\n",
      "Step 8  Loss: 0.3471686840057373\n",
      "Step 9  Loss: 0.35509517788887024\n",
      "Step 10  Loss: 0.45334628224372864\n",
      "total Loss of epoch  129  is  4.460956364870071\n",
      "Step 0  Loss: 0.3312171697616577\n",
      "Step 1  Loss: 0.48490840196609497\n",
      "Step 2  Loss: 0.44863489270210266\n",
      "Step 3  Loss: 0.3683827519416809\n",
      "Step 4  Loss: 0.4424988031387329\n",
      "Step 5  Loss: 0.3022097051143646\n",
      "Step 6  Loss: 0.3564438223838806\n",
      "Step 7  Loss: 0.41235989332199097\n",
      "Step 8  Loss: 0.4665966033935547\n",
      "Step 9  Loss: 0.37428656220436096\n",
      "Step 10  Loss: 0.4860609769821167\n",
      "total Loss of epoch  130  is  4.473599582910538\n",
      "Step 0  Loss: 0.4734511077404022\n",
      "Step 1  Loss: 0.37658655643463135\n",
      "Step 2  Loss: 0.38904380798339844\n",
      "Step 3  Loss: 0.4671225845813751\n",
      "Step 4  Loss: 0.5630494356155396\n",
      "Step 5  Loss: 0.42635273933410645\n",
      "Step 6  Loss: 0.46231141686439514\n",
      "Step 7  Loss: 0.4839506447315216\n",
      "Step 8  Loss: 0.4802408218383789\n",
      "Step 9  Loss: 0.4130631685256958\n",
      "Step 10  Loss: 0.3445304036140442\n",
      "total Loss of epoch  131  is  4.879702687263489\n",
      "Step 0  Loss: 0.36480215191841125\n",
      "Step 1  Loss: 0.4817996919155121\n",
      "Step 2  Loss: 0.39412468671798706\n",
      "Step 3  Loss: 0.4729090631008148\n",
      "Step 4  Loss: 0.46277332305908203\n",
      "Step 5  Loss: 0.346537709236145\n",
      "Step 6  Loss: 0.43351200222969055\n",
      "Step 7  Loss: 0.4271775484085083\n",
      "Step 8  Loss: 0.45987650752067566\n",
      "Step 9  Loss: 0.3710499405860901\n",
      "Step 10  Loss: 0.2673106789588928\n",
      "total Loss of epoch  132  is  4.48187330365181\n",
      "Step 0  Loss: 0.4547622501850128\n",
      "Step 1  Loss: 0.45112523436546326\n",
      "Step 2  Loss: 0.41820648312568665\n",
      "Step 3  Loss: 0.4636019170284271\n",
      "Step 4  Loss: 0.3254534602165222\n",
      "Step 5  Loss: 0.42796948552131653\n",
      "Step 6  Loss: 0.4372759759426117\n",
      "Step 7  Loss: 0.5164121389389038\n",
      "Step 8  Loss: 0.4076722264289856\n",
      "Step 9  Loss: 0.3218059241771698\n",
      "Step 10  Loss: 0.4285534620285034\n",
      "total Loss of epoch  133  is  4.652838557958603\n",
      "Step 0  Loss: 0.3175555169582367\n",
      "Step 1  Loss: 0.34957247972488403\n",
      "Step 2  Loss: 0.3815145194530487\n",
      "Step 3  Loss: 0.42422518134117126\n",
      "Step 4  Loss: 0.4033968448638916\n",
      "Step 5  Loss: 0.4700496792793274\n",
      "Step 6  Loss: 0.4095357656478882\n",
      "Step 7  Loss: 0.31318604946136475\n",
      "Step 8  Loss: 0.4659700393676758\n",
      "Step 9  Loss: 0.5097606778144836\n",
      "Step 10  Loss: 0.4222922921180725\n",
      "total Loss of epoch  134  is  4.4670590460300446\n",
      "Step 0  Loss: 0.45183899998664856\n",
      "Step 1  Loss: 0.4048044979572296\n",
      "Step 2  Loss: 0.4779409170150757\n",
      "Step 3  Loss: 0.3275696337223053\n",
      "Step 4  Loss: 0.33190470933914185\n",
      "Step 5  Loss: 0.35666507482528687\n",
      "Step 6  Loss: 0.4744704067707062\n",
      "Step 7  Loss: 0.46456971764564514\n",
      "Step 8  Loss: 0.43419307470321655\n",
      "Step 9  Loss: 0.4278072416782379\n",
      "Step 10  Loss: 0.2674504518508911\n",
      "total Loss of epoch  135  is  4.419214725494385\n",
      "Step 0  Loss: 0.39927199482917786\n",
      "Step 1  Loss: 0.3274790048599243\n",
      "Step 2  Loss: 0.4187023937702179\n",
      "Step 3  Loss: 0.46885642409324646\n",
      "Step 4  Loss: 0.38910284638404846\n",
      "Step 5  Loss: 0.36156994104385376\n",
      "Step 6  Loss: 0.4474833905696869\n",
      "Step 7  Loss: 0.32223984599113464\n",
      "Step 8  Loss: 0.3768686354160309\n",
      "Step 9  Loss: 0.3410404324531555\n",
      "Step 10  Loss: 0.26682576537132263\n",
      "total Loss of epoch  136  is  4.119440674781799\n",
      "Step 0  Loss: 0.4024430513381958\n",
      "Step 1  Loss: 0.3792549967765808\n",
      "Step 2  Loss: 0.34808677434921265\n",
      "Step 3  Loss: 0.41639426350593567\n",
      "Step 4  Loss: 0.2961764931678772\n",
      "Step 5  Loss: 0.4254171550273895\n",
      "Step 6  Loss: 0.2946185767650604\n",
      "Step 7  Loss: 0.37277743220329285\n",
      "Step 8  Loss: 0.30966031551361084\n",
      "Step 9  Loss: 0.5221436023712158\n",
      "Step 10  Loss: 0.3371312916278839\n",
      "total Loss of epoch  137  is  4.1041039526462555\n",
      "Step 0  Loss: 0.4056223928928375\n",
      "Step 1  Loss: 0.4330660402774811\n",
      "Step 2  Loss: 0.4070929288864136\n",
      "Step 3  Loss: 0.44666826725006104\n",
      "Step 4  Loss: 0.5009498000144958\n",
      "Step 5  Loss: 0.38912078738212585\n",
      "Step 6  Loss: 0.24968761205673218\n",
      "Step 7  Loss: 0.4634327292442322\n",
      "Step 8  Loss: 0.4468139410018921\n",
      "Step 9  Loss: 0.5109901428222656\n",
      "Step 10  Loss: 0.3339897394180298\n",
      "total Loss of epoch  138  is  4.587434381246567\n",
      "Step 0  Loss: 0.3173994719982147\n",
      "Step 1  Loss: 0.36021196842193604\n",
      "Step 2  Loss: 0.45918500423431396\n",
      "Step 3  Loss: 0.44306060671806335\n",
      "Step 4  Loss: 0.5059000849723816\n",
      "Step 5  Loss: 0.2894577085971832\n",
      "Step 6  Loss: 0.4881042540073395\n",
      "Step 7  Loss: 0.5172734260559082\n",
      "Step 8  Loss: 0.38127362728118896\n",
      "Step 9  Loss: 0.41606757044792175\n",
      "Step 10  Loss: 0.49982529878616333\n",
      "total Loss of epoch  139  is  4.677759021520615\n",
      "Step 0  Loss: 0.43496549129486084\n",
      "Step 1  Loss: 0.36590060591697693\n",
      "Step 2  Loss: 0.3519093990325928\n",
      "Step 3  Loss: 0.36082419753074646\n",
      "Step 4  Loss: 0.3836204409599304\n",
      "Step 5  Loss: 0.4601154029369354\n",
      "Step 6  Loss: 0.3896021544933319\n",
      "Step 7  Loss: 0.38119858503341675\n",
      "Step 8  Loss: 0.36037132143974304\n",
      "Step 9  Loss: 0.2768348455429077\n",
      "Step 10  Loss: 0.39185017347335815\n",
      "total Loss of epoch  140  is  4.1571926176548\n",
      "Step 0  Loss: 0.33089524507522583\n",
      "Step 1  Loss: 0.4218067526817322\n",
      "Step 2  Loss: 0.40901634097099304\n",
      "Step 3  Loss: 0.4035130739212036\n",
      "Step 4  Loss: 0.44926556944847107\n",
      "Step 5  Loss: 0.44719159603118896\n",
      "Step 6  Loss: 0.4184846580028534\n",
      "Step 7  Loss: 0.39067932963371277\n",
      "Step 8  Loss: 0.37089240550994873\n",
      "Step 9  Loss: 0.43369659781455994\n",
      "Step 10  Loss: 0.4797321557998657\n",
      "total Loss of epoch  141  is  4.555173724889755\n",
      "Step 0  Loss: 0.34910306334495544\n",
      "Step 1  Loss: 0.4288376569747925\n",
      "Step 2  Loss: 0.43659406900405884\n",
      "Step 3  Loss: 0.4077836871147156\n",
      "Step 4  Loss: 0.37035778164863586\n",
      "Step 5  Loss: 0.4575885236263275\n",
      "Step 6  Loss: 0.42150983214378357\n",
      "Step 7  Loss: 0.4584929645061493\n",
      "Step 8  Loss: 0.4387293756008148\n",
      "Step 9  Loss: 0.3643878698348999\n",
      "Step 10  Loss: 0.44595012068748474\n",
      "total Loss of epoch  142  is  4.579334944486618\n",
      "Step 0  Loss: 0.4624565839767456\n",
      "Step 1  Loss: 0.3681388199329376\n",
      "Step 2  Loss: 0.21685351431369781\n",
      "Step 3  Loss: 0.4493619203567505\n",
      "Step 4  Loss: 0.2991204559803009\n",
      "Step 5  Loss: 0.4418953061103821\n",
      "Step 6  Loss: 0.3712652027606964\n",
      "Step 7  Loss: 0.46232256293296814\n",
      "Step 8  Loss: 0.29595452547073364\n",
      "Step 9  Loss: 0.41369393467903137\n",
      "Step 10  Loss: 0.3175049424171448\n",
      "total Loss of epoch  143  is  4.098567768931389\n",
      "Step 0  Loss: 0.3022802174091339\n",
      "Step 1  Loss: 0.43180450797080994\n",
      "Step 2  Loss: 0.5576937198638916\n",
      "Step 3  Loss: 0.45292168855667114\n",
      "Step 4  Loss: 0.3418380916118622\n",
      "Step 5  Loss: 0.5014014840126038\n",
      "Step 6  Loss: 0.42126959562301636\n",
      "Step 7  Loss: 0.3986194431781769\n",
      "Step 8  Loss: 0.31349194049835205\n",
      "Step 9  Loss: 0.4341099262237549\n",
      "Step 10  Loss: 0.3783700466156006\n",
      "total Loss of epoch  144  is  4.533800661563873\n",
      "Step 0  Loss: 0.45219525694847107\n",
      "Step 1  Loss: 0.40544894337654114\n",
      "Step 2  Loss: 0.3548195958137512\n",
      "Step 3  Loss: 0.2615692913532257\n",
      "Step 4  Loss: 0.4777959883213043\n",
      "Step 5  Loss: 0.3437681496143341\n",
      "Step 6  Loss: 0.48994746804237366\n",
      "Step 7  Loss: 0.2965390980243683\n",
      "Step 8  Loss: 0.44878026843070984\n",
      "Step 9  Loss: 0.33934804797172546\n",
      "Step 10  Loss: 0.28879809379577637\n",
      "total Loss of epoch  145  is  4.159010201692581\n",
      "Step 0  Loss: 0.4585736393928528\n",
      "Step 1  Loss: 0.40919652581214905\n",
      "Step 2  Loss: 0.46499428153038025\n",
      "Step 3  Loss: 0.3275371193885803\n",
      "Step 4  Loss: 0.45331820845603943\n",
      "Step 5  Loss: 0.5823500752449036\n",
      "Step 6  Loss: 0.4178595542907715\n",
      "Step 7  Loss: 0.31612253189086914\n",
      "Step 8  Loss: 0.46409618854522705\n",
      "Step 9  Loss: 0.3449479639530182\n",
      "Step 10  Loss: 0.3925217390060425\n",
      "total Loss of epoch  146  is  4.631517827510834\n",
      "Step 0  Loss: 0.3934035003185272\n",
      "Step 1  Loss: 0.3773576021194458\n",
      "Step 2  Loss: 0.3224443197250366\n",
      "Step 3  Loss: 0.40996405482292175\n",
      "Step 4  Loss: 0.4045543372631073\n",
      "Step 5  Loss: 0.3097590506076813\n",
      "Step 6  Loss: 0.4210827350616455\n",
      "Step 7  Loss: 0.340979665517807\n",
      "Step 8  Loss: 0.4092046022415161\n",
      "Step 9  Loss: 0.44342514872550964\n",
      "Step 10  Loss: 0.6202971339225769\n",
      "total Loss of epoch  147  is  4.452472150325775\n",
      "Step 0  Loss: 0.3481844365596771\n",
      "Step 1  Loss: 0.405683696269989\n",
      "Step 2  Loss: 0.38514554500579834\n",
      "Step 3  Loss: 0.2708875834941864\n",
      "Step 4  Loss: 0.4219718277454376\n",
      "Step 5  Loss: 0.27839112281799316\n",
      "Step 6  Loss: 0.29698821902275085\n",
      "Step 7  Loss: 0.38236624002456665\n",
      "Step 8  Loss: 0.45867684483528137\n",
      "Step 9  Loss: 0.47398099303245544\n",
      "Step 10  Loss: 0.3825702369213104\n",
      "total Loss of epoch  148  is  4.104846745729446\n",
      "Step 0  Loss: 0.3475184142589569\n",
      "Step 1  Loss: 0.32164937257766724\n",
      "Step 2  Loss: 0.37244004011154175\n",
      "Step 3  Loss: 0.38929739594459534\n",
      "Step 4  Loss: 0.4045296907424927\n",
      "Step 5  Loss: 0.3740915358066559\n",
      "Step 6  Loss: 0.3428603708744049\n",
      "Step 7  Loss: 0.3316064774990082\n",
      "Step 8  Loss: 0.4637691378593445\n",
      "Step 9  Loss: 0.3659130930900574\n",
      "Step 10  Loss: 0.20671136677265167\n",
      "total Loss of epoch  149  is  3.9203868955373764\n",
      "Step 0  Loss: 0.406648188829422\n",
      "Step 1  Loss: 0.31584492325782776\n",
      "Step 2  Loss: 0.37558576464653015\n",
      "Step 3  Loss: 0.33912065625190735\n",
      "Step 4  Loss: 0.33740007877349854\n",
      "Step 5  Loss: 0.42489075660705566\n",
      "Step 6  Loss: 0.368502676486969\n",
      "Step 7  Loss: 0.4375414550304413\n",
      "Step 8  Loss: 0.3971039354801178\n",
      "Step 9  Loss: 0.4736267328262329\n",
      "Step 10  Loss: 0.44092002511024475\n",
      "total Loss of epoch  150  is  4.317185193300247\n",
      "Step 0  Loss: 0.3701850473880768\n",
      "Step 1  Loss: 0.4209883511066437\n",
      "Step 2  Loss: 0.4494531452655792\n",
      "Step 3  Loss: 0.35121095180511475\n",
      "Step 4  Loss: 0.4032920002937317\n",
      "Step 5  Loss: 0.4721010625362396\n",
      "Step 6  Loss: 0.3605055510997772\n",
      "Step 7  Loss: 0.36160433292388916\n",
      "Step 8  Loss: 0.3365497589111328\n",
      "Step 9  Loss: 0.37295106053352356\n",
      "Step 10  Loss: 0.31797850131988525\n",
      "total Loss of epoch  151  is  4.216819763183594\n",
      "Step 0  Loss: 0.3407336175441742\n",
      "Step 1  Loss: 0.29003196954727173\n",
      "Step 2  Loss: 0.4346250593662262\n",
      "Step 3  Loss: 0.44781309366226196\n",
      "Step 4  Loss: 0.30554506182670593\n",
      "Step 5  Loss: 0.5002046823501587\n",
      "Step 6  Loss: 0.43684589862823486\n",
      "Step 7  Loss: 0.4826279282569885\n",
      "Step 8  Loss: 0.39700520038604736\n",
      "Step 9  Loss: 0.3407353162765503\n",
      "Step 10  Loss: 0.48534971475601196\n",
      "total Loss of epoch  152  is  4.461517542600632\n",
      "Step 0  Loss: 0.35854047536849976\n",
      "Step 1  Loss: 0.28926560282707214\n",
      "Step 2  Loss: 0.4817759096622467\n",
      "Step 3  Loss: 0.30238473415374756\n",
      "Step 4  Loss: 0.45757997035980225\n",
      "Step 5  Loss: 0.3727411925792694\n",
      "Step 6  Loss: 0.2265792042016983\n",
      "Step 7  Loss: 0.4274342358112335\n",
      "Step 8  Loss: 0.3817400336265564\n",
      "Step 9  Loss: 0.4783878028392792\n",
      "Step 10  Loss: 0.27442264556884766\n",
      "total Loss of epoch  153  is  4.050851806998253\n",
      "Step 0  Loss: 0.40824881196022034\n",
      "Step 1  Loss: 0.36421000957489014\n",
      "Step 2  Loss: 0.4461820125579834\n",
      "Step 3  Loss: 0.5031884908676147\n",
      "Step 4  Loss: 0.2908943295478821\n",
      "Step 5  Loss: 0.3896864950656891\n",
      "Step 6  Loss: 0.40716180205345154\n",
      "Step 7  Loss: 0.4516923725605011\n",
      "Step 8  Loss: 0.5514477491378784\n",
      "Step 9  Loss: 0.39381903409957886\n",
      "Step 10  Loss: 0.4142919182777405\n",
      "total Loss of epoch  154  is  4.62082302570343\n",
      "Step 0  Loss: 0.522610604763031\n",
      "Step 1  Loss: 0.40882009267807007\n",
      "Step 2  Loss: 0.3708961308002472\n",
      "Step 3  Loss: 0.38877975940704346\n",
      "Step 4  Loss: 0.3641093075275421\n",
      "Step 5  Loss: 0.3459950387477875\n",
      "Step 6  Loss: 0.50321364402771\n",
      "Step 7  Loss: 0.49907463788986206\n",
      "Step 8  Loss: 0.39399591088294983\n",
      "Step 9  Loss: 0.3692114055156708\n",
      "Step 10  Loss: 0.4364009499549866\n",
      "total Loss of epoch  155  is  4.6031074821949005\n",
      "Step 0  Loss: 0.4452855885028839\n",
      "Step 1  Loss: 0.35600095987319946\n",
      "Step 2  Loss: 0.42138075828552246\n",
      "Step 3  Loss: 0.25459030270576477\n",
      "Step 4  Loss: 0.3183862566947937\n",
      "Step 5  Loss: 0.3574937880039215\n",
      "Step 6  Loss: 0.41417673230171204\n",
      "Step 7  Loss: 0.3960482180118561\n",
      "Step 8  Loss: 0.4487181603908539\n",
      "Step 9  Loss: 0.33952394127845764\n",
      "Step 10  Loss: 0.17908604443073273\n",
      "total Loss of epoch  156  is  3.930690750479698\n",
      "Step 0  Loss: 0.33374348282814026\n",
      "Step 1  Loss: 0.450022429227829\n",
      "Step 2  Loss: 0.4664415121078491\n",
      "Step 3  Loss: 0.4057239890098572\n",
      "Step 4  Loss: 0.43363645672798157\n",
      "Step 5  Loss: 0.458333820104599\n",
      "Step 6  Loss: 0.40081602334976196\n",
      "Step 7  Loss: 0.3954096734523773\n",
      "Step 8  Loss: 0.36658018827438354\n",
      "Step 9  Loss: 0.43304115533828735\n",
      "Step 10  Loss: 0.3330210745334625\n",
      "total Loss of epoch  157  is  4.476769804954529\n",
      "Step 0  Loss: 0.398605614900589\n",
      "Step 1  Loss: 0.2911262810230255\n",
      "Step 2  Loss: 0.41162341833114624\n",
      "Step 3  Loss: 0.41826319694519043\n",
      "Step 4  Loss: 0.4001510739326477\n",
      "Step 5  Loss: 0.40794625878334045\n",
      "Step 6  Loss: 0.41755327582359314\n",
      "Step 7  Loss: 0.3467363119125366\n",
      "Step 8  Loss: 0.3880707025527954\n",
      "Step 9  Loss: 0.3138248324394226\n",
      "Step 10  Loss: 0.4079263508319855\n",
      "total Loss of epoch  158  is  4.201827317476273\n",
      "Step 0  Loss: 0.4354133605957031\n",
      "Step 1  Loss: 0.3142925500869751\n",
      "Step 2  Loss: 0.3766320049762726\n",
      "Step 3  Loss: 0.4828835129737854\n",
      "Step 4  Loss: 0.3429368734359741\n",
      "Step 5  Loss: 0.5018877387046814\n",
      "Step 6  Loss: 0.25858932733535767\n",
      "Step 7  Loss: 0.37805745005607605\n",
      "Step 8  Loss: 0.3441101312637329\n",
      "Step 9  Loss: 0.41781115531921387\n",
      "Step 10  Loss: 0.541420042514801\n",
      "total Loss of epoch  159  is  4.394034147262573\n",
      "Step 0  Loss: 0.37755414843559265\n",
      "Step 1  Loss: 0.42031610012054443\n",
      "Step 2  Loss: 0.461213618516922\n",
      "Step 3  Loss: 0.3526235520839691\n",
      "Step 4  Loss: 0.3375571072101593\n",
      "Step 5  Loss: 0.45993268489837646\n",
      "Step 6  Loss: 0.40278375148773193\n",
      "Step 7  Loss: 0.32140016555786133\n",
      "Step 8  Loss: 0.4107309877872467\n",
      "Step 9  Loss: 0.3627246916294098\n",
      "Step 10  Loss: 0.4443046450614929\n",
      "total Loss of epoch  160  is  4.351141452789307\n",
      "Step 0  Loss: 0.41605910658836365\n",
      "Step 1  Loss: 0.3681856393814087\n",
      "Step 2  Loss: 0.2692757546901703\n",
      "Step 3  Loss: 0.42249995470046997\n",
      "Step 4  Loss: 0.37956544756889343\n",
      "Step 5  Loss: 0.44027483463287354\n",
      "Step 6  Loss: 0.2177893966436386\n",
      "Step 7  Loss: 0.5103206634521484\n",
      "Step 8  Loss: 0.3577291965484619\n",
      "Step 9  Loss: 0.4104202389717102\n",
      "Step 10  Loss: 0.2584080696105957\n",
      "total Loss of epoch  161  is  4.050528302788734\n",
      "Step 0  Loss: 0.4714714288711548\n",
      "Step 1  Loss: 0.35455021262168884\n",
      "Step 2  Loss: 0.34456416964530945\n",
      "Step 3  Loss: 0.4266170263290405\n",
      "Step 4  Loss: 0.47737425565719604\n",
      "Step 5  Loss: 0.46821820735931396\n",
      "Step 6  Loss: 0.3328261077404022\n",
      "Step 7  Loss: 0.3848211467266083\n",
      "Step 8  Loss: 0.3966502249240875\n",
      "Step 9  Loss: 0.439114511013031\n",
      "Step 10  Loss: 0.39080843329429626\n",
      "total Loss of epoch  162  is  4.487015724182129\n",
      "Step 0  Loss: 0.4557573199272156\n",
      "Step 1  Loss: 0.3974301815032959\n",
      "Step 2  Loss: 0.4396182596683502\n",
      "Step 3  Loss: 0.35797208547592163\n",
      "Step 4  Loss: 0.38189929723739624\n",
      "Step 5  Loss: 0.3996897041797638\n",
      "Step 6  Loss: 0.37210768461227417\n",
      "Step 7  Loss: 0.38275638222694397\n",
      "Step 8  Loss: 0.5066523551940918\n",
      "Step 9  Loss: 0.38639137148857117\n",
      "Step 10  Loss: 0.4761940538883209\n",
      "total Loss of epoch  163  is  4.556468695402145\n",
      "Step 0  Loss: 0.2152584046125412\n",
      "Step 1  Loss: 0.36258482933044434\n",
      "Step 2  Loss: 0.40059414505958557\n",
      "Step 3  Loss: 0.46188047528266907\n",
      "Step 4  Loss: 0.47672000527381897\n",
      "Step 5  Loss: 0.28398004174232483\n",
      "Step 6  Loss: 0.414874792098999\n",
      "Step 7  Loss: 0.45781415700912476\n",
      "Step 8  Loss: 0.430649071931839\n",
      "Step 9  Loss: 0.4220823049545288\n",
      "Step 10  Loss: 0.41800886392593384\n",
      "total Loss of epoch  164  is  4.344447091221809\n",
      "Step 0  Loss: 0.3404065668582916\n",
      "Step 1  Loss: 0.4116857349872589\n",
      "Step 2  Loss: 0.33874109387397766\n",
      "Step 3  Loss: 0.4255909323692322\n",
      "Step 4  Loss: 0.3997379541397095\n",
      "Step 5  Loss: 0.27933868765830994\n",
      "Step 6  Loss: 0.295990914106369\n",
      "Step 7  Loss: 0.3792504668235779\n",
      "Step 8  Loss: 0.3645693361759186\n",
      "Step 9  Loss: 0.43855398893356323\n",
      "Step 10  Loss: 0.44299307465553284\n",
      "total Loss of epoch  165  is  4.116858750581741\n",
      "Step 0  Loss: 0.34066593647003174\n",
      "Step 1  Loss: 0.29014238715171814\n",
      "Step 2  Loss: 0.33207786083221436\n",
      "Step 3  Loss: 0.42863166332244873\n",
      "Step 4  Loss: 0.42736920714378357\n",
      "Step 5  Loss: 0.3743102252483368\n",
      "Step 6  Loss: 0.3500484526157379\n",
      "Step 7  Loss: 0.3018651604652405\n",
      "Step 8  Loss: 0.24515105783939362\n",
      "Step 9  Loss: 0.4113168716430664\n",
      "Step 10  Loss: 0.4952777922153473\n",
      "total Loss of epoch  166  is  3.996856614947319\n",
      "Step 0  Loss: 0.35609737038612366\n",
      "Step 1  Loss: 0.42370450496673584\n",
      "Step 2  Loss: 0.3386308252811432\n",
      "Step 3  Loss: 0.39588335156440735\n",
      "Step 4  Loss: 0.38311466574668884\n",
      "Step 5  Loss: 0.3714528977870941\n",
      "Step 6  Loss: 0.3097919225692749\n",
      "Step 7  Loss: 0.30920013785362244\n",
      "Step 8  Loss: 0.43881547451019287\n",
      "Step 9  Loss: 0.49830371141433716\n",
      "Step 10  Loss: 0.3089771866798401\n",
      "total Loss of epoch  167  is  4.1339720487594604\n",
      "Step 0  Loss: 0.3439289927482605\n",
      "Step 1  Loss: 0.4107053279876709\n",
      "Step 2  Loss: 0.30241110920906067\n",
      "Step 3  Loss: 0.38642194867134094\n",
      "Step 4  Loss: 0.33099356293678284\n",
      "Step 5  Loss: 0.33316004276275635\n",
      "Step 6  Loss: 0.3869483768939972\n",
      "Step 7  Loss: 0.2927792966365814\n",
      "Step 8  Loss: 0.3102031946182251\n",
      "Step 9  Loss: 0.4776866137981415\n",
      "Step 10  Loss: 0.48112931847572327\n",
      "total Loss of epoch  168  is  4.056367784738541\n",
      "Step 0  Loss: 0.2892545163631439\n",
      "Step 1  Loss: 0.46970492601394653\n",
      "Step 2  Loss: 0.39762261509895325\n",
      "Step 3  Loss: 0.3747114837169647\n",
      "Step 4  Loss: 0.452094167470932\n",
      "Step 5  Loss: 0.3075858950614929\n",
      "Step 6  Loss: 0.42914751172065735\n",
      "Step 7  Loss: 0.4299648106098175\n",
      "Step 8  Loss: 0.39078718423843384\n",
      "Step 9  Loss: 0.3763084411621094\n",
      "Step 10  Loss: 0.4338208734989166\n",
      "total Loss of epoch  169  is  4.351002424955368\n",
      "Step 0  Loss: 0.3166690468788147\n",
      "Step 1  Loss: 0.25032997131347656\n",
      "Step 2  Loss: 0.3332158327102661\n",
      "Step 3  Loss: 0.3053521513938904\n",
      "Step 4  Loss: 0.41997769474983215\n",
      "Step 5  Loss: 0.37500742077827454\n",
      "Step 6  Loss: 0.3707934617996216\n",
      "Step 7  Loss: 0.49781057238578796\n",
      "Step 8  Loss: 0.32785889506340027\n",
      "Step 9  Loss: 0.42275264859199524\n",
      "Step 10  Loss: 0.3602094054222107\n",
      "total Loss of epoch  170  is  3.97997710108757\n",
      "Step 0  Loss: 0.2590087354183197\n",
      "Step 1  Loss: 0.47316691279411316\n",
      "Step 2  Loss: 0.41457441449165344\n",
      "Step 3  Loss: 0.4503123462200165\n",
      "Step 4  Loss: 0.40476900339126587\n",
      "Step 5  Loss: 0.5326163172721863\n",
      "Step 6  Loss: 0.41255566477775574\n",
      "Step 7  Loss: 0.41029107570648193\n",
      "Step 8  Loss: 0.5003713965415955\n",
      "Step 9  Loss: 0.25095435976982117\n",
      "Step 10  Loss: 0.4250483810901642\n",
      "total Loss of epoch  171  is  4.533668607473373\n",
      "Step 0  Loss: 0.2912815809249878\n",
      "Step 1  Loss: 0.3088577091693878\n",
      "Step 2  Loss: 0.35788193345069885\n",
      "Step 3  Loss: 0.5020204782485962\n",
      "Step 4  Loss: 0.44910699129104614\n",
      "Step 5  Loss: 0.4314444959163666\n",
      "Step 6  Loss: 0.36332786083221436\n",
      "Step 7  Loss: 0.37935692071914673\n",
      "Step 8  Loss: 0.44712623953819275\n",
      "Step 9  Loss: 0.48803094029426575\n",
      "Step 10  Loss: 0.41634783148765564\n",
      "total Loss of epoch  172  is  4.434782981872559\n",
      "Step 0  Loss: 0.3594707250595093\n",
      "Step 1  Loss: 0.4559953212738037\n",
      "Step 2  Loss: 0.3354906737804413\n",
      "Step 3  Loss: 0.46222740411758423\n",
      "Step 4  Loss: 0.32369720935821533\n",
      "Step 5  Loss: 0.4651912450790405\n",
      "Step 6  Loss: 0.29186224937438965\n",
      "Step 7  Loss: 0.37608975172042847\n",
      "Step 8  Loss: 0.4268869161605835\n",
      "Step 9  Loss: 0.35088834166526794\n",
      "Step 10  Loss: 0.2682994306087494\n",
      "total Loss of epoch  173  is  4.116099268198013\n",
      "Step 0  Loss: 0.41825711727142334\n",
      "Step 1  Loss: 0.1708722710609436\n",
      "Step 2  Loss: 0.32294684648513794\n",
      "Step 3  Loss: 0.4060690104961395\n",
      "Step 4  Loss: 0.3858742117881775\n",
      "Step 5  Loss: 0.377462238073349\n",
      "Step 6  Loss: 0.3036378026008606\n",
      "Step 7  Loss: 0.29183945059776306\n",
      "Step 8  Loss: 0.3331134021282196\n",
      "Step 9  Loss: 0.39181050658226013\n",
      "Step 10  Loss: 0.33827048540115356\n",
      "total Loss of epoch  174  is  3.740153342485428\n",
      "Step 0  Loss: 0.44977250695228577\n",
      "Step 1  Loss: 0.38649365305900574\n",
      "Step 2  Loss: 0.27801090478897095\n",
      "Step 3  Loss: 0.3311771750450134\n",
      "Step 4  Loss: 0.41359952092170715\n",
      "Step 5  Loss: 0.37444841861724854\n",
      "Step 6  Loss: 0.32958948612213135\n",
      "Step 7  Loss: 0.45190560817718506\n",
      "Step 8  Loss: 0.32656872272491455\n",
      "Step 9  Loss: 0.3764552175998688\n",
      "Step 10  Loss: 0.42699941992759705\n",
      "total Loss of epoch  175  is  4.145020633935928\n",
      "Step 0  Loss: 0.36226800084114075\n",
      "Step 1  Loss: 0.42609041929244995\n",
      "Step 2  Loss: 0.3637683689594269\n",
      "Step 3  Loss: 0.44080695509910583\n",
      "Step 4  Loss: 0.3397115468978882\n",
      "Step 5  Loss: 0.5046714544296265\n",
      "Step 6  Loss: 0.3749793469905853\n",
      "Step 7  Loss: 0.42067810893058777\n",
      "Step 8  Loss: 0.3535080552101135\n",
      "Step 9  Loss: 0.34219810366630554\n",
      "Step 10  Loss: 0.4688844382762909\n",
      "total Loss of epoch  176  is  4.397564798593521\n",
      "Step 0  Loss: 0.3844204545021057\n",
      "Step 1  Loss: 0.41538044810295105\n",
      "Step 2  Loss: 0.3261334002017975\n",
      "Step 3  Loss: 0.28766000270843506\n",
      "Step 4  Loss: 0.40444257855415344\n",
      "Step 5  Loss: 0.3490806818008423\n",
      "Step 6  Loss: 0.4276346266269684\n",
      "Step 7  Loss: 0.3885915279388428\n",
      "Step 8  Loss: 0.42517054080963135\n",
      "Step 9  Loss: 0.43021148443222046\n",
      "Step 10  Loss: 0.2857562303543091\n",
      "total Loss of epoch  177  is  4.124481976032257\n",
      "Step 0  Loss: 0.4421823024749756\n",
      "Step 1  Loss: 0.4609610140323639\n",
      "Step 2  Loss: 0.3698141872882843\n",
      "Step 3  Loss: 0.3905586898326874\n",
      "Step 4  Loss: 0.405892014503479\n",
      "Step 5  Loss: 0.3851144313812256\n",
      "Step 6  Loss: 0.35341572761535645\n",
      "Step 7  Loss: 0.29814571142196655\n",
      "Step 8  Loss: 0.4791564643383026\n",
      "Step 9  Loss: 0.34824615716934204\n",
      "Step 10  Loss: 0.4022625982761383\n",
      "total Loss of epoch  178  is  4.335749298334122\n",
      "Step 0  Loss: 0.3788183331489563\n",
      "Step 1  Loss: 0.36635822057724\n",
      "Step 2  Loss: 0.36712968349456787\n",
      "Step 3  Loss: 0.3737596571445465\n",
      "Step 4  Loss: 0.24634599685668945\n",
      "Step 5  Loss: 0.3019697070121765\n",
      "Step 6  Loss: 0.3155871331691742\n",
      "Step 7  Loss: 0.41203397512435913\n",
      "Step 8  Loss: 0.35863739252090454\n",
      "Step 9  Loss: 0.4572981894016266\n",
      "Step 10  Loss: 0.49481141567230225\n",
      "total Loss of epoch  179  is  4.072749704122543\n",
      "Step 0  Loss: 0.40488582849502563\n",
      "Step 1  Loss: 0.43634337186813354\n",
      "Step 2  Loss: 0.3235740065574646\n",
      "Step 3  Loss: 0.37401866912841797\n",
      "Step 4  Loss: 0.4438386857509613\n",
      "Step 5  Loss: 0.4317219853401184\n",
      "Step 6  Loss: 0.48792901635169983\n",
      "Step 7  Loss: 0.36289170384407043\n",
      "Step 8  Loss: 0.318194717168808\n",
      "Step 9  Loss: 0.3324432969093323\n",
      "Step 10  Loss: 0.30344682931900024\n",
      "total Loss of epoch  180  is  4.219288110733032\n",
      "Step 0  Loss: 0.4367983639240265\n",
      "Step 1  Loss: 0.4033282399177551\n",
      "Step 2  Loss: 0.2948971390724182\n",
      "Step 3  Loss: 0.35572898387908936\n",
      "Step 4  Loss: 0.28623995184898376\n",
      "Step 5  Loss: 0.31376180052757263\n",
      "Step 6  Loss: 0.39495712518692017\n",
      "Step 7  Loss: 0.36277633905410767\n",
      "Step 8  Loss: 0.3561772108078003\n",
      "Step 9  Loss: 0.43559086322784424\n",
      "Step 10  Loss: 0.3988818824291229\n",
      "total Loss of epoch  181  is  4.039137899875641\n",
      "Step 0  Loss: 0.3603478968143463\n",
      "Step 1  Loss: 0.37240898609161377\n",
      "Step 2  Loss: 0.3353922963142395\n",
      "Step 3  Loss: 0.44810518622398376\n",
      "Step 4  Loss: 0.3684912919998169\n",
      "Step 5  Loss: 0.400347501039505\n",
      "Step 6  Loss: 0.40676257014274597\n",
      "Step 7  Loss: 0.39802590012550354\n",
      "Step 8  Loss: 0.4920823574066162\n",
      "Step 9  Loss: 0.40468862652778625\n",
      "Step 10  Loss: 0.3578709065914154\n",
      "total Loss of epoch  182  is  4.344523519277573\n",
      "Step 0  Loss: 0.36536023020744324\n",
      "Step 1  Loss: 0.33122822642326355\n",
      "Step 2  Loss: 0.48060840368270874\n",
      "Step 3  Loss: 0.39372795820236206\n",
      "Step 4  Loss: 0.3266719579696655\n",
      "Step 5  Loss: 0.4200921952724457\n",
      "Step 6  Loss: 0.3112744688987732\n",
      "Step 7  Loss: 0.4304104447364807\n",
      "Step 8  Loss: 0.3379911184310913\n",
      "Step 9  Loss: 0.5077811479568481\n",
      "Step 10  Loss: 0.36550143361091614\n",
      "total Loss of epoch  183  is  4.270647585391998\n",
      "Step 0  Loss: 0.3513481020927429\n",
      "Step 1  Loss: 0.43896257877349854\n",
      "Step 2  Loss: 0.26387569308280945\n",
      "Step 3  Loss: 0.3188823461532593\n",
      "Step 4  Loss: 0.4790838062763214\n",
      "Step 5  Loss: 0.292776882648468\n",
      "Step 6  Loss: 0.319396048784256\n",
      "Step 7  Loss: 0.3143708109855652\n",
      "Step 8  Loss: 0.35710594058036804\n",
      "Step 9  Loss: 0.40255123376846313\n",
      "Step 10  Loss: 0.34617704153060913\n",
      "total Loss of epoch  184  is  3.884530484676361\n",
      "Step 0  Loss: 0.374545156955719\n",
      "Step 1  Loss: 0.32890796661376953\n",
      "Step 2  Loss: 0.5076766014099121\n",
      "Step 3  Loss: 0.4333724081516266\n",
      "Step 4  Loss: 0.2804768681526184\n",
      "Step 5  Loss: 0.41219907999038696\n",
      "Step 6  Loss: 0.3650359809398651\n",
      "Step 7  Loss: 0.37498152256011963\n",
      "Step 8  Loss: 0.4728122651576996\n",
      "Step 9  Loss: 0.3369893431663513\n",
      "Step 10  Loss: 0.4611165523529053\n",
      "total Loss of epoch  185  is  4.3481137454509735\n",
      "Step 0  Loss: 0.490103542804718\n",
      "Step 1  Loss: 0.4441770613193512\n",
      "Step 2  Loss: 0.5576052665710449\n",
      "Step 3  Loss: 0.48514774441719055\n",
      "Step 4  Loss: 0.4131496548652649\n",
      "Step 5  Loss: 0.4956863224506378\n",
      "Step 6  Loss: 0.33706197142601013\n",
      "Step 7  Loss: 0.44802558422088623\n",
      "Step 8  Loss: 0.4675755500793457\n",
      "Step 9  Loss: 0.4463796019554138\n",
      "Step 10  Loss: 0.3540978729724884\n",
      "total Loss of epoch  186  is  4.939010173082352\n",
      "Step 0  Loss: 0.4257369339466095\n",
      "Step 1  Loss: 0.36793389916419983\n",
      "Step 2  Loss: 0.4042370319366455\n",
      "Step 3  Loss: 0.33232349157333374\n",
      "Step 4  Loss: 0.3676910400390625\n",
      "Step 5  Loss: 0.3720385730266571\n",
      "Step 6  Loss: 0.3893476128578186\n",
      "Step 7  Loss: 0.3546803593635559\n",
      "Step 8  Loss: 0.3961784243583679\n",
      "Step 9  Loss: 0.4544772803783417\n",
      "Step 10  Loss: 0.32400959730148315\n",
      "total Loss of epoch  187  is  4.188654243946075\n",
      "Step 0  Loss: 0.43577438592910767\n",
      "Step 1  Loss: 0.3286401331424713\n",
      "Step 2  Loss: 0.32514670491218567\n",
      "Step 3  Loss: 0.39639100432395935\n",
      "Step 4  Loss: 0.3794637620449066\n",
      "Step 5  Loss: 0.3826184868812561\n",
      "Step 6  Loss: 0.47765305638313293\n",
      "Step 7  Loss: 0.3918169438838959\n",
      "Step 8  Loss: 0.4684631824493408\n",
      "Step 9  Loss: 0.3107425570487976\n",
      "Step 10  Loss: 0.3863215148448944\n",
      "total Loss of epoch  188  is  4.283031731843948\n",
      "Step 0  Loss: 0.3924585282802582\n",
      "Step 1  Loss: 0.3723439574241638\n",
      "Step 2  Loss: 0.35460010170936584\n",
      "Step 3  Loss: 0.5115698575973511\n",
      "Step 4  Loss: 0.37588414549827576\n",
      "Step 5  Loss: 0.3704228699207306\n",
      "Step 6  Loss: 0.33680257201194763\n",
      "Step 7  Loss: 0.35515275597572327\n",
      "Step 8  Loss: 0.4298967719078064\n",
      "Step 9  Loss: 0.3383443355560303\n",
      "Step 10  Loss: 0.3789002597332001\n",
      "total Loss of epoch  189  is  4.216376155614853\n",
      "Step 0  Loss: 0.34355413913726807\n",
      "Step 1  Loss: 0.341590017080307\n",
      "Step 2  Loss: 0.3117290735244751\n",
      "Step 3  Loss: 0.35304781794548035\n",
      "Step 4  Loss: 0.4502386152744293\n",
      "Step 5  Loss: 0.4571685791015625\n",
      "Step 6  Loss: 0.35913771390914917\n",
      "Step 7  Loss: 0.3304761052131653\n",
      "Step 8  Loss: 0.34481075406074524\n",
      "Step 9  Loss: 0.4174068570137024\n",
      "Step 10  Loss: 0.4419260621070862\n",
      "total Loss of epoch  190  is  4.151085734367371\n",
      "Step 0  Loss: 0.24676495790481567\n",
      "Step 1  Loss: 0.3844393193721771\n",
      "Step 2  Loss: 0.4367600679397583\n",
      "Step 3  Loss: 0.38586029410362244\n",
      "Step 4  Loss: 0.39130377769470215\n",
      "Step 5  Loss: 0.38601669669151306\n",
      "Step 6  Loss: 0.4776577353477478\n",
      "Step 7  Loss: 0.4479057192802429\n",
      "Step 8  Loss: 0.43053507804870605\n",
      "Step 9  Loss: 0.37446343898773193\n",
      "Step 10  Loss: 0.3239913284778595\n",
      "total Loss of epoch  191  is  4.285698413848877\n",
      "Step 0  Loss: 0.32347458600997925\n",
      "Step 1  Loss: 0.3274105489253998\n",
      "Step 2  Loss: 0.382623553276062\n",
      "Step 3  Loss: 0.24035830795764923\n",
      "Step 4  Loss: 0.26084190607070923\n",
      "Step 5  Loss: 0.2880101799964905\n",
      "Step 6  Loss: 0.3413868546485901\n",
      "Step 7  Loss: 0.4486892521381378\n",
      "Step 8  Loss: 0.4762699007987976\n",
      "Step 9  Loss: 0.3383423089981079\n",
      "Step 10  Loss: 0.361349493265152\n",
      "total Loss of epoch  192  is  3.7887568920850754\n",
      "Step 0  Loss: 0.4194352924823761\n",
      "Step 1  Loss: 0.3483651280403137\n",
      "Step 2  Loss: 0.38968178629875183\n",
      "Step 3  Loss: 0.38014042377471924\n",
      "Step 4  Loss: 0.4748428165912628\n",
      "Step 5  Loss: 0.45425570011138916\n",
      "Step 6  Loss: 0.3671662211418152\n",
      "Step 7  Loss: 0.3827231228351593\n",
      "Step 8  Loss: 0.35839584469795227\n",
      "Step 9  Loss: 0.46556606888771057\n",
      "Step 10  Loss: 0.33303532004356384\n",
      "total Loss of epoch  193  is  4.373607724905014\n",
      "Step 0  Loss: 0.4320451319217682\n",
      "Step 1  Loss: 0.3691118657588959\n",
      "Step 2  Loss: 0.372854083776474\n",
      "Step 3  Loss: 0.46881476044654846\n",
      "Step 4  Loss: 0.3758714497089386\n",
      "Step 5  Loss: 0.42513307929039\n",
      "Step 6  Loss: 0.4190402328968048\n",
      "Step 7  Loss: 0.31424668431282043\n",
      "Step 8  Loss: 0.3518262803554535\n",
      "Step 9  Loss: 0.3770853281021118\n",
      "Step 10  Loss: 0.25617456436157227\n",
      "total Loss of epoch  194  is  4.162203460931778\n",
      "Step 0  Loss: 0.27761775255203247\n",
      "Step 1  Loss: 0.39676904678344727\n",
      "Step 2  Loss: 0.4310903549194336\n",
      "Step 3  Loss: 0.4696671962738037\n",
      "Step 4  Loss: 0.38583678007125854\n",
      "Step 5  Loss: 0.35555604100227356\n",
      "Step 6  Loss: 0.4235205054283142\n",
      "Step 7  Loss: 0.4644293487071991\n",
      "Step 8  Loss: 0.3967626094818115\n",
      "Step 9  Loss: 0.29736000299453735\n",
      "Step 10  Loss: 0.505704402923584\n",
      "total Loss of epoch  195  is  4.404314041137695\n",
      "Step 0  Loss: 0.43463125824928284\n",
      "Step 1  Loss: 0.42288684844970703\n",
      "Step 2  Loss: 0.39514148235321045\n",
      "Step 3  Loss: 0.4134710133075714\n",
      "Step 4  Loss: 0.227512389421463\n",
      "Step 5  Loss: 0.33621689677238464\n",
      "Step 6  Loss: 0.32857972383499146\n",
      "Step 7  Loss: 0.3368554711341858\n",
      "Step 8  Loss: 0.2854840159416199\n",
      "Step 9  Loss: 0.41443273425102234\n",
      "Step 10  Loss: 0.30123141407966614\n",
      "total Loss of epoch  196  is  3.896443247795105\n",
      "Step 0  Loss: 0.37442710995674133\n",
      "Step 1  Loss: 0.28545308113098145\n",
      "Step 2  Loss: 0.32675445079803467\n",
      "Step 3  Loss: 0.4278384745121002\n",
      "Step 4  Loss: 0.30687060952186584\n",
      "Step 5  Loss: 0.3560739755630493\n",
      "Step 6  Loss: 0.44973981380462646\n",
      "Step 7  Loss: 0.4199199676513672\n",
      "Step 8  Loss: 0.49783816933631897\n",
      "Step 9  Loss: 0.4118953347206116\n",
      "Step 10  Loss: 0.4209703207015991\n",
      "total Loss of epoch  197  is  4.277781307697296\n",
      "Step 0  Loss: 0.37763890624046326\n",
      "Step 1  Loss: 0.3929588198661804\n",
      "Step 2  Loss: 0.31875115633010864\n",
      "Step 3  Loss: 0.26656821370124817\n",
      "Step 4  Loss: 0.3039975166320801\n",
      "Step 5  Loss: 0.5060376524925232\n",
      "Step 6  Loss: 0.43190112709999084\n",
      "Step 7  Loss: 0.4100847542285919\n",
      "Step 8  Loss: 0.4014388620853424\n",
      "Step 9  Loss: 0.393402099609375\n",
      "Step 10  Loss: 0.3277233839035034\n",
      "total Loss of epoch  198  is  4.130502492189407\n",
      "Step 0  Loss: 0.5216487050056458\n",
      "Step 1  Loss: 0.5276578068733215\n",
      "Step 2  Loss: 0.4668229818344116\n",
      "Step 3  Loss: 0.31187817454338074\n",
      "Step 4  Loss: 0.5318366289138794\n",
      "Step 5  Loss: 0.4190278947353363\n",
      "Step 6  Loss: 0.42335501313209534\n",
      "Step 7  Loss: 0.4464063048362732\n",
      "Step 8  Loss: 0.3785034418106079\n",
      "Step 9  Loss: 0.2854365408420563\n",
      "Step 10  Loss: 0.4583625793457031\n",
      "total Loss of epoch  199  is  4.770936071872711\n",
      "Step 0  Loss: 0.38449254631996155\n",
      "Step 1  Loss: 0.31523409485816956\n",
      "Step 2  Loss: 0.34873461723327637\n",
      "Step 3  Loss: 0.27175381779670715\n",
      "Step 4  Loss: 0.34075695276260376\n",
      "Step 5  Loss: 0.43864649534225464\n",
      "Step 6  Loss: 0.404070109128952\n",
      "Step 7  Loss: 0.3950255215167999\n",
      "Step 8  Loss: 0.22061742842197418\n",
      "Step 9  Loss: 0.362824022769928\n",
      "Step 10  Loss: 0.3575427830219269\n",
      "total Loss of epoch  200  is  3.839698389172554\n",
      "Step 0  Loss: 0.3007284998893738\n",
      "Step 1  Loss: 0.4431522488594055\n",
      "Step 2  Loss: 0.46302300691604614\n",
      "Step 3  Loss: 0.4332749843597412\n",
      "Step 4  Loss: 0.42501625418663025\n",
      "Step 5  Loss: 0.3063487708568573\n",
      "Step 6  Loss: 0.3684837222099304\n",
      "Step 7  Loss: 0.3257571756839752\n",
      "Step 8  Loss: 0.2708340287208557\n",
      "Step 9  Loss: 0.2984931468963623\n",
      "Step 10  Loss: 0.2891008257865906\n",
      "total Loss of epoch  201  is  3.9242126643657684\n",
      "Step 0  Loss: 0.4637831151485443\n",
      "Step 1  Loss: 0.4268995225429535\n",
      "Step 2  Loss: 0.42807602882385254\n",
      "Step 3  Loss: 0.39331546425819397\n",
      "Step 4  Loss: 0.4834125339984894\n",
      "Step 5  Loss: 0.29552456736564636\n",
      "Step 6  Loss: 0.32358479499816895\n",
      "Step 7  Loss: 0.4430331289768219\n",
      "Step 8  Loss: 0.41080546379089355\n",
      "Step 9  Loss: 0.4399043023586273\n",
      "Step 10  Loss: 0.3352808952331543\n",
      "total Loss of epoch  202  is  4.443619817495346\n",
      "Step 0  Loss: 0.34767627716064453\n",
      "Step 1  Loss: 0.4631521999835968\n",
      "Step 2  Loss: 0.3397051990032196\n",
      "Step 3  Loss: 0.33926132321357727\n",
      "Step 4  Loss: 0.33641907572746277\n",
      "Step 5  Loss: 0.4303988814353943\n",
      "Step 6  Loss: 0.5423095226287842\n",
      "Step 7  Loss: 0.2832145094871521\n",
      "Step 8  Loss: 0.36916327476501465\n",
      "Step 9  Loss: 0.3984491229057312\n",
      "Step 10  Loss: 0.3633202314376831\n",
      "total Loss of epoch  203  is  4.2130696177482605\n",
      "Step 0  Loss: 0.37068331241607666\n",
      "Step 1  Loss: 0.3437846899032593\n",
      "Step 2  Loss: 0.3148723840713501\n",
      "Step 3  Loss: 0.23715859651565552\n",
      "Step 4  Loss: 0.3839188516139984\n",
      "Step 5  Loss: 0.42157015204429626\n",
      "Step 6  Loss: 0.3627757132053375\n",
      "Step 7  Loss: 0.22639447450637817\n",
      "Step 8  Loss: 0.2227838933467865\n",
      "Step 9  Loss: 0.36049044132232666\n",
      "Step 10  Loss: 0.28239938616752625\n",
      "total Loss of epoch  204  is  3.5268318951129913\n",
      "Step 0  Loss: 0.3496480882167816\n",
      "Step 1  Loss: 0.33281639218330383\n",
      "Step 2  Loss: 0.3098445534706116\n",
      "Step 3  Loss: 0.4751242697238922\n",
      "Step 4  Loss: 0.42914578318595886\n",
      "Step 5  Loss: 0.3467824459075928\n",
      "Step 6  Loss: 0.3826547861099243\n",
      "Step 7  Loss: 0.3494094908237457\n",
      "Step 8  Loss: 0.38350024819374084\n",
      "Step 9  Loss: 0.3452584147453308\n",
      "Step 10  Loss: 0.42675915360450745\n",
      "total Loss of epoch  205  is  4.13094362616539\n",
      "Step 0  Loss: 0.3617743253707886\n",
      "Step 1  Loss: 0.39158007502555847\n",
      "Step 2  Loss: 0.4586232304573059\n",
      "Step 3  Loss: 0.4525538980960846\n",
      "Step 4  Loss: 0.3662692606449127\n",
      "Step 5  Loss: 0.4602804481983185\n",
      "Step 6  Loss: 0.3716529607772827\n",
      "Step 7  Loss: 0.4647613763809204\n",
      "Step 8  Loss: 0.4183744192123413\n",
      "Step 9  Loss: 0.376630574464798\n",
      "Step 10  Loss: 0.46955835819244385\n",
      "total Loss of epoch  206  is  4.592058926820755\n",
      "Step 0  Loss: 0.2441195398569107\n",
      "Step 1  Loss: 0.3078235387802124\n",
      "Step 2  Loss: 0.29413682222366333\n",
      "Step 3  Loss: 0.34468239545822144\n",
      "Step 4  Loss: 0.35894790291786194\n",
      "Step 5  Loss: 0.3210757374763489\n",
      "Step 6  Loss: 0.30469465255737305\n",
      "Step 7  Loss: 0.4344436228275299\n",
      "Step 8  Loss: 0.4228980541229248\n",
      "Step 9  Loss: 0.36314570903778076\n",
      "Step 10  Loss: 0.46443307399749756\n",
      "total Loss of epoch  207  is  3.8604010492563248\n",
      "Step 0  Loss: 0.40899714827537537\n",
      "Step 1  Loss: 0.3076857626438141\n",
      "Step 2  Loss: 0.4867636263370514\n",
      "Step 3  Loss: 0.358237087726593\n",
      "Step 4  Loss: 0.3341839909553528\n",
      "Step 5  Loss: 0.40299922227859497\n",
      "Step 6  Loss: 0.43683794140815735\n",
      "Step 7  Loss: 0.319627046585083\n",
      "Step 8  Loss: 0.47567689418792725\n",
      "Step 9  Loss: 0.3248496651649475\n",
      "Step 10  Loss: 0.5358126163482666\n",
      "total Loss of epoch  208  is  4.391671001911163\n",
      "Step 0  Loss: 0.4516219198703766\n",
      "Step 1  Loss: 0.32628846168518066\n",
      "Step 2  Loss: 0.23320971429347992\n",
      "Step 3  Loss: 0.37374424934387207\n",
      "Step 4  Loss: 0.3374638855457306\n",
      "Step 5  Loss: 0.31507185101509094\n",
      "Step 6  Loss: 0.30858728289604187\n",
      "Step 7  Loss: 0.430713415145874\n",
      "Step 8  Loss: 0.29545512795448303\n",
      "Step 9  Loss: 0.24550123512744904\n",
      "Step 10  Loss: 0.5267304182052612\n",
      "total Loss of epoch  209  is  3.84438756108284\n",
      "Step 0  Loss: 0.34976059198379517\n",
      "Step 1  Loss: 0.36287569999694824\n",
      "Step 2  Loss: 0.3130069077014923\n",
      "Step 3  Loss: 0.4101985692977905\n",
      "Step 4  Loss: 0.27510517835617065\n",
      "Step 5  Loss: 0.4389921724796295\n",
      "Step 6  Loss: 0.3994138538837433\n",
      "Step 7  Loss: 0.3901607394218445\n",
      "Step 8  Loss: 0.40842920541763306\n",
      "Step 9  Loss: 0.3952912986278534\n",
      "Step 10  Loss: 0.23787707090377808\n",
      "total Loss of epoch  210  is  3.9811112880706787\n",
      "Step 0  Loss: 0.4304710030555725\n",
      "Step 1  Loss: 0.39916354417800903\n",
      "Step 2  Loss: 0.33138781785964966\n",
      "Step 3  Loss: 0.41705697774887085\n",
      "Step 4  Loss: 0.3403613567352295\n",
      "Step 5  Loss: 0.36200499534606934\n",
      "Step 6  Loss: 0.35672298073768616\n",
      "Step 7  Loss: 0.3346528708934784\n",
      "Step 8  Loss: 0.46885445713996887\n",
      "Step 9  Loss: 0.5039186477661133\n",
      "Step 10  Loss: 0.43817463517189026\n",
      "total Loss of epoch  211  is  4.382769286632538\n",
      "Step 0  Loss: 0.40195876359939575\n",
      "Step 1  Loss: 0.3039053678512573\n",
      "Step 2  Loss: 0.43125835061073303\n",
      "Step 3  Loss: 0.40577325224876404\n",
      "Step 4  Loss: 0.46202757954597473\n",
      "Step 5  Loss: 0.35330870747566223\n",
      "Step 6  Loss: 0.30296096205711365\n",
      "Step 7  Loss: 0.26280269026756287\n",
      "Step 8  Loss: 0.4112949073314667\n",
      "Step 9  Loss: 0.4842817187309265\n",
      "Step 10  Loss: 0.5123108625411987\n",
      "total Loss of epoch  212  is  4.3318831622600555\n",
      "Step 0  Loss: 0.38596341013908386\n",
      "Step 1  Loss: 0.3405977189540863\n",
      "Step 2  Loss: 0.36531221866607666\n",
      "Step 3  Loss: 0.38371437788009644\n",
      "Step 4  Loss: 0.46768179535865784\n",
      "Step 5  Loss: 0.3562082052230835\n",
      "Step 6  Loss: 0.3132411539554596\n",
      "Step 7  Loss: 0.4374920129776001\n",
      "Step 8  Loss: 0.43729129433631897\n",
      "Step 9  Loss: 0.26761913299560547\n",
      "Step 10  Loss: 0.3533320426940918\n",
      "total Loss of epoch  213  is  4.1084533631801605\n",
      "Step 0  Loss: 0.306854248046875\n",
      "Step 1  Loss: 0.3606370687484741\n",
      "Step 2  Loss: 0.4875199794769287\n",
      "Step 3  Loss: 0.42449751496315\n",
      "Step 4  Loss: 0.39860135316848755\n",
      "Step 5  Loss: 0.45428013801574707\n",
      "Step 6  Loss: 0.32239004969596863\n",
      "Step 7  Loss: 0.4159378111362457\n",
      "Step 8  Loss: 0.27790430188179016\n",
      "Step 9  Loss: 0.4071216583251953\n",
      "Step 10  Loss: 0.46834972500801086\n",
      "total Loss of epoch  214  is  4.324093848466873\n",
      "Step 0  Loss: 0.40581366419792175\n",
      "Step 1  Loss: 0.37413352727890015\n",
      "Step 2  Loss: 0.3336038887500763\n",
      "Step 3  Loss: 0.3241199851036072\n",
      "Step 4  Loss: 0.3537892997264862\n",
      "Step 5  Loss: 0.4685240089893341\n",
      "Step 6  Loss: 0.39561885595321655\n",
      "Step 7  Loss: 0.500058650970459\n",
      "Step 8  Loss: 0.4181106686592102\n",
      "Step 9  Loss: 0.32002881169319153\n",
      "Step 10  Loss: 0.43353164196014404\n",
      "total Loss of epoch  215  is  4.327333003282547\n",
      "Step 0  Loss: 0.4051242172718048\n",
      "Step 1  Loss: 0.3610932528972626\n",
      "Step 2  Loss: 0.2799686789512634\n",
      "Step 3  Loss: 0.33209607005119324\n",
      "Step 4  Loss: 0.23012256622314453\n",
      "Step 5  Loss: 0.3834085166454315\n",
      "Step 6  Loss: 0.3783407509326935\n",
      "Step 7  Loss: 0.3988988697528839\n",
      "Step 8  Loss: 0.3880712687969208\n",
      "Step 9  Loss: 0.4504012167453766\n",
      "Step 10  Loss: 0.3100096881389618\n",
      "total Loss of epoch  216  is  3.9175350964069366\n",
      "Step 0  Loss: 0.3422514498233795\n",
      "Step 1  Loss: 0.42095258831977844\n",
      "Step 2  Loss: 0.34435874223709106\n",
      "Step 3  Loss: 0.3696325123310089\n",
      "Step 4  Loss: 0.30156779289245605\n",
      "Step 5  Loss: 0.39490050077438354\n",
      "Step 6  Loss: 0.4149589538574219\n",
      "Step 7  Loss: 0.3870304226875305\n",
      "Step 8  Loss: 0.3003219962120056\n",
      "Step 9  Loss: 0.3879770040512085\n",
      "Step 10  Loss: 0.3740788698196411\n",
      "total Loss of epoch  217  is  4.038030833005905\n",
      "Step 0  Loss: 0.39255592226982117\n",
      "Step 1  Loss: 0.3098095655441284\n",
      "Step 2  Loss: 0.322980672121048\n",
      "Step 3  Loss: 0.3890533149242401\n",
      "Step 4  Loss: 0.3326375186443329\n",
      "Step 5  Loss: 0.4703643023967743\n",
      "Step 6  Loss: 0.30208176374435425\n",
      "Step 7  Loss: 0.3945668339729309\n",
      "Step 8  Loss: 0.4070685803890228\n",
      "Step 9  Loss: 0.3358420729637146\n",
      "Step 10  Loss: 0.4427674412727356\n",
      "total Loss of epoch  218  is  4.099727988243103\n",
      "Step 0  Loss: 0.3456833064556122\n",
      "Step 1  Loss: 0.49592870473861694\n",
      "Step 2  Loss: 0.4695129990577698\n",
      "Step 3  Loss: 0.3741576373577118\n",
      "Step 4  Loss: 0.4170417785644531\n",
      "Step 5  Loss: 0.18668696284294128\n",
      "Step 6  Loss: 0.48324987292289734\n",
      "Step 7  Loss: 0.5137014985084534\n",
      "Step 8  Loss: 0.3230341374874115\n",
      "Step 9  Loss: 0.3783446252346039\n",
      "Step 10  Loss: 0.5312064290046692\n",
      "total Loss of epoch  219  is  4.51854795217514\n",
      "Step 0  Loss: 0.46803954243659973\n",
      "Step 1  Loss: 0.332712322473526\n",
      "Step 2  Loss: 0.41402536630630493\n",
      "Step 3  Loss: 0.4056943356990814\n",
      "Step 4  Loss: 0.5000637173652649\n",
      "Step 5  Loss: 0.38960880041122437\n",
      "Step 6  Loss: 0.347167044878006\n",
      "Step 7  Loss: 0.38350561261177063\n",
      "Step 8  Loss: 0.32761046290397644\n",
      "Step 9  Loss: 0.3443770110607147\n",
      "Step 10  Loss: 0.4214223325252533\n",
      "total Loss of epoch  220  is  4.334226548671722\n",
      "Step 0  Loss: 0.44784650206565857\n",
      "Step 1  Loss: 0.3432409465312958\n",
      "Step 2  Loss: 0.4188125729560852\n",
      "Step 3  Loss: 0.3970922529697418\n",
      "Step 4  Loss: 0.3534202575683594\n",
      "Step 5  Loss: 0.46534812450408936\n",
      "Step 6  Loss: 0.2784021198749542\n",
      "Step 7  Loss: 0.3522113263607025\n",
      "Step 8  Loss: 0.35555770993232727\n",
      "Step 9  Loss: 0.3542538285255432\n",
      "Step 10  Loss: 0.21413877606391907\n",
      "total Loss of epoch  221  is  3.9803244173526764\n",
      "Step 0  Loss: 0.3151087462902069\n",
      "Step 1  Loss: 0.4374048411846161\n",
      "Step 2  Loss: 0.3841443359851837\n",
      "Step 3  Loss: 0.4431939721107483\n",
      "Step 4  Loss: 0.36932215094566345\n",
      "Step 5  Loss: 0.38209688663482666\n",
      "Step 6  Loss: 0.3688328266143799\n",
      "Step 7  Loss: 0.3657783269882202\n",
      "Step 8  Loss: 0.3791508078575134\n",
      "Step 9  Loss: 0.40184324979782104\n",
      "Step 10  Loss: 0.44071298837661743\n",
      "total Loss of epoch  222  is  4.287589132785797\n",
      "Step 0  Loss: 0.45370686054229736\n",
      "Step 1  Loss: 0.3027172386646271\n",
      "Step 2  Loss: 0.3733571469783783\n",
      "Step 3  Loss: 0.4116581678390503\n",
      "Step 4  Loss: 0.4109010100364685\n",
      "Step 5  Loss: 0.3665004074573517\n",
      "Step 6  Loss: 0.3817293047904968\n",
      "Step 7  Loss: 0.39499396085739136\n",
      "Step 8  Loss: 0.3656654953956604\n",
      "Step 9  Loss: 0.3237821161746979\n",
      "Step 10  Loss: 0.3604578971862793\n",
      "total Loss of epoch  223  is  4.145469605922699\n",
      "Step 0  Loss: 0.4190303385257721\n",
      "Step 1  Loss: 0.38930657505989075\n",
      "Step 2  Loss: 0.42760515213012695\n",
      "Step 3  Loss: 0.4512638449668884\n",
      "Step 4  Loss: 0.22807015478610992\n",
      "Step 5  Loss: 0.3458372950553894\n",
      "Step 6  Loss: 0.3612433969974518\n",
      "Step 7  Loss: 0.31262850761413574\n",
      "Step 8  Loss: 0.33790135383605957\n",
      "Step 9  Loss: 0.3364331126213074\n",
      "Step 10  Loss: 0.236394464969635\n",
      "total Loss of epoch  224  is  3.845714196562767\n",
      "Step 0  Loss: 0.34543001651763916\n",
      "Step 1  Loss: 0.2609986364841461\n",
      "Step 2  Loss: 0.45584219694137573\n",
      "Step 3  Loss: 0.36192870140075684\n",
      "Step 4  Loss: 0.4032733142375946\n",
      "Step 5  Loss: 0.39578545093536377\n",
      "Step 6  Loss: 0.4696079194545746\n",
      "Step 7  Loss: 0.4342445731163025\n",
      "Step 8  Loss: 0.33627381920814514\n",
      "Step 9  Loss: 0.3784288167953491\n",
      "Step 10  Loss: 0.36417633295059204\n",
      "total Loss of epoch  225  is  4.20598977804184\n",
      "Step 0  Loss: 0.4398101270198822\n",
      "Step 1  Loss: 0.37875381112098694\n",
      "Step 2  Loss: 0.28836789727211\n",
      "Step 3  Loss: 0.5230490565299988\n",
      "Step 4  Loss: 0.3693038523197174\n",
      "Step 5  Loss: 0.36815670132637024\n",
      "Step 6  Loss: 0.3892397880554199\n",
      "Step 7  Loss: 0.23911891877651215\n",
      "Step 8  Loss: 0.391580730676651\n",
      "Step 9  Loss: 0.3330761790275574\n",
      "Step 10  Loss: 0.43641144037246704\n",
      "total Loss of epoch  226  is  4.156868502497673\n",
      "Step 0  Loss: 0.5000646114349365\n",
      "Step 1  Loss: 0.34039050340652466\n",
      "Step 2  Loss: 0.32724711298942566\n",
      "Step 3  Loss: 0.3407236337661743\n",
      "Step 4  Loss: 0.36718878149986267\n",
      "Step 5  Loss: 0.20323550701141357\n",
      "Step 6  Loss: 0.3090980648994446\n",
      "Step 7  Loss: 0.4247623682022095\n",
      "Step 8  Loss: 0.3548821806907654\n",
      "Step 9  Loss: 0.32545751333236694\n",
      "Step 10  Loss: 0.3403759300708771\n",
      "total Loss of epoch  227  is  3.833426207304001\n",
      "Step 0  Loss: 0.3858306109905243\n",
      "Step 1  Loss: 0.39510953426361084\n",
      "Step 2  Loss: 0.4254838228225708\n",
      "Step 3  Loss: 0.3881416916847229\n",
      "Step 4  Loss: 0.3805127441883087\n",
      "Step 5  Loss: 0.3201497793197632\n",
      "Step 6  Loss: 0.4111159145832062\n",
      "Step 7  Loss: 0.430446594953537\n",
      "Step 8  Loss: 0.43262606859207153\n",
      "Step 9  Loss: 0.37802061438560486\n",
      "Step 10  Loss: 0.33207306265830994\n",
      "total Loss of epoch  228  is  4.27951043844223\n",
      "Step 0  Loss: 0.36282113194465637\n",
      "Step 1  Loss: 0.38487207889556885\n",
      "Step 2  Loss: 0.35922911763191223\n",
      "Step 3  Loss: 0.3156594932079315\n",
      "Step 4  Loss: 0.29565563797950745\n",
      "Step 5  Loss: 0.3876522481441498\n",
      "Step 6  Loss: 0.43832358717918396\n",
      "Step 7  Loss: 0.41454604268074036\n",
      "Step 8  Loss: 0.3809392750263214\n",
      "Step 9  Loss: 0.33755019307136536\n",
      "Step 10  Loss: 0.47852057218551636\n",
      "total Loss of epoch  229  is  4.155769377946854\n",
      "Step 0  Loss: 0.3985194265842438\n",
      "Step 1  Loss: 0.40320226550102234\n",
      "Step 2  Loss: 0.31064850091934204\n",
      "Step 3  Loss: 0.3841318190097809\n",
      "Step 4  Loss: 0.3758438527584076\n",
      "Step 5  Loss: 0.3152829706668854\n",
      "Step 6  Loss: 0.349458783864975\n",
      "Step 7  Loss: 0.4370429217815399\n",
      "Step 8  Loss: 0.4646936058998108\n",
      "Step 9  Loss: 0.3378854990005493\n",
      "Step 10  Loss: 0.37001562118530273\n",
      "total Loss of epoch  230  is  4.14672526717186\n",
      "Step 0  Loss: 0.39540573954582214\n",
      "Step 1  Loss: 0.42557233572006226\n",
      "Step 2  Loss: 0.33649444580078125\n",
      "Step 3  Loss: 0.30153775215148926\n",
      "Step 4  Loss: 0.4626340866088867\n",
      "Step 5  Loss: 0.40345486998558044\n",
      "Step 6  Loss: 0.4180730879306793\n",
      "Step 7  Loss: 0.31720972061157227\n",
      "Step 8  Loss: 0.4158722460269928\n",
      "Step 9  Loss: 0.2899353504180908\n",
      "Step 10  Loss: 0.5065310001373291\n",
      "total Loss of epoch  231  is  4.272720634937286\n",
      "Step 0  Loss: 0.3588309586048126\n",
      "Step 1  Loss: 0.3991606831550598\n",
      "Step 2  Loss: 0.5107706189155579\n",
      "Step 3  Loss: 0.3707060217857361\n",
      "Step 4  Loss: 0.31482645869255066\n",
      "Step 5  Loss: 0.3363592028617859\n",
      "Step 6  Loss: 0.37753021717071533\n",
      "Step 7  Loss: 0.39671826362609863\n",
      "Step 8  Loss: 0.2755134403705597\n",
      "Step 9  Loss: 0.36621689796447754\n",
      "Step 10  Loss: 0.41207951307296753\n",
      "total Loss of epoch  232  is  4.118712276220322\n",
      "Step 0  Loss: 0.3794838786125183\n",
      "Step 1  Loss: 0.28610703349113464\n",
      "Step 2  Loss: 0.3250485956668854\n",
      "Step 3  Loss: 0.410462349653244\n",
      "Step 4  Loss: 0.2957117259502411\n",
      "Step 5  Loss: 0.3974398076534271\n",
      "Step 6  Loss: 0.37814265489578247\n",
      "Step 7  Loss: 0.40938451886177063\n",
      "Step 8  Loss: 0.426769495010376\n",
      "Step 9  Loss: 0.30296608805656433\n",
      "Step 10  Loss: 0.5688033699989319\n",
      "total Loss of epoch  233  is  4.180319517850876\n",
      "Step 0  Loss: 0.4046984314918518\n",
      "Step 1  Loss: 0.4262346923351288\n",
      "Step 2  Loss: 0.4612331986427307\n",
      "Step 3  Loss: 0.39063990116119385\n",
      "Step 4  Loss: 0.3125635087490082\n",
      "Step 5  Loss: 0.4203243553638458\n",
      "Step 6  Loss: 0.4513969123363495\n",
      "Step 7  Loss: 0.30587533116340637\n",
      "Step 8  Loss: 0.45310571789741516\n",
      "Step 9  Loss: 0.5725294351577759\n",
      "Step 10  Loss: 0.179447203874588\n",
      "total Loss of epoch  234  is  4.378048688173294\n",
      "Step 0  Loss: 0.39050084352493286\n",
      "Step 1  Loss: 0.4156041741371155\n",
      "Step 2  Loss: 0.41048333048820496\n",
      "Step 3  Loss: 0.3919793963432312\n",
      "Step 4  Loss: 0.16854076087474823\n",
      "Step 5  Loss: 0.376359224319458\n",
      "Step 6  Loss: 0.39482247829437256\n",
      "Step 7  Loss: 0.4593920409679413\n",
      "Step 8  Loss: 0.36011382937431335\n",
      "Step 9  Loss: 0.3553331196308136\n",
      "Step 10  Loss: 0.3210306167602539\n",
      "total Loss of epoch  235  is  4.044159814715385\n",
      "Step 0  Loss: 0.3759387135505676\n",
      "Step 1  Loss: 0.2747441232204437\n",
      "Step 2  Loss: 0.45235010981559753\n",
      "Step 3  Loss: 0.422823965549469\n",
      "Step 4  Loss: 0.2469182163476944\n",
      "Step 5  Loss: 0.2781994044780731\n",
      "Step 6  Loss: 0.3748210072517395\n",
      "Step 7  Loss: 0.2749667465686798\n",
      "Step 8  Loss: 0.3743840754032135\n",
      "Step 9  Loss: 0.28948506712913513\n",
      "Step 10  Loss: 0.3767114579677582\n",
      "total Loss of epoch  236  is  3.7413428872823715\n",
      "Step 0  Loss: 0.34324750304222107\n",
      "Step 1  Loss: 0.3238992989063263\n",
      "Step 2  Loss: 0.4590737819671631\n",
      "Step 3  Loss: 0.439454048871994\n",
      "Step 4  Loss: 0.3978203535079956\n",
      "Step 5  Loss: 0.41429153084754944\n",
      "Step 6  Loss: 0.35364022850990295\n",
      "Step 7  Loss: 0.38873594999313354\n",
      "Step 8  Loss: 0.3544658124446869\n",
      "Step 9  Loss: 0.32848674058914185\n",
      "Step 10  Loss: 0.4068169891834259\n",
      "total Loss of epoch  237  is  4.209932237863541\n",
      "Step 0  Loss: 0.3862752318382263\n",
      "Step 1  Loss: 0.38462695479393005\n",
      "Step 2  Loss: 0.3079105615615845\n",
      "Step 3  Loss: 0.29274412989616394\n",
      "Step 4  Loss: 0.44211167097091675\n",
      "Step 5  Loss: 0.38296133279800415\n",
      "Step 6  Loss: 0.4776494801044464\n",
      "Step 7  Loss: 0.2973412275314331\n",
      "Step 8  Loss: 0.370928019285202\n",
      "Step 9  Loss: 0.49555960297584534\n",
      "Step 10  Loss: 0.350411593914032\n",
      "total Loss of epoch  238  is  4.1885198056697845\n",
      "Step 0  Loss: 0.33925360441207886\n",
      "Step 1  Loss: 0.34358441829681396\n",
      "Step 2  Loss: 0.326973021030426\n",
      "Step 3  Loss: 0.3034594655036926\n",
      "Step 4  Loss: 0.30771660804748535\n",
      "Step 5  Loss: 0.5012843012809753\n",
      "Step 6  Loss: 0.395459920167923\n",
      "Step 7  Loss: 0.4483799934387207\n",
      "Step 8  Loss: 0.4060124456882477\n",
      "Step 9  Loss: 0.42701682448387146\n",
      "Step 10  Loss: 0.40088993310928345\n",
      "total Loss of epoch  239  is  4.200030535459518\n",
      "Step 0  Loss: 0.4200096130371094\n",
      "Step 1  Loss: 0.3797503113746643\n",
      "Step 2  Loss: 0.3152335286140442\n",
      "Step 3  Loss: 0.3616812825202942\n",
      "Step 4  Loss: 0.2767782211303711\n",
      "Step 5  Loss: 0.455046683549881\n",
      "Step 6  Loss: 0.40799570083618164\n",
      "Step 7  Loss: 0.4016232490539551\n",
      "Step 8  Loss: 0.26894956827163696\n",
      "Step 9  Loss: 0.3249254524707794\n",
      "Step 10  Loss: 0.4677943289279938\n",
      "total Loss of epoch  240  is  4.079787939786911\n",
      "Step 0  Loss: 0.2778359353542328\n",
      "Step 1  Loss: 0.3501567840576172\n",
      "Step 2  Loss: 0.3973139524459839\n",
      "Step 3  Loss: 0.4436011016368866\n",
      "Step 4  Loss: 0.3835630714893341\n",
      "Step 5  Loss: 0.324713796377182\n",
      "Step 6  Loss: 0.4417358636856079\n",
      "Step 7  Loss: 0.33754467964172363\n",
      "Step 8  Loss: 0.3493780195713043\n",
      "Step 9  Loss: 0.37409281730651855\n",
      "Step 10  Loss: 0.2977653741836548\n",
      "total Loss of epoch  241  is  3.9777013957500458\n",
      "Step 0  Loss: 0.24632495641708374\n",
      "Step 1  Loss: 0.29072922468185425\n",
      "Step 2  Loss: 0.30276864767074585\n",
      "Step 3  Loss: 0.32980966567993164\n",
      "Step 4  Loss: 0.5497802495956421\n",
      "Step 5  Loss: 0.4012768864631653\n",
      "Step 6  Loss: 0.44726377725601196\n",
      "Step 7  Loss: 0.3428853750228882\n",
      "Step 8  Loss: 0.3499656021595001\n",
      "Step 9  Loss: 0.40908047556877136\n",
      "Step 10  Loss: 0.5918481945991516\n",
      "total Loss of epoch  242  is  4.261733055114746\n",
      "Step 0  Loss: 0.29224154353141785\n",
      "Step 1  Loss: 0.3207598030567169\n",
      "Step 2  Loss: 0.31187960505485535\n",
      "Step 3  Loss: 0.2907915413379669\n",
      "Step 4  Loss: 0.2866456210613251\n",
      "Step 5  Loss: 0.4244931638240814\n",
      "Step 6  Loss: 0.3996943533420563\n",
      "Step 7  Loss: 0.4069451689720154\n",
      "Step 8  Loss: 0.3922114074230194\n",
      "Step 9  Loss: 0.24101008474826813\n",
      "Step 10  Loss: 0.36787962913513184\n",
      "total Loss of epoch  243  is  3.7345519214868546\n",
      "Step 0  Loss: 0.39646872878074646\n",
      "Step 1  Loss: 0.41732165217399597\n",
      "Step 2  Loss: 0.30647656321525574\n",
      "Step 3  Loss: 0.4551105499267578\n",
      "Step 4  Loss: 0.35551193356513977\n",
      "Step 5  Loss: 0.34041425585746765\n",
      "Step 6  Loss: 0.5012619495391846\n",
      "Step 7  Loss: 0.4227844476699829\n",
      "Step 8  Loss: 0.2670234739780426\n",
      "Step 9  Loss: 0.4458419382572174\n",
      "Step 10  Loss: 0.33378204703330994\n",
      "total Loss of epoch  244  is  4.241997539997101\n",
      "Step 0  Loss: 0.3721209764480591\n",
      "Step 1  Loss: 0.42078834772109985\n",
      "Step 2  Loss: 0.3392612934112549\n",
      "Step 3  Loss: 0.3444878160953522\n",
      "Step 4  Loss: 0.32382774353027344\n",
      "Step 5  Loss: 0.2732865810394287\n",
      "Step 6  Loss: 0.4100952744483948\n",
      "Step 7  Loss: 0.39993810653686523\n",
      "Step 8  Loss: 0.4086097478866577\n",
      "Step 9  Loss: 0.41744574904441833\n",
      "Step 10  Loss: 0.29955634474754333\n",
      "total Loss of epoch  245  is  4.0094179809093475\n",
      "Step 0  Loss: 0.37006208300590515\n",
      "Step 1  Loss: 0.3283989727497101\n",
      "Step 2  Loss: 0.3484053313732147\n",
      "Step 3  Loss: 0.3884263038635254\n",
      "Step 4  Loss: 0.3133406341075897\n",
      "Step 5  Loss: 0.4201696217060089\n",
      "Step 6  Loss: 0.3065538704395294\n",
      "Step 7  Loss: 0.33523130416870117\n",
      "Step 8  Loss: 0.34228071570396423\n",
      "Step 9  Loss: 0.3483811318874359\n",
      "Step 10  Loss: 0.4603043794631958\n",
      "total Loss of epoch  246  is  3.9615543484687805\n",
      "Step 0  Loss: 0.3970218598842621\n",
      "Step 1  Loss: 0.40026405453681946\n",
      "Step 2  Loss: 0.3983248770236969\n",
      "Step 3  Loss: 0.3282744586467743\n",
      "Step 4  Loss: 0.34874677658081055\n",
      "Step 5  Loss: 0.28555622696876526\n",
      "Step 6  Loss: 0.34075236320495605\n",
      "Step 7  Loss: 0.3244099020957947\n",
      "Step 8  Loss: 0.37726280093193054\n",
      "Step 9  Loss: 0.3519652783870697\n",
      "Step 10  Loss: 0.45781752467155457\n",
      "total Loss of epoch  247  is  4.010396122932434\n",
      "Step 0  Loss: 0.3508441746234894\n",
      "Step 1  Loss: 0.3058922290802002\n",
      "Step 2  Loss: 0.4052618741989136\n",
      "Step 3  Loss: 0.34667742252349854\n",
      "Step 4  Loss: 0.34251710772514343\n",
      "Step 5  Loss: 0.40897101163864136\n",
      "Step 6  Loss: 0.42351388931274414\n",
      "Step 7  Loss: 0.3441885709762573\n",
      "Step 8  Loss: 0.4016297459602356\n",
      "Step 9  Loss: 0.4602086842060089\n",
      "Step 10  Loss: 0.28133949637413025\n",
      "total Loss of epoch  248  is  4.071044206619263\n",
      "Step 0  Loss: 0.2536707818508148\n",
      "Step 1  Loss: 0.3070198893547058\n",
      "Step 2  Loss: 0.3277587890625\n",
      "Step 3  Loss: 0.4060344696044922\n",
      "Step 4  Loss: 0.44346433877944946\n",
      "Step 5  Loss: 0.31622636318206787\n",
      "Step 6  Loss: 0.46610942482948303\n",
      "Step 7  Loss: 0.5099036693572998\n",
      "Step 8  Loss: 0.31779876351356506\n",
      "Step 9  Loss: 0.318448007106781\n",
      "Step 10  Loss: 0.17319358885288239\n",
      "total Loss of epoch  249  is  3.8396280854940414\n",
      "Step 0  Loss: 0.34204164147377014\n",
      "Step 1  Loss: 0.3346475064754486\n",
      "Step 2  Loss: 0.3217966854572296\n",
      "Step 3  Loss: 0.3266776502132416\n",
      "Step 4  Loss: 0.31273984909057617\n",
      "Step 5  Loss: 0.27977269887924194\n",
      "Step 6  Loss: 0.4584049582481384\n",
      "Step 7  Loss: 0.310316801071167\n",
      "Step 8  Loss: 0.390918493270874\n",
      "Step 9  Loss: 0.40221741795539856\n",
      "Step 10  Loss: 0.41295284032821655\n",
      "total Loss of epoch  250  is  3.8924865424633026\n",
      "Step 0  Loss: 0.29010024666786194\n",
      "Step 1  Loss: 0.33819714188575745\n",
      "Step 2  Loss: 0.4049759805202484\n",
      "Step 3  Loss: 0.35857558250427246\n",
      "Step 4  Loss: 0.3957659900188446\n",
      "Step 5  Loss: 0.3031117916107178\n",
      "Step 6  Loss: 0.49172231554985046\n",
      "Step 7  Loss: 0.3411518335342407\n",
      "Step 8  Loss: 0.39436542987823486\n",
      "Step 9  Loss: 0.45120054483413696\n",
      "Step 10  Loss: 0.290563702583313\n",
      "total Loss of epoch  251  is  4.059730559587479\n",
      "Step 0  Loss: 0.2982843220233917\n",
      "Step 1  Loss: 0.3304130434989929\n",
      "Step 2  Loss: 0.3748363256454468\n",
      "Step 3  Loss: 0.3473069667816162\n",
      "Step 4  Loss: 0.3717484474182129\n",
      "Step 5  Loss: 0.5490191578865051\n",
      "Step 6  Loss: 0.34168604016304016\n",
      "Step 7  Loss: 0.33220192790031433\n",
      "Step 8  Loss: 0.2791552245616913\n",
      "Step 9  Loss: 0.29802560806274414\n",
      "Step 10  Loss: 0.33939340710639954\n",
      "total Loss of epoch  252  is  3.862070471048355\n",
      "Step 0  Loss: 0.4561159014701843\n",
      "Step 1  Loss: 0.2746601700782776\n",
      "Step 2  Loss: 0.24013680219650269\n",
      "Step 3  Loss: 0.34550556540489197\n",
      "Step 4  Loss: 0.4318222999572754\n",
      "Step 5  Loss: 0.4160582721233368\n",
      "Step 6  Loss: 0.49915099143981934\n",
      "Step 7  Loss: 0.42559710144996643\n",
      "Step 8  Loss: 0.3322801887989044\n",
      "Step 9  Loss: 0.36859509348869324\n",
      "Step 10  Loss: 0.42233309149742126\n",
      "total Loss of epoch  253  is  4.212255477905273\n",
      "Step 0  Loss: 0.3241178095340729\n",
      "Step 1  Loss: 0.39270684123039246\n",
      "Step 2  Loss: 0.32407689094543457\n",
      "Step 3  Loss: 0.30381014943122864\n",
      "Step 4  Loss: 0.4266235828399658\n",
      "Step 5  Loss: 0.24767953157424927\n",
      "Step 6  Loss: 0.28303617238998413\n",
      "Step 7  Loss: 0.3373454809188843\n",
      "Step 8  Loss: 0.2794579565525055\n",
      "Step 9  Loss: 0.35086503624916077\n",
      "Step 10  Loss: 0.37807661294937134\n",
      "total Loss of epoch  254  is  3.6477960646152496\n",
      "Step 0  Loss: 0.28483620285987854\n",
      "Step 1  Loss: 0.423835813999176\n",
      "Step 2  Loss: 0.24297885596752167\n",
      "Step 3  Loss: 0.41449522972106934\n",
      "Step 4  Loss: 0.2975430190563202\n",
      "Step 5  Loss: 0.2662021219730377\n",
      "Step 6  Loss: 0.38009268045425415\n",
      "Step 7  Loss: 0.42737558484077454\n",
      "Step 8  Loss: 0.413108229637146\n",
      "Step 9  Loss: 0.3051660358905792\n",
      "Step 10  Loss: 0.19529494643211365\n",
      "total Loss of epoch  255  is  3.650928720831871\n",
      "Step 0  Loss: 0.32800012826919556\n",
      "Step 1  Loss: 0.376867413520813\n",
      "Step 2  Loss: 0.37639614939689636\n",
      "Step 3  Loss: 0.34057918190956116\n",
      "Step 4  Loss: 0.2776118218898773\n",
      "Step 5  Loss: 0.37638869881629944\n",
      "Step 6  Loss: 0.26439374685287476\n",
      "Step 7  Loss: 0.3362806439399719\n",
      "Step 8  Loss: 0.4043123722076416\n",
      "Step 9  Loss: 0.42609161138534546\n",
      "Step 10  Loss: 0.20596815645694733\n",
      "total Loss of epoch  256  is  3.712889924645424\n",
      "Step 0  Loss: 0.3344399333000183\n",
      "Step 1  Loss: 0.4438224136829376\n",
      "Step 2  Loss: 0.3884838819503784\n",
      "Step 3  Loss: 0.3108701705932617\n",
      "Step 4  Loss: 0.3561919629573822\n",
      "Step 5  Loss: 0.3528461754322052\n",
      "Step 6  Loss: 0.43181708455085754\n",
      "Step 7  Loss: 0.41730067133903503\n",
      "Step 8  Loss: 0.2951441705226898\n",
      "Step 9  Loss: 0.39429640769958496\n",
      "Step 10  Loss: 0.2983267605304718\n",
      "total Loss of epoch  257  is  4.023539632558823\n",
      "Step 0  Loss: 0.31260794401168823\n",
      "Step 1  Loss: 0.24828697741031647\n",
      "Step 2  Loss: 0.3332446813583374\n",
      "Step 3  Loss: 0.31687578558921814\n",
      "Step 4  Loss: 0.3288077414035797\n",
      "Step 5  Loss: 0.33742406964302063\n",
      "Step 6  Loss: 0.5091413855552673\n",
      "Step 7  Loss: 0.4007384479045868\n",
      "Step 8  Loss: 0.38249680399894714\n",
      "Step 9  Loss: 0.39502525329589844\n",
      "Step 10  Loss: 0.30868685245513916\n",
      "total Loss of epoch  258  is  3.8733359426259995\n",
      "Step 0  Loss: 0.3446584641933441\n",
      "Step 1  Loss: 0.30776897072792053\n",
      "Step 2  Loss: 0.4092530608177185\n",
      "Step 3  Loss: 0.2762078046798706\n",
      "Step 4  Loss: 0.31628289818763733\n",
      "Step 5  Loss: 0.4282474219799042\n",
      "Step 6  Loss: 0.4022659659385681\n",
      "Step 7  Loss: 0.3492673933506012\n",
      "Step 8  Loss: 0.3789253830909729\n",
      "Step 9  Loss: 0.3084034323692322\n",
      "Step 10  Loss: 0.2653871774673462\n",
      "total Loss of epoch  259  is  3.786667972803116\n",
      "Step 0  Loss: 0.2647334933280945\n",
      "Step 1  Loss: 0.311597615480423\n",
      "Step 2  Loss: 0.4874601662158966\n",
      "Step 3  Loss: 0.2887532711029053\n",
      "Step 4  Loss: 0.3707439601421356\n",
      "Step 5  Loss: 0.3692994713783264\n",
      "Step 6  Loss: 0.45342597365379333\n",
      "Step 7  Loss: 0.34441205859184265\n",
      "Step 8  Loss: 0.4325868487358093\n",
      "Step 9  Loss: 0.3508300483226776\n",
      "Step 10  Loss: 0.1763906031847\n",
      "total Loss of epoch  260  is  3.8502335101366043\n",
      "Step 0  Loss: 0.3853360116481781\n",
      "Step 1  Loss: 0.38764312863349915\n",
      "Step 2  Loss: 0.2626487612724304\n",
      "Step 3  Loss: 0.3974536657333374\n",
      "Step 4  Loss: 0.3618585765361786\n",
      "Step 5  Loss: 0.5123817920684814\n",
      "Step 6  Loss: 0.23625637590885162\n",
      "Step 7  Loss: 0.3827037513256073\n",
      "Step 8  Loss: 0.3936993181705475\n",
      "Step 9  Loss: 0.305847704410553\n",
      "Step 10  Loss: 0.3671344220638275\n",
      "total Loss of epoch  261  is  3.992963507771492\n",
      "Step 0  Loss: 0.2922263443470001\n",
      "Step 1  Loss: 0.3863459527492523\n",
      "Step 2  Loss: 0.40653425455093384\n",
      "Step 3  Loss: 0.40137365460395813\n",
      "Step 4  Loss: 0.3921531140804291\n",
      "Step 5  Loss: 0.3658961355686188\n",
      "Step 6  Loss: 0.36989620327949524\n",
      "Step 7  Loss: 0.2791332006454468\n",
      "Step 8  Loss: 0.30306562781333923\n",
      "Step 9  Loss: 0.3168796896934509\n",
      "Step 10  Loss: 0.34514397382736206\n",
      "total Loss of epoch  262  is  3.8586481511592865\n",
      "Step 0  Loss: 0.375916987657547\n",
      "Step 1  Loss: 0.3942107558250427\n",
      "Step 2  Loss: 0.3635152578353882\n",
      "Step 3  Loss: 0.3152066469192505\n",
      "Step 4  Loss: 0.44543468952178955\n",
      "Step 5  Loss: 0.3258465826511383\n",
      "Step 6  Loss: 0.3118566572666168\n",
      "Step 7  Loss: 0.3637755811214447\n",
      "Step 8  Loss: 0.3226684629917145\n",
      "Step 9  Loss: 0.279979944229126\n",
      "Step 10  Loss: 0.49693113565444946\n",
      "total Loss of epoch  263  is  3.9953427016735077\n",
      "Step 0  Loss: 0.38151979446411133\n",
      "Step 1  Loss: 0.3673252761363983\n",
      "Step 2  Loss: 0.36772620677948\n",
      "Step 3  Loss: 0.36038023233413696\n",
      "Step 4  Loss: 0.41965335607528687\n",
      "Step 5  Loss: 0.33594876527786255\n",
      "Step 6  Loss: 0.3530668318271637\n",
      "Step 7  Loss: 0.35939937829971313\n",
      "Step 8  Loss: 0.3995244801044464\n",
      "Step 9  Loss: 0.3179541826248169\n",
      "Step 10  Loss: 0.2980738878250122\n",
      "total Loss of epoch  264  is  3.9605723917484283\n",
      "Step 0  Loss: 0.44732698798179626\n",
      "Step 1  Loss: 0.38272106647491455\n",
      "Step 2  Loss: 0.26659274101257324\n",
      "Step 3  Loss: 0.35268399119377136\n",
      "Step 4  Loss: 0.25294196605682373\n",
      "Step 5  Loss: 0.31167247891426086\n",
      "Step 6  Loss: 0.3434063196182251\n",
      "Step 7  Loss: 0.405927449464798\n",
      "Step 8  Loss: 0.3833664655685425\n",
      "Step 9  Loss: 0.26007646322250366\n",
      "Step 10  Loss: 0.41736286878585815\n",
      "total Loss of epoch  265  is  3.8240787982940674\n",
      "Step 0  Loss: 0.3596556782722473\n",
      "Step 1  Loss: 0.32333558797836304\n",
      "Step 2  Loss: 0.4619238078594208\n",
      "Step 3  Loss: 0.32267940044403076\n",
      "Step 4  Loss: 0.47389841079711914\n",
      "Step 5  Loss: 0.36082178354263306\n",
      "Step 6  Loss: 0.358953058719635\n",
      "Step 7  Loss: 0.4317653477191925\n",
      "Step 8  Loss: 0.23606300354003906\n",
      "Step 9  Loss: 0.5294578671455383\n",
      "Step 10  Loss: 0.38112711906433105\n",
      "total Loss of epoch  266  is  4.23968106508255\n",
      "Step 0  Loss: 0.429043710231781\n",
      "Step 1  Loss: 0.28294268250465393\n",
      "Step 2  Loss: 0.2614979147911072\n",
      "Step 3  Loss: 0.41751629114151\n",
      "Step 4  Loss: 0.36544451117515564\n",
      "Step 5  Loss: 0.4071699380874634\n",
      "Step 6  Loss: 0.445823073387146\n",
      "Step 7  Loss: 0.44755515456199646\n",
      "Step 8  Loss: 0.3312236964702606\n",
      "Step 9  Loss: 0.4356425702571869\n",
      "Step 10  Loss: 0.5240695476531982\n",
      "total Loss of epoch  267  is  4.347929090261459\n",
      "Step 0  Loss: 0.32338571548461914\n",
      "Step 1  Loss: 0.31001394987106323\n",
      "Step 2  Loss: 0.30582407116889954\n",
      "Step 3  Loss: 0.2839307188987732\n",
      "Step 4  Loss: 0.4327354431152344\n",
      "Step 5  Loss: 0.30973532795906067\n",
      "Step 6  Loss: 0.2651403248310089\n",
      "Step 7  Loss: 0.3749041259288788\n",
      "Step 8  Loss: 0.40954455733299255\n",
      "Step 9  Loss: 0.31317177414894104\n",
      "Step 10  Loss: 0.3732362985610962\n",
      "total Loss of epoch  268  is  3.7016223073005676\n",
      "Step 0  Loss: 0.39780911803245544\n",
      "Step 1  Loss: 0.33545196056365967\n",
      "Step 2  Loss: 0.43888548016548157\n",
      "Step 3  Loss: 0.3661586046218872\n",
      "Step 4  Loss: 0.12949500977993011\n",
      "Step 5  Loss: 0.29179951548576355\n",
      "Step 6  Loss: 0.28502097725868225\n",
      "Step 7  Loss: 0.35608842968940735\n",
      "Step 8  Loss: 0.2697610557079315\n",
      "Step 9  Loss: 0.33912599086761475\n",
      "Step 10  Loss: 0.43863311409950256\n",
      "total Loss of epoch  269  is  3.648229256272316\n",
      "Step 0  Loss: 0.3608874976634979\n",
      "Step 1  Loss: 0.30826857686042786\n",
      "Step 2  Loss: 0.34858280420303345\n",
      "Step 3  Loss: 0.4367324411869049\n",
      "Step 4  Loss: 0.24911007285118103\n",
      "Step 5  Loss: 0.27974551916122437\n",
      "Step 6  Loss: 0.3044392466545105\n",
      "Step 7  Loss: 0.3449212610721588\n",
      "Step 8  Loss: 0.37770745158195496\n",
      "Step 9  Loss: 0.3094343841075897\n",
      "Step 10  Loss: 0.46142324805259705\n",
      "total Loss of epoch  270  is  3.7812525033950806\n",
      "Step 0  Loss: 0.3071430027484894\n",
      "Step 1  Loss: 0.28642067313194275\n",
      "Step 2  Loss: 0.3456434905529022\n",
      "Step 3  Loss: 0.4433116018772125\n",
      "Step 4  Loss: 0.5387373566627502\n",
      "Step 5  Loss: 0.45004042983055115\n",
      "Step 6  Loss: 0.38536831736564636\n",
      "Step 7  Loss: 0.34407344460487366\n",
      "Step 8  Loss: 0.44771242141723633\n",
      "Step 9  Loss: 0.4226970374584198\n",
      "Step 10  Loss: 0.5016142129898071\n",
      "total Loss of epoch  271  is  4.4727619886398315\n",
      "Step 0  Loss: 0.255398690700531\n",
      "Step 1  Loss: 0.36516618728637695\n",
      "Step 2  Loss: 0.481618732213974\n",
      "Step 3  Loss: 0.3293585479259491\n",
      "Step 4  Loss: 0.35674288868904114\n",
      "Step 5  Loss: 0.36233919858932495\n",
      "Step 6  Loss: 0.43019428849220276\n",
      "Step 7  Loss: 0.345886766910553\n",
      "Step 8  Loss: 0.38889411091804504\n",
      "Step 9  Loss: 0.36719051003456116\n",
      "Step 10  Loss: 0.4600484073162079\n",
      "total Loss of epoch  272  is  4.142838329076767\n",
      "Step 0  Loss: 0.33272111415863037\n",
      "Step 1  Loss: 0.4561721384525299\n",
      "Step 2  Loss: 0.3185148537158966\n",
      "Step 3  Loss: 0.33404141664505005\n",
      "Step 4  Loss: 0.4324510097503662\n",
      "Step 5  Loss: 0.5159814357757568\n",
      "Step 6  Loss: 0.3421440124511719\n",
      "Step 7  Loss: 0.4105644226074219\n",
      "Step 8  Loss: 0.32557106018066406\n",
      "Step 9  Loss: 0.3194044530391693\n",
      "Step 10  Loss: 0.4383901357650757\n",
      "total Loss of epoch  273  is  4.225956052541733\n",
      "Step 0  Loss: 0.33586740493774414\n",
      "Step 1  Loss: 0.15150554478168488\n",
      "Step 2  Loss: 0.3672819137573242\n",
      "Step 3  Loss: 0.3339366614818573\n",
      "Step 4  Loss: 0.3106594383716583\n",
      "Step 5  Loss: 0.3007887899875641\n",
      "Step 6  Loss: 0.2912941873073578\n",
      "Step 7  Loss: 0.38419264554977417\n",
      "Step 8  Loss: 0.2783975601196289\n",
      "Step 9  Loss: 0.40714943408966064\n",
      "Step 10  Loss: 0.36531659960746765\n",
      "total Loss of epoch  274  is  3.526390179991722\n",
      "Step 0  Loss: 0.5123183727264404\n",
      "Step 1  Loss: 0.35520684719085693\n",
      "Step 2  Loss: 0.3546717166900635\n",
      "Step 3  Loss: 0.4438191056251526\n",
      "Step 4  Loss: 0.34621626138687134\n",
      "Step 5  Loss: 0.4118814468383789\n",
      "Step 6  Loss: 0.38835272192955017\n",
      "Step 7  Loss: 0.3028900623321533\n",
      "Step 8  Loss: 0.36550384759902954\n",
      "Step 9  Loss: 0.3566477298736572\n",
      "Step 10  Loss: 0.33096614480018616\n",
      "total Loss of epoch  275  is  4.16847425699234\n",
      "Step 0  Loss: 0.4479527473449707\n",
      "Step 1  Loss: 0.32030755281448364\n",
      "Step 2  Loss: 0.2895990014076233\n",
      "Step 3  Loss: 0.49173861742019653\n",
      "Step 4  Loss: 0.42607343196868896\n",
      "Step 5  Loss: 0.33895617723464966\n",
      "Step 6  Loss: 0.32002130150794983\n",
      "Step 7  Loss: 0.3891993761062622\n",
      "Step 8  Loss: 0.3761977255344391\n",
      "Step 9  Loss: 0.4946592152118683\n",
      "Step 10  Loss: 0.3540138602256775\n",
      "total Loss of epoch  276  is  4.24871900677681\n",
      "Step 0  Loss: 0.5177686810493469\n",
      "Step 1  Loss: 0.343533456325531\n",
      "Step 2  Loss: 0.41931360960006714\n",
      "Step 3  Loss: 0.33100298047065735\n",
      "Step 4  Loss: 0.4593315124511719\n",
      "Step 5  Loss: 0.34643983840942383\n",
      "Step 6  Loss: 0.24121502041816711\n",
      "Step 7  Loss: 0.34205329418182373\n",
      "Step 8  Loss: 0.39781761169433594\n",
      "Step 9  Loss: 0.36180683970451355\n",
      "Step 10  Loss: 0.4738152325153351\n",
      "total Loss of epoch  277  is  4.2340980768203735\n",
      "Step 0  Loss: 0.43399858474731445\n",
      "Step 1  Loss: 0.3373301923274994\n",
      "Step 2  Loss: 0.3312743008136749\n",
      "Step 3  Loss: 0.4434772729873657\n",
      "Step 4  Loss: 0.3510635495185852\n",
      "Step 5  Loss: 0.32893121242523193\n",
      "Step 6  Loss: 0.36492910981178284\n",
      "Step 7  Loss: 0.39628085494041443\n",
      "Step 8  Loss: 0.2849084436893463\n",
      "Step 9  Loss: 0.4164264500141144\n",
      "Step 10  Loss: 0.327046275138855\n",
      "total Loss of epoch  278  is  4.015666246414185\n",
      "Step 0  Loss: 0.43111419677734375\n",
      "Step 1  Loss: 0.3702864944934845\n",
      "Step 2  Loss: 0.3146953582763672\n",
      "Step 3  Loss: 0.3624219596385956\n",
      "Step 4  Loss: 0.37701326608657837\n",
      "Step 5  Loss: 0.36415761709213257\n",
      "Step 6  Loss: 0.35709553956985474\n",
      "Step 7  Loss: 0.4834192097187042\n",
      "Step 8  Loss: 0.4229573607444763\n",
      "Step 9  Loss: 0.4253682792186737\n",
      "Step 10  Loss: 0.52020663022995\n",
      "total Loss of epoch  279  is  4.428735911846161\n",
      "Step 0  Loss: 0.41621196269989014\n",
      "Step 1  Loss: 0.3948705494403839\n",
      "Step 2  Loss: 0.2816159725189209\n",
      "Step 3  Loss: 0.38051992654800415\n",
      "Step 4  Loss: 0.41138195991516113\n",
      "Step 5  Loss: 0.4248359203338623\n",
      "Step 6  Loss: 0.2969658076763153\n",
      "Step 7  Loss: 0.39181992411613464\n",
      "Step 8  Loss: 0.38197794556617737\n",
      "Step 9  Loss: 0.3488459289073944\n",
      "Step 10  Loss: 0.3464553952217102\n",
      "total Loss of epoch  280  is  4.0755012929439545\n",
      "Step 0  Loss: 0.35152336955070496\n",
      "Step 1  Loss: 0.4161537289619446\n",
      "Step 2  Loss: 0.29300588369369507\n",
      "Step 3  Loss: 0.3082830309867859\n",
      "Step 4  Loss: 0.3728976845741272\n",
      "Step 5  Loss: 0.43577122688293457\n",
      "Step 6  Loss: 0.3382461369037628\n",
      "Step 7  Loss: 0.35352760553359985\n",
      "Step 8  Loss: 0.31673625111579895\n",
      "Step 9  Loss: 0.2900145947933197\n",
      "Step 10  Loss: 0.19795037806034088\n",
      "total Loss of epoch  281  is  3.6741098910570145\n",
      "Step 0  Loss: 0.2710883319377899\n",
      "Step 1  Loss: 0.34990373253822327\n",
      "Step 2  Loss: 0.29487982392311096\n",
      "Step 3  Loss: 0.39933687448501587\n",
      "Step 4  Loss: 0.41751062870025635\n",
      "Step 5  Loss: 0.4481055438518524\n",
      "Step 6  Loss: 0.3182954490184784\n",
      "Step 7  Loss: 0.3342769742012024\n",
      "Step 8  Loss: 0.42376241087913513\n",
      "Step 9  Loss: 0.30159899592399597\n",
      "Step 10  Loss: 0.40072178840637207\n",
      "total Loss of epoch  282  is  3.9594805538654327\n",
      "Step 0  Loss: 0.35571354627609253\n",
      "Step 1  Loss: 0.27695712447166443\n",
      "Step 2  Loss: 0.3791443109512329\n",
      "Step 3  Loss: 0.3106745779514313\n",
      "Step 4  Loss: 0.3383057415485382\n",
      "Step 5  Loss: 0.38198307156562805\n",
      "Step 6  Loss: 0.4899526536464691\n",
      "Step 7  Loss: 0.3598020374774933\n",
      "Step 8  Loss: 0.22591006755828857\n",
      "Step 9  Loss: 0.39697638154029846\n",
      "Step 10  Loss: 0.2566613256931305\n",
      "total Loss of epoch  283  is  3.7720808386802673\n",
      "Step 0  Loss: 0.331495076417923\n",
      "Step 1  Loss: 0.48962435126304626\n",
      "Step 2  Loss: 0.3755183815956116\n",
      "Step 3  Loss: 0.5039240717887878\n",
      "Step 4  Loss: 0.3742489218711853\n",
      "Step 5  Loss: 0.36665138602256775\n",
      "Step 6  Loss: 0.39543044567108154\n",
      "Step 7  Loss: 0.3656158149242401\n",
      "Step 8  Loss: 0.45842912793159485\n",
      "Step 9  Loss: 0.20339618623256683\n",
      "Step 10  Loss: 0.33713600039482117\n",
      "total Loss of epoch  284  is  4.201469764113426\n",
      "Step 0  Loss: 0.4032069742679596\n",
      "Step 1  Loss: 0.46175438165664673\n",
      "Step 2  Loss: 0.43518227338790894\n",
      "Step 3  Loss: 0.3914763927459717\n",
      "Step 4  Loss: 0.4592106342315674\n",
      "Step 5  Loss: 0.4777251183986664\n",
      "Step 6  Loss: 0.24386319518089294\n",
      "Step 7  Loss: 0.2582385540008545\n",
      "Step 8  Loss: 0.3987349569797516\n",
      "Step 9  Loss: 0.3409598171710968\n",
      "Step 10  Loss: 0.17709308862686157\n",
      "total Loss of epoch  285  is  4.047445386648178\n",
      "Step 0  Loss: 0.4080478549003601\n",
      "Step 1  Loss: 0.3988058269023895\n",
      "Step 2  Loss: 0.40474408864974976\n",
      "Step 3  Loss: 0.2534264922142029\n",
      "Step 4  Loss: 0.33213844895362854\n",
      "Step 5  Loss: 0.48266834020614624\n",
      "Step 6  Loss: 0.42835015058517456\n",
      "Step 7  Loss: 0.37442120909690857\n",
      "Step 8  Loss: 0.2788580060005188\n",
      "Step 9  Loss: 0.38529518246650696\n",
      "Step 10  Loss: 0.2943554222583771\n",
      "total Loss of epoch  286  is  4.041111022233963\n",
      "Step 0  Loss: 0.31904539465904236\n",
      "Step 1  Loss: 0.25573766231536865\n",
      "Step 2  Loss: 0.4384024441242218\n",
      "Step 3  Loss: 0.390292763710022\n",
      "Step 4  Loss: 0.4263046979904175\n",
      "Step 5  Loss: 0.3588978052139282\n",
      "Step 6  Loss: 0.5019448399543762\n",
      "Step 7  Loss: 0.26729264855384827\n",
      "Step 8  Loss: 0.3550303876399994\n",
      "Step 9  Loss: 0.3881498873233795\n",
      "Step 10  Loss: 0.3974534273147583\n",
      "total Loss of epoch  287  is  4.098551958799362\n",
      "Step 0  Loss: 0.33558565378189087\n",
      "Step 1  Loss: 0.37376144528388977\n",
      "Step 2  Loss: 0.29389849305152893\n",
      "Step 3  Loss: 0.41466596722602844\n",
      "Step 4  Loss: 0.3280758261680603\n",
      "Step 5  Loss: 0.4189301133155823\n",
      "Step 6  Loss: 0.4069589674472809\n",
      "Step 7  Loss: 0.29658985137939453\n",
      "Step 8  Loss: 0.36906298995018005\n",
      "Step 9  Loss: 0.5522469282150269\n",
      "Step 10  Loss: 0.6621853709220886\n",
      "total Loss of epoch  288  is  4.4519616067409515\n",
      "Step 0  Loss: 0.3668610751628876\n",
      "Step 1  Loss: 0.36710086464881897\n",
      "Step 2  Loss: 0.254779577255249\n",
      "Step 3  Loss: 0.4395744204521179\n",
      "Step 4  Loss: 0.41809019446372986\n",
      "Step 5  Loss: 0.4082290530204773\n",
      "Step 6  Loss: 0.2855565547943115\n",
      "Step 7  Loss: 0.4364513158798218\n",
      "Step 8  Loss: 0.3610166907310486\n",
      "Step 9  Loss: 0.41295355558395386\n",
      "Step 10  Loss: 0.3430413603782654\n",
      "total Loss of epoch  289  is  4.093654662370682\n",
      "Step 0  Loss: 0.420788437128067\n",
      "Step 1  Loss: 0.33072802424430847\n",
      "Step 2  Loss: 0.31070151925086975\n",
      "Step 3  Loss: 0.3518659174442291\n",
      "Step 4  Loss: 0.29490965604782104\n",
      "Step 5  Loss: 0.26188451051712036\n",
      "Step 6  Loss: 0.37820860743522644\n",
      "Step 7  Loss: 0.3935503661632538\n",
      "Step 8  Loss: 0.35930120944976807\n",
      "Step 9  Loss: 0.42075976729393005\n",
      "Step 10  Loss: 0.18936407566070557\n",
      "total Loss of epoch  290  is  3.7120620906352997\n",
      "Step 0  Loss: 0.4256457984447479\n",
      "Step 1  Loss: 0.3290737271308899\n",
      "Step 2  Loss: 0.3626200258731842\n",
      "Step 3  Loss: 0.2804824709892273\n",
      "Step 4  Loss: 0.35171157121658325\n",
      "Step 5  Loss: 0.32476481795310974\n",
      "Step 6  Loss: 0.4337083101272583\n",
      "Step 7  Loss: 0.31852206587791443\n",
      "Step 8  Loss: 0.47880029678344727\n",
      "Step 9  Loss: 0.3669925630092621\n",
      "Step 10  Loss: 0.38198786973953247\n",
      "total Loss of epoch  291  is  4.054309517145157\n",
      "Step 0  Loss: 0.31460389494895935\n",
      "Step 1  Loss: 0.4022308588027954\n",
      "Step 2  Loss: 0.35145944356918335\n",
      "Step 3  Loss: 0.3882982134819031\n",
      "Step 4  Loss: 0.3471924662590027\n",
      "Step 5  Loss: 0.3513474464416504\n",
      "Step 6  Loss: 0.41455334424972534\n",
      "Step 7  Loss: 0.31306177377700806\n",
      "Step 8  Loss: 0.3529389500617981\n",
      "Step 9  Loss: 0.40053337812423706\n",
      "Step 10  Loss: 0.33354640007019043\n",
      "total Loss of epoch  292  is  3.9697661697864532\n",
      "Step 0  Loss: 0.21308547258377075\n",
      "Step 1  Loss: 0.27201947569847107\n",
      "Step 2  Loss: 0.37682387232780457\n",
      "Step 3  Loss: 0.26349109411239624\n",
      "Step 4  Loss: 0.3108227849006653\n",
      "Step 5  Loss: 0.36398494243621826\n",
      "Step 6  Loss: 0.29036250710487366\n",
      "Step 7  Loss: 0.40092340111732483\n",
      "Step 8  Loss: 0.28823912143707275\n",
      "Step 9  Loss: 0.4295472800731659\n",
      "Step 10  Loss: 0.30865177512168884\n",
      "total Loss of epoch  293  is  3.517951726913452\n",
      "Step 0  Loss: 0.2978491485118866\n",
      "Step 1  Loss: 0.29589197039604187\n",
      "Step 2  Loss: 0.4843994379043579\n",
      "Step 3  Loss: 0.37535035610198975\n",
      "Step 4  Loss: 0.3329029977321625\n",
      "Step 5  Loss: 0.37863534688949585\n",
      "Step 6  Loss: 0.37242868542671204\n",
      "Step 7  Loss: 0.340801864862442\n",
      "Step 8  Loss: 0.24493470788002014\n",
      "Step 9  Loss: 0.38389450311660767\n",
      "Step 10  Loss: 0.27487465739250183\n",
      "total Loss of epoch  294  is  3.781963676214218\n",
      "Step 0  Loss: 0.3010369837284088\n",
      "Step 1  Loss: 0.3021811842918396\n",
      "Step 2  Loss: 0.20978623628616333\n",
      "Step 3  Loss: 0.4177275598049164\n",
      "Step 4  Loss: 0.477271169424057\n",
      "Step 5  Loss: 0.3640674352645874\n",
      "Step 6  Loss: 0.42408186197280884\n",
      "Step 7  Loss: 0.25629037618637085\n",
      "Step 8  Loss: 0.3941310942173004\n",
      "Step 9  Loss: 0.36854854226112366\n",
      "Step 10  Loss: 0.21163365244865417\n",
      "total Loss of epoch  295  is  3.7267560958862305\n",
      "Step 0  Loss: 0.3504859209060669\n",
      "Step 1  Loss: 0.3097977638244629\n",
      "Step 2  Loss: 0.3868038058280945\n",
      "Step 3  Loss: 0.22143349051475525\n",
      "Step 4  Loss: 0.33474910259246826\n",
      "Step 5  Loss: 0.35902732610702515\n",
      "Step 6  Loss: 0.35926932096481323\n",
      "Step 7  Loss: 0.33041512966156006\n",
      "Step 8  Loss: 0.2628019452095032\n",
      "Step 9  Loss: 0.35866108536720276\n",
      "Step 10  Loss: 0.3784727454185486\n",
      "total Loss of epoch  296  is  3.6519176363945007\n",
      "Step 0  Loss: 0.33171603083610535\n",
      "Step 1  Loss: 0.32214799523353577\n",
      "Step 2  Loss: 0.3830419182777405\n",
      "Step 3  Loss: 0.35336947441101074\n",
      "Step 4  Loss: 0.3148839473724365\n",
      "Step 5  Loss: 0.44235700368881226\n",
      "Step 6  Loss: 0.32919570803642273\n",
      "Step 7  Loss: 0.3881340026855469\n",
      "Step 8  Loss: 0.2758880853652954\n",
      "Step 9  Loss: 0.46551597118377686\n",
      "Step 10  Loss: 0.4106539487838745\n",
      "total Loss of epoch  297  is  4.0169040858745575\n",
      "Step 0  Loss: 0.3135567307472229\n",
      "Step 1  Loss: 0.2870965898036957\n",
      "Step 2  Loss: 0.4117967486381531\n",
      "Step 3  Loss: 0.32152631878852844\n",
      "Step 4  Loss: 0.22361116111278534\n",
      "Step 5  Loss: 0.3236418664455414\n",
      "Step 6  Loss: 0.32892873883247375\n",
      "Step 7  Loss: 0.2731621563434601\n",
      "Step 8  Loss: 0.401602566242218\n",
      "Step 9  Loss: 0.3716035485267639\n",
      "Step 10  Loss: 0.31749361753463745\n",
      "total Loss of epoch  298  is  3.57402004301548\n",
      "Step 0  Loss: 0.34101158380508423\n",
      "Step 1  Loss: 0.34257256984710693\n",
      "Step 2  Loss: 0.2775304317474365\n",
      "Step 3  Loss: 0.40676459670066833\n",
      "Step 4  Loss: 0.48408570885658264\n",
      "Step 5  Loss: 0.323592871427536\n",
      "Step 6  Loss: 0.36842235922813416\n",
      "Step 7  Loss: 0.35280171036720276\n",
      "Step 8  Loss: 0.33114728331565857\n",
      "Step 9  Loss: 0.37444835901260376\n",
      "Step 10  Loss: 0.4026377201080322\n",
      "total Loss of epoch  299  is  4.005015194416046\n",
      "Step 0  Loss: 0.3104899525642395\n",
      "Step 1  Loss: 0.35929200053215027\n",
      "Step 2  Loss: 0.3710577189922333\n",
      "Step 3  Loss: 0.4007674753665924\n",
      "Step 4  Loss: 0.31544196605682373\n",
      "Step 5  Loss: 0.3807504177093506\n",
      "Step 6  Loss: 0.2940635681152344\n",
      "Step 7  Loss: 0.39511212706565857\n",
      "Step 8  Loss: 0.3212560713291168\n",
      "Step 9  Loss: 0.3791123926639557\n",
      "Step 10  Loss: 0.20573189854621887\n",
      "total Loss of epoch  300  is  3.733075588941574\n",
      "Step 0  Loss: 0.40256935358047485\n",
      "Step 1  Loss: 0.3131697475910187\n",
      "Step 2  Loss: 0.32395753264427185\n",
      "Step 3  Loss: 0.4126073718070984\n",
      "Step 4  Loss: 0.2866570055484772\n",
      "Step 5  Loss: 0.41628050804138184\n",
      "Step 6  Loss: 0.3428172767162323\n",
      "Step 7  Loss: 0.4130550026893616\n",
      "Step 8  Loss: 0.345132052898407\n",
      "Step 9  Loss: 0.3536090850830078\n",
      "Step 10  Loss: 0.3957732617855072\n",
      "total Loss of epoch  301  is  4.005628198385239\n",
      "Step 0  Loss: 0.32792529463768005\n",
      "Step 1  Loss: 0.36943891644477844\n",
      "Step 2  Loss: 0.3960352838039398\n",
      "Step 3  Loss: 0.3195372521877289\n",
      "Step 4  Loss: 0.30099987983703613\n",
      "Step 5  Loss: 0.37546077370643616\n",
      "Step 6  Loss: 0.29638534784317017\n",
      "Step 7  Loss: 0.44673895835876465\n",
      "Step 8  Loss: 0.2820202112197876\n",
      "Step 9  Loss: 0.43715524673461914\n",
      "Step 10  Loss: 0.31728294491767883\n",
      "total Loss of epoch  302  is  3.86898010969162\n",
      "Step 0  Loss: 0.3360711634159088\n",
      "Step 1  Loss: 0.5034762024879456\n",
      "Step 2  Loss: 0.3327154815196991\n",
      "Step 3  Loss: 0.317261666059494\n",
      "Step 4  Loss: 0.344374418258667\n",
      "Step 5  Loss: 0.3603040874004364\n",
      "Step 6  Loss: 0.38110655546188354\n",
      "Step 7  Loss: 0.39698246121406555\n",
      "Step 8  Loss: 0.41364195942878723\n",
      "Step 9  Loss: 0.3959183692932129\n",
      "Step 10  Loss: 0.4821661412715912\n",
      "total Loss of epoch  303  is  4.264018505811691\n",
      "Step 0  Loss: 0.3417782783508301\n",
      "Step 1  Loss: 0.3839877247810364\n",
      "Step 2  Loss: 0.2967149317264557\n",
      "Step 3  Loss: 0.3790843188762665\n",
      "Step 4  Loss: 0.29432162642478943\n",
      "Step 5  Loss: 0.350163072347641\n",
      "Step 6  Loss: 0.34861457347869873\n",
      "Step 7  Loss: 0.4995037019252777\n",
      "Step 8  Loss: 0.39453238248825073\n",
      "Step 9  Loss: 0.3383933901786804\n",
      "Step 10  Loss: 0.24663463234901428\n",
      "total Loss of epoch  304  is  3.873728632926941\n",
      "Step 0  Loss: 0.371681272983551\n",
      "Step 1  Loss: 0.3454951345920563\n",
      "Step 2  Loss: 0.386532723903656\n",
      "Step 3  Loss: 0.42190882563591003\n",
      "Step 4  Loss: 0.2984218895435333\n",
      "Step 5  Loss: 0.40305349230766296\n",
      "Step 6  Loss: 0.3170125484466553\n",
      "Step 7  Loss: 0.4133388102054596\n",
      "Step 8  Loss: 0.23990611732006073\n",
      "Step 9  Loss: 0.34827569127082825\n",
      "Step 10  Loss: 0.3930744230747223\n",
      "total Loss of epoch  305  is  3.9387009292840958\n",
      "Step 0  Loss: 0.3167080581188202\n",
      "Step 1  Loss: 0.31729796528816223\n",
      "Step 2  Loss: 0.3599816560745239\n",
      "Step 3  Loss: 0.373102605342865\n",
      "Step 4  Loss: 0.42070838809013367\n",
      "Step 5  Loss: 0.35970667004585266\n",
      "Step 6  Loss: 0.43216627836227417\n",
      "Step 7  Loss: 0.35964712500572205\n",
      "Step 8  Loss: 0.31697550415992737\n",
      "Step 9  Loss: 0.3550870716571808\n",
      "Step 10  Loss: 0.33948197960853577\n",
      "total Loss of epoch  306  is  3.950863301753998\n",
      "Step 0  Loss: 0.3324615955352783\n",
      "Step 1  Loss: 0.34865373373031616\n",
      "Step 2  Loss: 0.26776430010795593\n",
      "Step 3  Loss: 0.3794665038585663\n",
      "Step 4  Loss: 0.3676449656486511\n",
      "Step 5  Loss: 0.3987451195716858\n",
      "Step 6  Loss: 0.35485324263572693\n",
      "Step 7  Loss: 0.2830103933811188\n",
      "Step 8  Loss: 0.44554999470710754\n",
      "Step 9  Loss: 0.323378324508667\n",
      "Step 10  Loss: 0.3135069012641907\n",
      "total Loss of epoch  307  is  3.8150350749492645\n",
      "Step 0  Loss: 0.41545578837394714\n",
      "Step 1  Loss: 0.34217432141304016\n",
      "Step 2  Loss: 0.3630615174770355\n",
      "Step 3  Loss: 0.3595391809940338\n",
      "Step 4  Loss: 0.37332555651664734\n",
      "Step 5  Loss: 0.39329013228416443\n",
      "Step 6  Loss: 0.30070170760154724\n",
      "Step 7  Loss: 0.34622228145599365\n",
      "Step 8  Loss: 0.3325541615486145\n",
      "Step 9  Loss: 0.3259495496749878\n",
      "Step 10  Loss: 0.2670932114124298\n",
      "total Loss of epoch  308  is  3.8193674087524414\n",
      "Step 0  Loss: 0.34166932106018066\n",
      "Step 1  Loss: 0.38984763622283936\n",
      "Step 2  Loss: 0.3888795077800751\n",
      "Step 3  Loss: 0.16316716372966766\n",
      "Step 4  Loss: 0.34559008479118347\n",
      "Step 5  Loss: 0.3052138388156891\n",
      "Step 6  Loss: 0.4234354496002197\n",
      "Step 7  Loss: 0.3746047616004944\n",
      "Step 8  Loss: 0.30881401896476746\n",
      "Step 9  Loss: 0.4151941239833832\n",
      "Step 10  Loss: 0.3838064968585968\n",
      "total Loss of epoch  309  is  3.840222403407097\n",
      "Step 0  Loss: 0.42829063534736633\n",
      "Step 1  Loss: 0.3623761832714081\n",
      "Step 2  Loss: 0.4049892723560333\n",
      "Step 3  Loss: 0.3202285170555115\n",
      "Step 4  Loss: 0.42600035667419434\n",
      "Step 5  Loss: 0.31226056814193726\n",
      "Step 6  Loss: 0.2880939543247223\n",
      "Step 7  Loss: 0.28873035311698914\n",
      "Step 8  Loss: 0.3192501962184906\n",
      "Step 9  Loss: 0.4267568290233612\n",
      "Step 10  Loss: 0.22911542654037476\n",
      "total Loss of epoch  310  is  3.806092292070389\n",
      "Step 0  Loss: 0.23786699771881104\n",
      "Step 1  Loss: 0.29260143637657166\n",
      "Step 2  Loss: 0.3978334665298462\n",
      "Step 3  Loss: 0.3787088692188263\n",
      "Step 4  Loss: 0.46902647614479065\n",
      "Step 5  Loss: 0.46339964866638184\n",
      "Step 6  Loss: 0.3952985107898712\n",
      "Step 7  Loss: 0.22128675878047943\n",
      "Step 8  Loss: 0.30732986330986023\n",
      "Step 9  Loss: 0.3472942113876343\n",
      "Step 10  Loss: 0.33735963702201843\n",
      "total Loss of epoch  311  is  3.8480058759450912\n",
      "Step 0  Loss: 0.4022309184074402\n",
      "Step 1  Loss: 0.4102988541126251\n",
      "Step 2  Loss: 0.33747828006744385\n",
      "Step 3  Loss: 0.25027382373809814\n",
      "Step 4  Loss: 0.39444687962532043\n",
      "Step 5  Loss: 0.3386998772621155\n",
      "Step 6  Loss: 0.44003039598464966\n",
      "Step 7  Loss: 0.4365882873535156\n",
      "Step 8  Loss: 0.5488573908805847\n",
      "Step 9  Loss: 0.3708494007587433\n",
      "Step 10  Loss: 0.29591473937034607\n",
      "total Loss of epoch  312  is  4.225668847560883\n",
      "Step 0  Loss: 0.5146579146385193\n",
      "Step 1  Loss: 0.3256796896457672\n",
      "Step 2  Loss: 0.30631163716316223\n",
      "Step 3  Loss: 0.3935737609863281\n",
      "Step 4  Loss: 0.3274697959423065\n",
      "Step 5  Loss: 0.318291038274765\n",
      "Step 6  Loss: 0.27039653062820435\n",
      "Step 7  Loss: 0.523594081401825\n",
      "Step 8  Loss: 0.4472394585609436\n",
      "Step 9  Loss: 0.34540268778800964\n",
      "Step 10  Loss: 0.2826954424381256\n",
      "total Loss of epoch  313  is  4.0553120374679565\n",
      "Step 0  Loss: 0.3514096438884735\n",
      "Step 1  Loss: 0.397865891456604\n",
      "Step 2  Loss: 0.40388023853302\n",
      "Step 3  Loss: 0.304694801568985\n",
      "Step 4  Loss: 0.29549530148506165\n",
      "Step 5  Loss: 0.221012145280838\n",
      "Step 6  Loss: 0.3646678030490875\n",
      "Step 7  Loss: 0.36330273747444153\n",
      "Step 8  Loss: 0.2779233455657959\n",
      "Step 9  Loss: 0.3801049292087555\n",
      "Step 10  Loss: 0.3148450255393982\n",
      "total Loss of epoch  314  is  3.675201863050461\n",
      "Step 0  Loss: 0.3697350025177002\n",
      "Step 1  Loss: 0.3693183660507202\n",
      "Step 2  Loss: 0.34735649824142456\n",
      "Step 3  Loss: 0.39892444014549255\n",
      "Step 4  Loss: 0.388370156288147\n",
      "Step 5  Loss: 0.33624669909477234\n",
      "Step 6  Loss: 0.3875691294670105\n",
      "Step 7  Loss: 0.2810737192630768\n",
      "Step 8  Loss: 0.38792043924331665\n",
      "Step 9  Loss: 0.30035510659217834\n",
      "Step 10  Loss: 0.3762097954750061\n",
      "total Loss of epoch  315  is  3.943079352378845\n",
      "Step 0  Loss: 0.2177753448486328\n",
      "Step 1  Loss: 0.2568860650062561\n",
      "Step 2  Loss: 0.3226439952850342\n",
      "Step 3  Loss: 0.42524659633636475\n",
      "Step 4  Loss: 0.251003623008728\n",
      "Step 5  Loss: 0.3601977825164795\n",
      "Step 6  Loss: 0.2662142515182495\n",
      "Step 7  Loss: 0.3304300606250763\n",
      "Step 8  Loss: 0.4095184803009033\n",
      "Step 9  Loss: 0.41516244411468506\n",
      "Step 10  Loss: 0.34823623299598694\n",
      "total Loss of epoch  316  is  3.6033148765563965\n",
      "Step 0  Loss: 0.3999652862548828\n",
      "Step 1  Loss: 0.4660009443759918\n",
      "Step 2  Loss: 0.3801771104335785\n",
      "Step 3  Loss: 0.23277051746845245\n",
      "Step 4  Loss: 0.2794943153858185\n",
      "Step 5  Loss: 0.3260245621204376\n",
      "Step 6  Loss: 0.3412255644798279\n",
      "Step 7  Loss: 0.4652004837989807\n",
      "Step 8  Loss: 0.4305728077888489\n",
      "Step 9  Loss: 0.40322187542915344\n",
      "Step 10  Loss: 0.40444791316986084\n",
      "total Loss of epoch  317  is  4.129101380705833\n",
      "Step 0  Loss: 0.35493040084838867\n",
      "Step 1  Loss: 0.29964348673820496\n",
      "Step 2  Loss: 0.2812631130218506\n",
      "Step 3  Loss: 0.286142498254776\n",
      "Step 4  Loss: 0.39880645275115967\n",
      "Step 5  Loss: 0.3363981544971466\n",
      "Step 6  Loss: 0.389565110206604\n",
      "Step 7  Loss: 0.381831556558609\n",
      "Step 8  Loss: 0.40096622705459595\n",
      "Step 9  Loss: 0.26220324635505676\n",
      "Step 10  Loss: 0.390704482793808\n",
      "total Loss of epoch  318  is  3.7824547290802\n",
      "Step 0  Loss: 0.2808237671852112\n",
      "Step 1  Loss: 0.30215707421302795\n",
      "Step 2  Loss: 0.44545209407806396\n",
      "Step 3  Loss: 0.37802377343177795\n",
      "Step 4  Loss: 0.36087724566459656\n",
      "Step 5  Loss: 0.4258117377758026\n",
      "Step 6  Loss: 0.30038973689079285\n",
      "Step 7  Loss: 0.402131587266922\n",
      "Step 8  Loss: 0.3966690003871918\n",
      "Step 9  Loss: 0.4103842079639435\n",
      "Step 10  Loss: 0.35474705696105957\n",
      "total Loss of epoch  319  is  4.05746728181839\n",
      "Step 0  Loss: 0.39231565594673157\n",
      "Step 1  Loss: 0.3232809007167816\n",
      "Step 2  Loss: 0.3679293990135193\n",
      "Step 3  Loss: 0.3689610958099365\n",
      "Step 4  Loss: 0.3741104006767273\n",
      "Step 5  Loss: 0.3756432831287384\n",
      "Step 6  Loss: 0.3267218768596649\n",
      "Step 7  Loss: 0.41602739691734314\n",
      "Step 8  Loss: 0.2985095977783203\n",
      "Step 9  Loss: 0.43224936723709106\n",
      "Step 10  Loss: 0.4512745141983032\n",
      "total Loss of epoch  320  is  4.127023488283157\n",
      "Step 0  Loss: 0.3371247947216034\n",
      "Step 1  Loss: 0.35142087936401367\n",
      "Step 2  Loss: 0.29980719089508057\n",
      "Step 3  Loss: 0.3872546851634979\n",
      "Step 4  Loss: 0.32833996415138245\n",
      "Step 5  Loss: 0.42636165022850037\n",
      "Step 6  Loss: 0.3218745291233063\n",
      "Step 7  Loss: 0.33262982964515686\n",
      "Step 8  Loss: 0.34668052196502686\n",
      "Step 9  Loss: 0.38510218262672424\n",
      "Step 10  Loss: 0.44147399067878723\n",
      "total Loss of epoch  321  is  3.95807021856308\n",
      "Step 0  Loss: 0.2862342596054077\n",
      "Step 1  Loss: 0.31433531641960144\n",
      "Step 2  Loss: 0.24053099751472473\n",
      "Step 3  Loss: 0.25121593475341797\n",
      "Step 4  Loss: 0.3268965184688568\n",
      "Step 5  Loss: 0.36778873205184937\n",
      "Step 6  Loss: 0.3442649841308594\n",
      "Step 7  Loss: 0.3262855112552643\n",
      "Step 8  Loss: 0.4069381058216095\n",
      "Step 9  Loss: 0.43587011098861694\n",
      "Step 10  Loss: 0.5028079152107239\n",
      "total Loss of epoch  322  is  3.803168386220932\n",
      "Step 0  Loss: 0.2694752812385559\n",
      "Step 1  Loss: 0.40413376688957214\n",
      "Step 2  Loss: 0.33976420760154724\n",
      "Step 3  Loss: 0.3474607467651367\n",
      "Step 4  Loss: 0.3223675489425659\n",
      "Step 5  Loss: 0.2965734004974365\n",
      "Step 6  Loss: 0.2605960965156555\n",
      "Step 7  Loss: 0.35560235381126404\n",
      "Step 8  Loss: 0.3861096501350403\n",
      "Step 9  Loss: 0.4026460349559784\n",
      "Step 10  Loss: 0.34548255801200867\n",
      "total Loss of epoch  323  is  3.7302116453647614\n",
      "Step 0  Loss: 0.3148272931575775\n",
      "Step 1  Loss: 0.29479700326919556\n",
      "Step 2  Loss: 0.32125499844551086\n",
      "Step 3  Loss: 0.3214899003505707\n",
      "Step 4  Loss: 0.37832096219062805\n",
      "Step 5  Loss: 0.42525699734687805\n",
      "Step 6  Loss: 0.4567720592021942\n",
      "Step 7  Loss: 0.46122804284095764\n",
      "Step 8  Loss: 0.4194912612438202\n",
      "Step 9  Loss: 0.3849605619907379\n",
      "Step 10  Loss: 0.4030734598636627\n",
      "total Loss of epoch  324  is  4.181472539901733\n",
      "Step 0  Loss: 0.3979548513889313\n",
      "Step 1  Loss: 0.2986043095588684\n",
      "Step 2  Loss: 0.4586262106895447\n",
      "Step 3  Loss: 0.3873421549797058\n",
      "Step 4  Loss: 0.37128761410713196\n",
      "Step 5  Loss: 0.2513658106327057\n",
      "Step 6  Loss: 0.34285637736320496\n",
      "Step 7  Loss: 0.3586674630641937\n",
      "Step 8  Loss: 0.3929027318954468\n",
      "Step 9  Loss: 0.291740357875824\n",
      "Step 10  Loss: 0.21162571012973785\n",
      "total Loss of epoch  325  is  3.762973591685295\n",
      "Step 0  Loss: 0.33027786016464233\n",
      "Step 1  Loss: 0.3710894286632538\n",
      "Step 2  Loss: 0.3954464793205261\n",
      "Step 3  Loss: 0.3546925187110901\n",
      "Step 4  Loss: 0.4426953196525574\n",
      "Step 5  Loss: 0.35863205790519714\n",
      "Step 6  Loss: 0.24429193139076233\n",
      "Step 7  Loss: 0.503853976726532\n",
      "Step 8  Loss: 0.3946678638458252\n",
      "Step 9  Loss: 0.4319068491458893\n",
      "Step 10  Loss: 0.34633108973503113\n",
      "total Loss of epoch  326  is  4.173885375261307\n",
      "Step 0  Loss: 0.28680071234703064\n",
      "Step 1  Loss: 0.27034708857536316\n",
      "Step 2  Loss: 0.35783031582832336\n",
      "Step 3  Loss: 0.45709651708602905\n",
      "Step 4  Loss: 0.4451022446155548\n",
      "Step 5  Loss: 0.4320680797100067\n",
      "Step 6  Loss: 0.2552487850189209\n",
      "Step 7  Loss: 0.2733811140060425\n",
      "Step 8  Loss: 0.41287553310394287\n",
      "Step 9  Loss: 0.31809762120246887\n",
      "Step 10  Loss: 0.33182191848754883\n",
      "total Loss of epoch  327  is  3.8406699299812317\n",
      "Step 0  Loss: 0.4309002161026001\n",
      "Step 1  Loss: 0.28137388825416565\n",
      "Step 2  Loss: 0.43697914481163025\n",
      "Step 3  Loss: 0.3663153052330017\n",
      "Step 4  Loss: 0.33541733026504517\n",
      "Step 5  Loss: 0.32533150911331177\n",
      "Step 6  Loss: 0.371966153383255\n",
      "Step 7  Loss: 0.3657897710800171\n",
      "Step 8  Loss: 0.38305673003196716\n",
      "Step 9  Loss: 0.36808544397354126\n",
      "Step 10  Loss: 0.303989052772522\n",
      "total Loss of epoch  328  is  3.969204545021057\n",
      "Step 0  Loss: 0.41146600246429443\n",
      "Step 1  Loss: 0.35134321451187134\n",
      "Step 2  Loss: 0.40063947439193726\n",
      "Step 3  Loss: 0.3030412197113037\n",
      "Step 4  Loss: 0.46581289172172546\n",
      "Step 5  Loss: 0.48192736506462097\n",
      "Step 6  Loss: 0.3536241352558136\n",
      "Step 7  Loss: 0.3494189977645874\n",
      "Step 8  Loss: 0.4746789336204529\n",
      "Step 9  Loss: 0.37698519229888916\n",
      "Step 10  Loss: 0.5018126964569092\n",
      "total Loss of epoch  329  is  4.470750123262405\n",
      "Step 0  Loss: 0.3483227491378784\n",
      "Step 1  Loss: 0.41996607184410095\n",
      "Step 2  Loss: 0.33929505944252014\n",
      "Step 3  Loss: 0.36728036403656006\n",
      "Step 4  Loss: 0.25800472497940063\n",
      "Step 5  Loss: 0.3965604603290558\n",
      "Step 6  Loss: 0.43620413541793823\n",
      "Step 7  Loss: 0.31017664074897766\n",
      "Step 8  Loss: 0.3044353127479553\n",
      "Step 9  Loss: 0.3744848668575287\n",
      "Step 10  Loss: 0.26939550042152405\n",
      "total Loss of epoch  330  is  3.82412588596344\n",
      "Step 0  Loss: 0.40221890807151794\n",
      "Step 1  Loss: 0.3473314642906189\n",
      "Step 2  Loss: 0.42719003558158875\n",
      "Step 3  Loss: 0.3196406066417694\n",
      "Step 4  Loss: 0.3652552664279938\n",
      "Step 5  Loss: 0.47413966059684753\n",
      "Step 6  Loss: 0.36387360095977783\n",
      "Step 7  Loss: 0.3481253683567047\n",
      "Step 8  Loss: 0.39590322971343994\n",
      "Step 9  Loss: 0.3190959692001343\n",
      "Step 10  Loss: 0.32463061809539795\n",
      "total Loss of epoch  331  is  4.087404727935791\n",
      "Step 0  Loss: 0.2291916012763977\n",
      "Step 1  Loss: 0.2945946156978607\n",
      "Step 2  Loss: 0.37864765524864197\n",
      "Step 3  Loss: 0.3180428445339203\n",
      "Step 4  Loss: 0.3553815484046936\n",
      "Step 5  Loss: 0.40178191661834717\n",
      "Step 6  Loss: 0.46000435948371887\n",
      "Step 7  Loss: 0.3148897588253021\n",
      "Step 8  Loss: 0.3117723762989044\n",
      "Step 9  Loss: 0.38471531867980957\n",
      "Step 10  Loss: 0.3481442332267761\n",
      "total Loss of epoch  332  is  3.7971662282943726\n",
      "Step 0  Loss: 0.3123074471950531\n",
      "Step 1  Loss: 0.46136897802352905\n",
      "Step 2  Loss: 0.3473168611526489\n",
      "Step 3  Loss: 0.3825533092021942\n",
      "Step 4  Loss: 0.2953803241252899\n",
      "Step 5  Loss: 0.4242812991142273\n",
      "Step 6  Loss: 0.27859073877334595\n",
      "Step 7  Loss: 0.4112953841686249\n",
      "Step 8  Loss: 0.4351513981819153\n",
      "Step 9  Loss: 0.3840537369251251\n",
      "Step 10  Loss: 0.31130704283714294\n",
      "total Loss of epoch  333  is  4.043606519699097\n",
      "Step 0  Loss: 0.34378474950790405\n",
      "Step 1  Loss: 0.4437970817089081\n",
      "Step 2  Loss: 0.3499627709388733\n",
      "Step 3  Loss: 0.24935397505760193\n",
      "Step 4  Loss: 0.3092348277568817\n",
      "Step 5  Loss: 0.2791297435760498\n",
      "Step 6  Loss: 0.4215589165687561\n",
      "Step 7  Loss: 0.4149841070175171\n",
      "Step 8  Loss: 0.43452706933021545\n",
      "Step 9  Loss: 0.3346366584300995\n",
      "Step 10  Loss: 0.35756322741508484\n",
      "total Loss of epoch  334  is  3.938533127307892\n",
      "Step 0  Loss: 0.3716052770614624\n",
      "Step 1  Loss: 0.32880282402038574\n",
      "Step 2  Loss: 0.3940586745738983\n",
      "Step 3  Loss: 0.2833957076072693\n",
      "Step 4  Loss: 0.28412938117980957\n",
      "Step 5  Loss: 0.3519873321056366\n",
      "Step 6  Loss: 0.3923022747039795\n",
      "Step 7  Loss: 0.3234981596469879\n",
      "Step 8  Loss: 0.37164199352264404\n",
      "Step 9  Loss: 0.39853963255882263\n",
      "Step 10  Loss: 0.1504131406545639\n",
      "total Loss of epoch  335  is  3.65037439763546\n",
      "Step 0  Loss: 0.4113478362560272\n",
      "Step 1  Loss: 0.35981494188308716\n",
      "Step 2  Loss: 0.4235893785953522\n",
      "Step 3  Loss: 0.41475915908813477\n",
      "Step 4  Loss: 0.37236443161964417\n",
      "Step 5  Loss: 0.35065335035324097\n",
      "Step 6  Loss: 0.371352881193161\n",
      "Step 7  Loss: 0.35499176383018494\n",
      "Step 8  Loss: 0.3111034035682678\n",
      "Step 9  Loss: 0.40672567486763\n",
      "Step 10  Loss: 0.409475713968277\n",
      "total Loss of epoch  336  is  4.186178535223007\n",
      "Step 0  Loss: 0.33354419469833374\n",
      "Step 1  Loss: 0.2767103314399719\n",
      "Step 2  Loss: 0.31965580582618713\n",
      "Step 3  Loss: 0.3362240493297577\n",
      "Step 4  Loss: 0.25969353318214417\n",
      "Step 5  Loss: 0.4032835066318512\n",
      "Step 6  Loss: 0.3638874888420105\n",
      "Step 7  Loss: 0.23097620904445648\n",
      "Step 8  Loss: 0.2971775233745575\n",
      "Step 9  Loss: 0.3791826665401459\n",
      "Step 10  Loss: 0.18174222111701965\n",
      "total Loss of epoch  337  is  3.382077530026436\n",
      "Step 0  Loss: 0.27288374304771423\n",
      "Step 1  Loss: 0.348598450422287\n",
      "Step 2  Loss: 0.2650717496871948\n",
      "Step 3  Loss: 0.4219878017902374\n",
      "Step 4  Loss: 0.4025508165359497\n",
      "Step 5  Loss: 0.5091806054115295\n",
      "Step 6  Loss: 0.23232850432395935\n",
      "Step 7  Loss: 0.3327709138393402\n",
      "Step 8  Loss: 0.3713931143283844\n",
      "Step 9  Loss: 0.3309352397918701\n",
      "Step 10  Loss: 0.30987972021102905\n",
      "total Loss of epoch  338  is  3.797580659389496\n",
      "Step 0  Loss: 0.45561444759368896\n",
      "Step 1  Loss: 0.3432249128818512\n",
      "Step 2  Loss: 0.37961551547050476\n",
      "Step 3  Loss: 0.3547162413597107\n",
      "Step 4  Loss: 0.32992780208587646\n",
      "Step 5  Loss: 0.3246932327747345\n",
      "Step 6  Loss: 0.4062331020832062\n",
      "Step 7  Loss: 0.3125630021095276\n",
      "Step 8  Loss: 0.41182830929756165\n",
      "Step 9  Loss: 0.4205503761768341\n",
      "Step 10  Loss: 0.36081957817077637\n",
      "total Loss of epoch  339  is  4.0997865200042725\n",
      "Step 0  Loss: 0.2948603332042694\n",
      "Step 1  Loss: 0.36827507615089417\n",
      "Step 2  Loss: 0.26757004857063293\n",
      "Step 3  Loss: 0.3695092499256134\n",
      "Step 4  Loss: 0.36458539962768555\n",
      "Step 5  Loss: 0.3661363422870636\n",
      "Step 6  Loss: 0.4068038761615753\n",
      "Step 7  Loss: 0.34704187512397766\n",
      "Step 8  Loss: 0.3876176178455353\n",
      "Step 9  Loss: 0.31608596444129944\n",
      "Step 10  Loss: 0.1687345653772354\n",
      "total Loss of epoch  340  is  3.657220348715782\n",
      "Step 0  Loss: 0.41630324721336365\n",
      "Step 1  Loss: 0.277388334274292\n",
      "Step 2  Loss: 0.3854873478412628\n",
      "Step 3  Loss: 0.33312323689460754\n",
      "Step 4  Loss: 0.38697195053100586\n",
      "Step 5  Loss: 0.3701154291629791\n",
      "Step 6  Loss: 0.4683886468410492\n",
      "Step 7  Loss: 0.3752199411392212\n",
      "Step 8  Loss: 0.29624640941619873\n",
      "Step 9  Loss: 0.37063342332839966\n",
      "Step 10  Loss: 0.39362579584121704\n",
      "total Loss of epoch  341  is  4.073503762483597\n",
      "Step 0  Loss: 0.26336953043937683\n",
      "Step 1  Loss: 0.45492687821388245\n",
      "Step 2  Loss: 0.3794196546077728\n",
      "Step 3  Loss: 0.29631099104881287\n",
      "Step 4  Loss: 0.3930383324623108\n",
      "Step 5  Loss: 0.3754176199436188\n",
      "Step 6  Loss: 0.4487375020980835\n",
      "Step 7  Loss: 0.3844144642353058\n",
      "Step 8  Loss: 0.32706117630004883\n",
      "Step 9  Loss: 0.45932894945144653\n",
      "Step 10  Loss: 0.44965967535972595\n",
      "total Loss of epoch  342  is  4.231684774160385\n",
      "Step 0  Loss: 0.31679627299308777\n",
      "Step 1  Loss: 0.28654322028160095\n",
      "Step 2  Loss: 0.37294548749923706\n",
      "Step 3  Loss: 0.4271702468395233\n",
      "Step 4  Loss: 0.27089741826057434\n",
      "Step 5  Loss: 0.4433620572090149\n",
      "Step 6  Loss: 0.36884191632270813\n",
      "Step 7  Loss: 0.28651145100593567\n",
      "Step 8  Loss: 0.45330655574798584\n",
      "Step 9  Loss: 0.2916471064090729\n",
      "Step 10  Loss: 0.3137023448944092\n",
      "total Loss of epoch  343  is  3.83172407746315\n",
      "Step 0  Loss: 0.35972684621810913\n",
      "Step 1  Loss: 0.36215412616729736\n",
      "Step 2  Loss: 0.4790465533733368\n",
      "Step 3  Loss: 0.3867425322532654\n",
      "Step 4  Loss: 0.26970595121383667\n",
      "Step 5  Loss: 0.38833650946617126\n",
      "Step 6  Loss: 0.3275497853755951\n",
      "Step 7  Loss: 0.38915809988975525\n",
      "Step 8  Loss: 0.41452646255493164\n",
      "Step 9  Loss: 0.36249807476997375\n",
      "Step 10  Loss: 0.27454376220703125\n",
      "total Loss of epoch  344  is  4.013988703489304\n",
      "Step 0  Loss: 0.21537388861179352\n",
      "Step 1  Loss: 0.2804532051086426\n",
      "Step 2  Loss: 0.3930746614933014\n",
      "Step 3  Loss: 0.33827298879623413\n",
      "Step 4  Loss: 0.33909696340560913\n",
      "Step 5  Loss: 0.4117998480796814\n",
      "Step 6  Loss: 0.3833528459072113\n",
      "Step 7  Loss: 0.3617658317089081\n",
      "Step 8  Loss: 0.3405067026615143\n",
      "Step 9  Loss: 0.35129883885383606\n",
      "Step 10  Loss: 0.5108851194381714\n",
      "total Loss of epoch  345  is  3.9258808940649033\n",
      "Step 0  Loss: 0.4319627285003662\n",
      "Step 1  Loss: 0.3190663456916809\n",
      "Step 2  Loss: 0.371878981590271\n",
      "Step 3  Loss: 0.3896430730819702\n",
      "Step 4  Loss: 0.5355352759361267\n",
      "Step 5  Loss: 0.3367556035518646\n",
      "Step 6  Loss: 0.22969457507133484\n",
      "Step 7  Loss: 0.3372572958469391\n",
      "Step 8  Loss: 0.35071349143981934\n",
      "Step 9  Loss: 0.32767513394355774\n",
      "Step 10  Loss: 0.5844274759292603\n",
      "total Loss of epoch  346  is  4.214609980583191\n",
      "Step 0  Loss: 0.40496501326560974\n",
      "Step 1  Loss: 0.3343476355075836\n",
      "Step 2  Loss: 0.3775547742843628\n",
      "Step 3  Loss: 0.3799716830253601\n",
      "Step 4  Loss: 0.25514379143714905\n",
      "Step 5  Loss: 0.4570436477661133\n",
      "Step 6  Loss: 0.31622347235679626\n",
      "Step 7  Loss: 0.300086110830307\n",
      "Step 8  Loss: 0.39385879039764404\n",
      "Step 9  Loss: 0.35184016823768616\n",
      "Step 10  Loss: 0.22463591396808624\n",
      "total Loss of epoch  347  is  3.7956710010766983\n",
      "Step 0  Loss: 0.31690502166748047\n",
      "Step 1  Loss: 0.27549558877944946\n",
      "Step 2  Loss: 0.3936040699481964\n",
      "Step 3  Loss: 0.3679603636264801\n",
      "Step 4  Loss: 0.23325544595718384\n",
      "Step 5  Loss: 0.4598783552646637\n",
      "Step 6  Loss: 0.4321463406085968\n",
      "Step 7  Loss: 0.21971718966960907\n",
      "Step 8  Loss: 0.39832255244255066\n",
      "Step 9  Loss: 0.27290454506874084\n",
      "Step 10  Loss: 0.17667067050933838\n",
      "total Loss of epoch  348  is  3.5468601435422897\n",
      "Step 0  Loss: 0.373663067817688\n",
      "Step 1  Loss: 0.46441593766212463\n",
      "Step 2  Loss: 0.3383234441280365\n",
      "Step 3  Loss: 0.3815821409225464\n",
      "Step 4  Loss: 0.2994348108768463\n",
      "Step 5  Loss: 0.31561052799224854\n",
      "Step 6  Loss: 0.28387168049812317\n",
      "Step 7  Loss: 0.36086735129356384\n",
      "Step 8  Loss: 0.3981318771839142\n",
      "Step 9  Loss: 0.3503735065460205\n",
      "Step 10  Loss: 0.404427707195282\n",
      "total Loss of epoch  349  is  3.970702052116394\n",
      "Step 0  Loss: 0.37593063712120056\n",
      "Step 1  Loss: 0.28480982780456543\n",
      "Step 2  Loss: 0.32721319794654846\n",
      "Step 3  Loss: 0.41542354226112366\n",
      "Step 4  Loss: 0.43531665205955505\n",
      "Step 5  Loss: 0.5029639005661011\n",
      "Step 6  Loss: 0.29290834069252014\n",
      "Step 7  Loss: 0.47881627082824707\n",
      "Step 8  Loss: 0.360696017742157\n",
      "Step 9  Loss: 0.286735862493515\n",
      "Step 10  Loss: 0.308209627866745\n",
      "total Loss of epoch  350  is  4.069023877382278\n",
      "Step 0  Loss: 0.3100476861000061\n",
      "Step 1  Loss: 0.2973811626434326\n",
      "Step 2  Loss: 0.44162431359291077\n",
      "Step 3  Loss: 0.23127718269824982\n",
      "Step 4  Loss: 0.4203898012638092\n",
      "Step 5  Loss: 0.3547489643096924\n",
      "Step 6  Loss: 0.34516191482543945\n",
      "Step 7  Loss: 0.3867572247982025\n",
      "Step 8  Loss: 0.34541192650794983\n",
      "Step 9  Loss: 0.358905553817749\n",
      "Step 10  Loss: 0.43908438086509705\n",
      "total Loss of epoch  351  is  3.9307901114225388\n",
      "Step 0  Loss: 0.3088958263397217\n",
      "Step 1  Loss: 0.24549038708209991\n",
      "Step 2  Loss: 0.43124788999557495\n",
      "Step 3  Loss: 0.36702051758766174\n",
      "Step 4  Loss: 0.5081078410148621\n",
      "Step 5  Loss: 0.5369427800178528\n",
      "Step 6  Loss: 0.48674869537353516\n",
      "Step 7  Loss: 0.36185500025749207\n",
      "Step 8  Loss: 0.31211915612220764\n",
      "Step 9  Loss: 0.35474544763565063\n",
      "Step 10  Loss: 0.32602861523628235\n",
      "total Loss of epoch  352  is  4.239202156662941\n",
      "Step 0  Loss: 0.43092820048332214\n",
      "Step 1  Loss: 0.3793458044528961\n",
      "Step 2  Loss: 0.4638887345790863\n",
      "Step 3  Loss: 0.2964082658290863\n",
      "Step 4  Loss: 0.24699902534484863\n",
      "Step 5  Loss: 0.4879462420940399\n",
      "Step 6  Loss: 0.35214996337890625\n",
      "Step 7  Loss: 0.40793269872665405\n",
      "Step 8  Loss: 0.24208280444145203\n",
      "Step 9  Loss: 0.3305315673351288\n",
      "Step 10  Loss: 0.3588729202747345\n",
      "total Loss of epoch  353  is  3.997086226940155\n",
      "Step 0  Loss: 0.46893683075904846\n",
      "Step 1  Loss: 0.3438970744609833\n",
      "Step 2  Loss: 0.42243674397468567\n",
      "Step 3  Loss: 0.4036021828651428\n",
      "Step 4  Loss: 0.34884628653526306\n",
      "Step 5  Loss: 0.36103492975234985\n",
      "Step 6  Loss: 0.3858833312988281\n",
      "Step 7  Loss: 0.2870800495147705\n",
      "Step 8  Loss: 0.4354698061943054\n",
      "Step 9  Loss: 0.47553589940071106\n",
      "Step 10  Loss: 0.34663212299346924\n",
      "total Loss of epoch  354  is  4.2793552577495575\n",
      "Step 0  Loss: 0.24969425797462463\n",
      "Step 1  Loss: 0.4485580325126648\n",
      "Step 2  Loss: 0.44446033239364624\n",
      "Step 3  Loss: 0.4649055600166321\n",
      "Step 4  Loss: 0.39706510305404663\n",
      "Step 5  Loss: 0.5197703242301941\n",
      "Step 6  Loss: 0.35892215371131897\n",
      "Step 7  Loss: 0.22208131849765778\n",
      "Step 8  Loss: 0.3397756516933441\n",
      "Step 9  Loss: 0.3658933639526367\n",
      "Step 10  Loss: 0.3827447295188904\n",
      "total Loss of epoch  355  is  4.193870827555656\n",
      "Step 0  Loss: 0.4153488278388977\n",
      "Step 1  Loss: 0.36084553599357605\n",
      "Step 2  Loss: 0.31103670597076416\n",
      "Step 3  Loss: 0.4314784109592438\n",
      "Step 4  Loss: 0.49034804105758667\n",
      "Step 5  Loss: 0.3415633738040924\n",
      "Step 6  Loss: 0.4142778217792511\n",
      "Step 7  Loss: 0.33692699670791626\n",
      "Step 8  Loss: 0.3577519357204437\n",
      "Step 9  Loss: 0.2925984859466553\n",
      "Step 10  Loss: 0.3814341425895691\n",
      "total Loss of epoch  356  is  4.133610278367996\n",
      "Step 0  Loss: 0.2213405966758728\n",
      "Step 1  Loss: 0.2976357936859131\n",
      "Step 2  Loss: 0.36883845925331116\n",
      "Step 3  Loss: 0.3359523117542267\n",
      "Step 4  Loss: 0.30664631724357605\n",
      "Step 5  Loss: 0.20618468523025513\n",
      "Step 6  Loss: 0.29136568307876587\n",
      "Step 7  Loss: 0.37051790952682495\n",
      "Step 8  Loss: 0.2857276499271393\n",
      "Step 9  Loss: 0.3817019760608673\n",
      "Step 10  Loss: 0.2081371247768402\n",
      "total Loss of epoch  357  is  3.2740485072135925\n",
      "Step 0  Loss: 0.2987253963947296\n",
      "Step 1  Loss: 0.3144001364707947\n",
      "Step 2  Loss: 0.43043771386146545\n",
      "Step 3  Loss: 0.26595214009284973\n",
      "Step 4  Loss: 0.35690271854400635\n",
      "Step 5  Loss: 0.4121553301811218\n",
      "Step 6  Loss: 0.37525197863578796\n",
      "Step 7  Loss: 0.26116877794265747\n",
      "Step 8  Loss: 0.34840264916419983\n",
      "Step 9  Loss: 0.3773629665374756\n",
      "Step 10  Loss: 0.35704106092453003\n",
      "total Loss of epoch  358  is  3.7978008687496185\n",
      "Step 0  Loss: 0.45916518568992615\n",
      "Step 1  Loss: 0.39523330330848694\n",
      "Step 2  Loss: 0.3943064212799072\n",
      "Step 3  Loss: 0.3112936317920685\n",
      "Step 4  Loss: 0.24370107054710388\n",
      "Step 5  Loss: 0.3496426045894623\n",
      "Step 6  Loss: 0.3750729560852051\n",
      "Step 7  Loss: 0.4014745354652405\n",
      "Step 8  Loss: 0.3989662528038025\n",
      "Step 9  Loss: 0.32994407415390015\n",
      "Step 10  Loss: 0.38185760378837585\n",
      "total Loss of epoch  359  is  4.040657639503479\n",
      "Step 0  Loss: 0.4120393395423889\n",
      "Step 1  Loss: 0.37663769721984863\n",
      "Step 2  Loss: 0.3005521595478058\n",
      "Step 3  Loss: 0.3152216970920563\n",
      "Step 4  Loss: 0.3407464027404785\n",
      "Step 5  Loss: 0.4188416004180908\n",
      "Step 6  Loss: 0.27694347500801086\n",
      "Step 7  Loss: 0.412330687046051\n",
      "Step 8  Loss: 0.40748080611228943\n",
      "Step 9  Loss: 0.49205100536346436\n",
      "Step 10  Loss: 0.5117210745811462\n",
      "total Loss of epoch  360  is  4.264565944671631\n",
      "Step 0  Loss: 0.32894837856292725\n",
      "Step 1  Loss: 0.25372859835624695\n",
      "Step 2  Loss: 0.35136356949806213\n",
      "Step 3  Loss: 0.21509017050266266\n",
      "Step 4  Loss: 0.477154403924942\n",
      "Step 5  Loss: 0.3201965093612671\n",
      "Step 6  Loss: 0.2939586639404297\n",
      "Step 7  Loss: 0.3119339644908905\n",
      "Step 8  Loss: 0.36450642347335815\n",
      "Step 9  Loss: 0.2655377984046936\n",
      "Step 10  Loss: 0.38117796182632446\n",
      "total Loss of epoch  361  is  3.5635964423418045\n",
      "Step 0  Loss: 0.2196682095527649\n",
      "Step 1  Loss: 0.3455026149749756\n",
      "Step 2  Loss: 0.2347683608531952\n",
      "Step 3  Loss: 0.2710568904876709\n",
      "Step 4  Loss: 0.3406497538089752\n",
      "Step 5  Loss: 0.3422577381134033\n",
      "Step 6  Loss: 0.39860227704048157\n",
      "Step 7  Loss: 0.29745253920555115\n",
      "Step 8  Loss: 0.2865212559700012\n",
      "Step 9  Loss: 0.33065885305404663\n",
      "Step 10  Loss: 0.3576253652572632\n",
      "total Loss of epoch  362  is  3.424763858318329\n",
      "Step 0  Loss: 0.43936240673065186\n",
      "Step 1  Loss: 0.27622631192207336\n",
      "Step 2  Loss: 0.31905314326286316\n",
      "Step 3  Loss: 0.3349314332008362\n",
      "Step 4  Loss: 0.3890620768070221\n",
      "Step 5  Loss: 0.31560513377189636\n",
      "Step 6  Loss: 0.2709839940071106\n",
      "Step 7  Loss: 0.32352757453918457\n",
      "Step 8  Loss: 0.34092026948928833\n",
      "Step 9  Loss: 0.3819587230682373\n",
      "Step 10  Loss: 0.488709956407547\n",
      "total Loss of epoch  363  is  3.880341023206711\n",
      "Step 0  Loss: 0.38345518708229065\n",
      "Step 1  Loss: 0.3297750651836395\n",
      "Step 2  Loss: 0.3341286778450012\n",
      "Step 3  Loss: 0.3448086977005005\n",
      "Step 4  Loss: 0.3884003758430481\n",
      "Step 5  Loss: 0.3780820667743683\n",
      "Step 6  Loss: 0.2933312654495239\n",
      "Step 7  Loss: 0.38214316964149475\n",
      "Step 8  Loss: 0.3561694025993347\n",
      "Step 9  Loss: 0.3159286379814148\n",
      "Step 10  Loss: 0.410232275724411\n",
      "total Loss of epoch  364  is  3.9164548218250275\n",
      "Step 0  Loss: 0.37421131134033203\n",
      "Step 1  Loss: 0.32266005873680115\n",
      "Step 2  Loss: 0.42060261964797974\n",
      "Step 3  Loss: 0.36506402492523193\n",
      "Step 4  Loss: 0.3538353145122528\n",
      "Step 5  Loss: 0.4489627778530121\n",
      "Step 6  Loss: 0.31296226382255554\n",
      "Step 7  Loss: 0.35683685541152954\n",
      "Step 8  Loss: 0.3244911730289459\n",
      "Step 9  Loss: 0.3152722716331482\n",
      "Step 10  Loss: 0.3760237395763397\n",
      "total Loss of epoch  365  is  3.9709224104881287\n",
      "Step 0  Loss: 0.34887459874153137\n",
      "Step 1  Loss: 0.32045215368270874\n",
      "Step 2  Loss: 0.43145307898521423\n",
      "Step 3  Loss: 0.32780131697654724\n",
      "Step 4  Loss: 0.3703562915325165\n",
      "Step 5  Loss: 0.42006951570510864\n",
      "Step 6  Loss: 0.3464750647544861\n",
      "Step 7  Loss: 0.478866845369339\n",
      "Step 8  Loss: 0.34777289628982544\n",
      "Step 9  Loss: 0.5030133128166199\n",
      "Step 10  Loss: 0.36242467164993286\n",
      "total Loss of epoch  366  is  4.25755974650383\n",
      "Step 0  Loss: 0.2801516354084015\n",
      "Step 1  Loss: 0.4537309408187866\n",
      "Step 2  Loss: 0.3281796872615814\n",
      "Step 3  Loss: 0.4530905783176422\n",
      "Step 4  Loss: 0.36073726415634155\n",
      "Step 5  Loss: 0.2654428482055664\n",
      "Step 6  Loss: 0.21042928099632263\n",
      "Step 7  Loss: 0.3749605119228363\n",
      "Step 8  Loss: 0.39312416315078735\n",
      "Step 9  Loss: 0.3530791997909546\n",
      "Step 10  Loss: 0.35635921359062195\n",
      "total Loss of epoch  367  is  3.8292853236198425\n",
      "Step 0  Loss: 0.30205997824668884\n",
      "Step 1  Loss: 0.4239867031574249\n",
      "Step 2  Loss: 0.2689221501350403\n",
      "Step 3  Loss: 0.2812606394290924\n",
      "Step 4  Loss: 0.3504168689250946\n",
      "Step 5  Loss: 0.24364234507083893\n",
      "Step 6  Loss: 0.3445874750614166\n",
      "Step 7  Loss: 0.30393996834754944\n",
      "Step 8  Loss: 0.40868744254112244\n",
      "Step 9  Loss: 0.3175393342971802\n",
      "Step 10  Loss: 0.39845016598701477\n",
      "total Loss of epoch  368  is  3.6434930711984634\n",
      "Step 0  Loss: 0.31430554389953613\n",
      "Step 1  Loss: 0.32072994112968445\n",
      "Step 2  Loss: 0.45156675577163696\n",
      "Step 3  Loss: 0.33127519488334656\n",
      "Step 4  Loss: 0.21600796282291412\n",
      "Step 5  Loss: 0.43750664591789246\n",
      "Step 6  Loss: 0.3691023588180542\n",
      "Step 7  Loss: 0.32032904028892517\n",
      "Step 8  Loss: 0.31532129645347595\n",
      "Step 9  Loss: 0.35965967178344727\n",
      "Step 10  Loss: 0.3774944841861725\n",
      "total Loss of epoch  369  is  3.8132988959550858\n",
      "Step 0  Loss: 0.3292698264122009\n",
      "Step 1  Loss: 0.4016924500465393\n",
      "Step 2  Loss: 0.46293383836746216\n",
      "Step 3  Loss: 0.25487545132637024\n",
      "Step 4  Loss: 0.38176265358924866\n",
      "Step 5  Loss: 0.4140239953994751\n",
      "Step 6  Loss: 0.38272929191589355\n",
      "Step 7  Loss: 0.32809576392173767\n",
      "Step 8  Loss: 0.41716933250427246\n",
      "Step 9  Loss: 0.31065064668655396\n",
      "Step 10  Loss: 0.3528122305870056\n",
      "total Loss of epoch  370  is  4.03601548075676\n",
      "Step 0  Loss: 0.3349300026893616\n",
      "Step 1  Loss: 0.3109005093574524\n",
      "Step 2  Loss: 0.35772478580474854\n",
      "Step 3  Loss: 0.3790128529071808\n",
      "Step 4  Loss: 0.34177637100219727\n",
      "Step 5  Loss: 0.3403432071208954\n",
      "Step 6  Loss: 0.4158378541469574\n",
      "Step 7  Loss: 0.3520347476005554\n",
      "Step 8  Loss: 0.4024454355239868\n",
      "Step 9  Loss: 0.3039880394935608\n",
      "Step 10  Loss: 0.4320462942123413\n",
      "total Loss of epoch  371  is  3.9710400998592377\n",
      "Step 0  Loss: 0.2425161898136139\n",
      "Step 1  Loss: 0.3652048408985138\n",
      "Step 2  Loss: 0.34616363048553467\n",
      "Step 3  Loss: 0.39605337381362915\n",
      "Step 4  Loss: 0.32583481073379517\n",
      "Step 5  Loss: 0.3073619604110718\n",
      "Step 6  Loss: 0.3254680335521698\n",
      "Step 7  Loss: 0.4394914507865906\n",
      "Step 8  Loss: 0.39511317014694214\n",
      "Step 9  Loss: 0.3873307704925537\n",
      "Step 10  Loss: 0.3625016212463379\n",
      "total Loss of epoch  372  is  3.8930398523807526\n",
      "Step 0  Loss: 0.3373502492904663\n",
      "Step 1  Loss: 0.3838280141353607\n",
      "Step 2  Loss: 0.3361678421497345\n",
      "Step 3  Loss: 0.27449846267700195\n",
      "Step 4  Loss: 0.3794522285461426\n",
      "Step 5  Loss: 0.40909263491630554\n",
      "Step 6  Loss: 0.4310438632965088\n",
      "Step 7  Loss: 0.31439146399497986\n",
      "Step 8  Loss: 0.27860912680625916\n",
      "Step 9  Loss: 0.39010533690452576\n",
      "Step 10  Loss: 0.25809189677238464\n",
      "total Loss of epoch  373  is  3.79263111948967\n",
      "Step 0  Loss: 0.4648224115371704\n",
      "Step 1  Loss: 0.3291369378566742\n",
      "Step 2  Loss: 0.4462551474571228\n",
      "Step 3  Loss: 0.34186968207359314\n",
      "Step 4  Loss: 0.364865243434906\n",
      "Step 5  Loss: 0.3512899875640869\n",
      "Step 6  Loss: 0.3767133057117462\n",
      "Step 7  Loss: 0.35057976841926575\n",
      "Step 8  Loss: 0.3867843449115753\n",
      "Step 9  Loss: 0.5166903734207153\n",
      "Step 10  Loss: 0.32412001490592957\n",
      "total Loss of epoch  374  is  4.253127217292786\n",
      "Step 0  Loss: 0.40679046511650085\n",
      "Step 1  Loss: 0.3794213831424713\n",
      "Step 2  Loss: 0.3536248207092285\n",
      "Step 3  Loss: 0.38821619749069214\n",
      "Step 4  Loss: 0.3903583884239197\n",
      "Step 5  Loss: 0.42269402742385864\n",
      "Step 6  Loss: 0.35637542605400085\n",
      "Step 7  Loss: 0.4370049834251404\n",
      "Step 8  Loss: 0.37336626648902893\n",
      "Step 9  Loss: 0.3851621448993683\n",
      "Step 10  Loss: 0.41992393136024475\n",
      "total Loss of epoch  375  is  4.312938034534454\n",
      "Step 0  Loss: 0.3353789448738098\n",
      "Step 1  Loss: 0.238511860370636\n",
      "Step 2  Loss: 0.3395318388938904\n",
      "Step 3  Loss: 0.42837920784950256\n",
      "Step 4  Loss: 0.3153017461299896\n",
      "Step 5  Loss: 0.42559149861335754\n",
      "Step 6  Loss: 0.35419031977653503\n",
      "Step 7  Loss: 0.285662978887558\n",
      "Step 8  Loss: 0.3570643961429596\n",
      "Step 9  Loss: 0.34040626883506775\n",
      "Step 10  Loss: 0.3695991337299347\n",
      "total Loss of epoch  376  is  3.789618194103241\n",
      "Step 0  Loss: 0.27488625049591064\n",
      "Step 1  Loss: 0.32117435336112976\n",
      "Step 2  Loss: 0.5434693098068237\n",
      "Step 3  Loss: 0.3643305003643036\n",
      "Step 4  Loss: 0.1513890027999878\n",
      "Step 5  Loss: 0.33581891655921936\n",
      "Step 6  Loss: 0.46114444732666016\n",
      "Step 7  Loss: 0.3204019367694855\n",
      "Step 8  Loss: 0.3813745081424713\n",
      "Step 9  Loss: 0.3202502429485321\n",
      "Step 10  Loss: 0.38655567169189453\n",
      "total Loss of epoch  377  is  3.8607951402664185\n",
      "Step 0  Loss: 0.41169893741607666\n",
      "Step 1  Loss: 0.3165525496006012\n",
      "Step 2  Loss: 0.3182644844055176\n",
      "Step 3  Loss: 0.3400842249393463\n",
      "Step 4  Loss: 0.4607570767402649\n",
      "Step 5  Loss: 0.4062339663505554\n",
      "Step 6  Loss: 0.2826741337776184\n",
      "Step 7  Loss: 0.2806815505027771\n",
      "Step 8  Loss: 0.3192838728427887\n",
      "Step 9  Loss: 0.4304969310760498\n",
      "Step 10  Loss: 0.48563387989997864\n",
      "total Loss of epoch  378  is  4.052361607551575\n",
      "Step 0  Loss: 0.31314849853515625\n",
      "Step 1  Loss: 0.3992660939693451\n",
      "Step 2  Loss: 0.43102002143859863\n",
      "Step 3  Loss: 0.35668450593948364\n",
      "Step 4  Loss: 0.5234881639480591\n",
      "Step 5  Loss: 0.36348971724510193\n",
      "Step 6  Loss: 0.35228630900382996\n",
      "Step 7  Loss: 0.3656467795372009\n",
      "Step 8  Loss: 0.391354501247406\n",
      "Step 9  Loss: 0.3169165253639221\n",
      "Step 10  Loss: 0.31249287724494934\n",
      "total Loss of epoch  379  is  4.125793993473053\n",
      "Step 0  Loss: 0.4118311405181885\n",
      "Step 1  Loss: 0.39815759658813477\n",
      "Step 2  Loss: 0.38643065094947815\n",
      "Step 3  Loss: 0.27652508020401\n",
      "Step 4  Loss: 0.28458601236343384\n",
      "Step 5  Loss: 0.3338468074798584\n",
      "Step 6  Loss: 0.34849607944488525\n",
      "Step 7  Loss: 0.37465399503707886\n",
      "Step 8  Loss: 0.3248898983001709\n",
      "Step 9  Loss: 0.264693945646286\n",
      "Step 10  Loss: 0.3244532346725464\n",
      "total Loss of epoch  380  is  3.728564441204071\n",
      "Step 0  Loss: 0.4512997269630432\n",
      "Step 1  Loss: 0.23236535489559174\n",
      "Step 2  Loss: 0.3254888951778412\n",
      "Step 3  Loss: 0.4361514151096344\n",
      "Step 4  Loss: 0.44312533736228943\n",
      "Step 5  Loss: 0.34715890884399414\n",
      "Step 6  Loss: 0.3748326301574707\n",
      "Step 7  Loss: 0.42531895637512207\n",
      "Step 8  Loss: 0.30898207426071167\n",
      "Step 9  Loss: 0.3789426386356354\n",
      "Step 10  Loss: 0.2812630236148834\n",
      "total Loss of epoch  381  is  4.004928961396217\n",
      "Step 0  Loss: 0.31823134422302246\n",
      "Step 1  Loss: 0.3217412531375885\n",
      "Step 2  Loss: 0.3940069377422333\n",
      "Step 3  Loss: 0.37426069378852844\n",
      "Step 4  Loss: 0.43941107392311096\n",
      "Step 5  Loss: 0.36087167263031006\n",
      "Step 6  Loss: 0.3734632134437561\n",
      "Step 7  Loss: 0.374946653842926\n",
      "Step 8  Loss: 0.4533345103263855\n",
      "Step 9  Loss: 0.26834505796432495\n",
      "Step 10  Loss: 0.29423168301582336\n",
      "total Loss of epoch  382  is  3.9728440940380096\n",
      "Step 0  Loss: 0.3100701868534088\n",
      "Step 1  Loss: 0.37496986985206604\n",
      "Step 2  Loss: 0.37147292494773865\n",
      "Step 3  Loss: 0.2919776439666748\n",
      "Step 4  Loss: 0.3107284903526306\n",
      "Step 5  Loss: 0.437808632850647\n",
      "Step 6  Loss: 0.39093315601348877\n",
      "Step 7  Loss: 0.2457970827817917\n",
      "Step 8  Loss: 0.3906835615634918\n",
      "Step 9  Loss: 0.4143616557121277\n",
      "Step 10  Loss: 0.30035117268562317\n",
      "total Loss of epoch  383  is  3.839154377579689\n",
      "Step 0  Loss: 0.3807491064071655\n",
      "Step 1  Loss: 0.2511640191078186\n",
      "Step 2  Loss: 0.3150625228881836\n",
      "Step 3  Loss: 0.26325714588165283\n",
      "Step 4  Loss: 0.49459436535835266\n",
      "Step 5  Loss: 0.3361775875091553\n",
      "Step 6  Loss: 0.41845759749412537\n",
      "Step 7  Loss: 0.33418846130371094\n",
      "Step 8  Loss: 0.3020083010196686\n",
      "Step 9  Loss: 0.36840248107910156\n",
      "Step 10  Loss: 0.3682434558868408\n",
      "total Loss of epoch  384  is  3.8323050439357758\n",
      "Step 0  Loss: 0.338507741689682\n",
      "Step 1  Loss: 0.4027418792247772\n",
      "Step 2  Loss: 0.34107568860054016\n",
      "Step 3  Loss: 0.27636221051216125\n",
      "Step 4  Loss: 0.45833417773246765\n",
      "Step 5  Loss: 0.3181111812591553\n",
      "Step 6  Loss: 0.32898637652397156\n",
      "Step 7  Loss: 0.2665790915489197\n",
      "Step 8  Loss: 0.29218095541000366\n",
      "Step 9  Loss: 0.42415088415145874\n",
      "Step 10  Loss: 0.31257933378219604\n",
      "total Loss of epoch  385  is  3.7596095204353333\n",
      "Step 0  Loss: 0.41939428448677063\n",
      "Step 1  Loss: 0.28643256425857544\n",
      "Step 2  Loss: 0.29143255949020386\n",
      "Step 3  Loss: 0.3303210437297821\n",
      "Step 4  Loss: 0.37516844272613525\n",
      "Step 5  Loss: 0.4656330347061157\n",
      "Step 6  Loss: 0.3134266138076782\n",
      "Step 7  Loss: 0.3001203238964081\n",
      "Step 8  Loss: 0.37164637446403503\n",
      "Step 9  Loss: 0.29428762197494507\n",
      "Step 10  Loss: 0.2414337396621704\n",
      "total Loss of epoch  386  is  3.68929660320282\n",
      "Step 0  Loss: 0.43162959814071655\n",
      "Step 1  Loss: 0.3763628900051117\n",
      "Step 2  Loss: 0.3967176079750061\n",
      "Step 3  Loss: 0.361581951379776\n",
      "Step 4  Loss: 0.4601219892501831\n",
      "Step 5  Loss: 0.4737716019153595\n",
      "Step 6  Loss: 0.38107290863990784\n",
      "Step 7  Loss: 0.4068315923213959\n",
      "Step 8  Loss: 0.33532366156578064\n",
      "Step 9  Loss: 0.4775981903076172\n",
      "Step 10  Loss: 0.49624598026275635\n",
      "total Loss of epoch  387  is  4.597257971763611\n",
      "Step 0  Loss: 0.2729608714580536\n",
      "Step 1  Loss: 0.3140077292919159\n",
      "Step 2  Loss: 0.39414510130882263\n",
      "Step 3  Loss: 0.2824020981788635\n",
      "Step 4  Loss: 0.2894320785999298\n",
      "Step 5  Loss: 0.3568514287471771\n",
      "Step 6  Loss: 0.3535640835762024\n",
      "Step 7  Loss: 0.32067936658859253\n",
      "Step 8  Loss: 0.3167836368083954\n",
      "Step 9  Loss: 0.40858590602874756\n",
      "Step 10  Loss: 0.4319087266921997\n",
      "total Loss of epoch  388  is  3.7413210272789\n",
      "Step 0  Loss: 0.38254162669181824\n",
      "Step 1  Loss: 0.2894100248813629\n",
      "Step 2  Loss: 0.2994869351387024\n",
      "Step 3  Loss: 0.31051793694496155\n",
      "Step 4  Loss: 0.30241090059280396\n",
      "Step 5  Loss: 0.314139187335968\n",
      "Step 6  Loss: 0.23130716383457184\n",
      "Step 7  Loss: 0.45156893134117126\n",
      "Step 8  Loss: 0.4266008138656616\n",
      "Step 9  Loss: 0.328792929649353\n",
      "Step 10  Loss: 0.4694068133831024\n",
      "total Loss of epoch  389  is  3.8061832636594772\n",
      "Step 0  Loss: 0.32012712955474854\n",
      "Step 1  Loss: 0.28996986150741577\n",
      "Step 2  Loss: 0.540589451789856\n",
      "Step 3  Loss: 0.3983350694179535\n",
      "Step 4  Loss: 0.2897477149963379\n",
      "Step 5  Loss: 0.45409920811653137\n",
      "Step 6  Loss: 0.34966930747032166\n",
      "Step 7  Loss: 0.29615604877471924\n",
      "Step 8  Loss: 0.31595709919929504\n",
      "Step 9  Loss: 0.4269393980503082\n",
      "Step 10  Loss: 0.32153502106666565\n",
      "total Loss of epoch  390  is  4.003125309944153\n",
      "Step 0  Loss: 0.44615209102630615\n",
      "Step 1  Loss: 0.39100420475006104\n",
      "Step 2  Loss: 0.41161197423934937\n",
      "Step 3  Loss: 0.3794967532157898\n",
      "Step 4  Loss: 0.364623486995697\n",
      "Step 5  Loss: 0.414372980594635\n",
      "Step 6  Loss: 0.34545817971229553\n",
      "Step 7  Loss: 0.43831562995910645\n",
      "Step 8  Loss: 0.41215068101882935\n",
      "Step 9  Loss: 0.358577698469162\n",
      "Step 10  Loss: 0.3710368871688843\n",
      "total Loss of epoch  391  is  4.332800567150116\n",
      "Step 0  Loss: 0.2700434625148773\n",
      "Step 1  Loss: 0.4251247048377991\n",
      "Step 2  Loss: 0.35293567180633545\n",
      "Step 3  Loss: 0.34811824560165405\n",
      "Step 4  Loss: 0.38646045327186584\n",
      "Step 5  Loss: 0.42728564143180847\n",
      "Step 6  Loss: 0.21954511106014252\n",
      "Step 7  Loss: 0.36539995670318604\n",
      "Step 8  Loss: 0.3298594057559967\n",
      "Step 9  Loss: 0.41290804743766785\n",
      "Step 10  Loss: 0.41277003288269043\n",
      "total Loss of epoch  392  is  3.9504507333040237\n",
      "Step 0  Loss: 0.45817819237709045\n",
      "Step 1  Loss: 0.33860108256340027\n",
      "Step 2  Loss: 0.282866507768631\n",
      "Step 3  Loss: 0.38282641768455505\n",
      "Step 4  Loss: 0.2701491713523865\n",
      "Step 5  Loss: 0.3004396855831146\n",
      "Step 6  Loss: 0.38897672295570374\n",
      "Step 7  Loss: 0.448855996131897\n",
      "Step 8  Loss: 0.44678163528442383\n",
      "Step 9  Loss: 0.4172200560569763\n",
      "Step 10  Loss: 0.381168931722641\n",
      "total Loss of epoch  393  is  4.11606439948082\n",
      "Step 0  Loss: 0.38166770339012146\n",
      "Step 1  Loss: 0.3623879551887512\n",
      "Step 2  Loss: 0.36565178632736206\n",
      "Step 3  Loss: 0.3974545896053314\n",
      "Step 4  Loss: 0.4903794527053833\n",
      "Step 5  Loss: 0.3914858400821686\n",
      "Step 6  Loss: 0.3700510263442993\n",
      "Step 7  Loss: 0.3692169189453125\n",
      "Step 8  Loss: 0.37898874282836914\n",
      "Step 9  Loss: 0.3879585862159729\n",
      "Step 10  Loss: 0.46401071548461914\n",
      "total Loss of epoch  394  is  4.359253317117691\n",
      "Step 0  Loss: 0.3611636459827423\n",
      "Step 1  Loss: 0.2706359326839447\n",
      "Step 2  Loss: 0.3652542233467102\n",
      "Step 3  Loss: 0.36222898960113525\n",
      "Step 4  Loss: 0.3080495595932007\n",
      "Step 5  Loss: 0.3323158025741577\n",
      "Step 6  Loss: 0.44209250807762146\n",
      "Step 7  Loss: 0.4048507511615753\n",
      "Step 8  Loss: 0.40368303656578064\n",
      "Step 9  Loss: 0.37760695815086365\n",
      "Step 10  Loss: 0.2081325799226761\n",
      "total Loss of epoch  395  is  3.836013987660408\n",
      "Step 0  Loss: 0.2886633276939392\n",
      "Step 1  Loss: 0.3511686623096466\n",
      "Step 2  Loss: 0.3413846790790558\n",
      "Step 3  Loss: 0.3377370536327362\n",
      "Step 4  Loss: 0.36138778924942017\n",
      "Step 5  Loss: 0.30508360266685486\n",
      "Step 6  Loss: 0.3451816141605377\n",
      "Step 7  Loss: 0.2384900003671646\n",
      "Step 8  Loss: 0.26804307103157043\n",
      "Step 9  Loss: 0.2724195122718811\n",
      "Step 10  Loss: 0.5077541470527649\n",
      "total Loss of epoch  396  is  3.6173134595155716\n",
      "Step 0  Loss: 0.38647574186325073\n",
      "Step 1  Loss: 0.27409452199935913\n",
      "Step 2  Loss: 0.2908991277217865\n",
      "Step 3  Loss: 0.3171907067298889\n",
      "Step 4  Loss: 0.28416910767555237\n",
      "Step 5  Loss: 0.4063483476638794\n",
      "Step 6  Loss: 0.3914440870285034\n",
      "Step 7  Loss: 0.4002007246017456\n",
      "Step 8  Loss: 0.32043901085853577\n",
      "Step 9  Loss: 0.36623311042785645\n",
      "Step 10  Loss: 0.3803558647632599\n",
      "total Loss of epoch  397  is  3.817850351333618\n",
      "Step 0  Loss: 0.27025526762008667\n",
      "Step 1  Loss: 0.33831292390823364\n",
      "Step 2  Loss: 0.33500972390174866\n",
      "Step 3  Loss: 0.34134986996650696\n",
      "Step 4  Loss: 0.4412054121494293\n",
      "Step 5  Loss: 0.28853970766067505\n",
      "Step 6  Loss: 0.28283974528312683\n",
      "Step 7  Loss: 0.3678983449935913\n",
      "Step 8  Loss: 0.4322216510772705\n",
      "Step 9  Loss: 0.3894035220146179\n",
      "Step 10  Loss: 0.43941834568977356\n",
      "total Loss of epoch  398  is  3.9264545142650604\n",
      "Step 0  Loss: 0.26649072766304016\n",
      "Step 1  Loss: 0.350225031375885\n",
      "Step 2  Loss: 0.3351873457431793\n",
      "Step 3  Loss: 0.4574485719203949\n",
      "Step 4  Loss: 0.27896130084991455\n",
      "Step 5  Loss: 0.35802051424980164\n",
      "Step 6  Loss: 0.3644952178001404\n",
      "Step 7  Loss: 0.3665764033794403\n",
      "Step 8  Loss: 0.36507633328437805\n",
      "Step 9  Loss: 0.28823116421699524\n",
      "Step 10  Loss: 0.31708720326423645\n",
      "total Loss of epoch  399  is  3.747799813747406\n",
      "Step 0  Loss: 0.3178543150424957\n",
      "Step 1  Loss: 0.42426928877830505\n",
      "Step 2  Loss: 0.34590965509414673\n",
      "Step 3  Loss: 0.3572208881378174\n",
      "Step 4  Loss: 0.39323028922080994\n",
      "Step 5  Loss: 0.38523346185684204\n",
      "Step 6  Loss: 0.252849280834198\n",
      "Step 7  Loss: 0.3890456557273865\n",
      "Step 8  Loss: 0.36626100540161133\n",
      "Step 9  Loss: 0.43038803339004517\n",
      "Step 10  Loss: 0.46076056361198425\n",
      "total Loss of epoch  400  is  4.123022437095642\n",
      "Step 0  Loss: 0.30434340238571167\n",
      "Step 1  Loss: 0.36485686898231506\n",
      "Step 2  Loss: 0.28825902938842773\n",
      "Step 3  Loss: 0.3555563986301422\n",
      "Step 4  Loss: 0.31855934858322144\n",
      "Step 5  Loss: 0.41031166911125183\n",
      "Step 6  Loss: 0.3567594289779663\n",
      "Step 7  Loss: 0.34941941499710083\n",
      "Step 8  Loss: 0.38356339931488037\n",
      "Step 9  Loss: 0.37692323327064514\n",
      "Step 10  Loss: 0.32511070370674133\n",
      "total Loss of epoch  401  is  3.833662897348404\n",
      "Step 0  Loss: 0.2923663854598999\n",
      "Step 1  Loss: 0.38706618547439575\n",
      "Step 2  Loss: 0.43036410212516785\n",
      "Step 3  Loss: 0.37059253454208374\n",
      "Step 4  Loss: 0.2593561112880707\n",
      "Step 5  Loss: 0.30098235607147217\n",
      "Step 6  Loss: 0.36846134066581726\n",
      "Step 7  Loss: 0.3616265654563904\n",
      "Step 8  Loss: 0.23331065475940704\n",
      "Step 9  Loss: 0.2708541452884674\n",
      "Step 10  Loss: 0.34070590138435364\n",
      "total Loss of epoch  402  is  3.615686282515526\n",
      "Step 0  Loss: 0.3064154088497162\n",
      "Step 1  Loss: 0.3229641616344452\n",
      "Step 2  Loss: 0.45425865054130554\n",
      "Step 3  Loss: 0.3998454809188843\n",
      "Step 4  Loss: 0.3517249822616577\n",
      "Step 5  Loss: 0.34608104825019836\n",
      "Step 6  Loss: 0.3211309313774109\n",
      "Step 7  Loss: 0.2570584714412689\n",
      "Step 8  Loss: 0.3965795934200287\n",
      "Step 9  Loss: 0.3638880252838135\n",
      "Step 10  Loss: 0.5590159296989441\n",
      "total Loss of epoch  403  is  4.078962683677673\n",
      "Step 0  Loss: 0.326582670211792\n",
      "Step 1  Loss: 0.4173065423965454\n",
      "Step 2  Loss: 0.36829525232315063\n",
      "Step 3  Loss: 0.20715412497520447\n",
      "Step 4  Loss: 0.3252636790275574\n",
      "Step 5  Loss: 0.40843304991722107\n",
      "Step 6  Loss: 0.3650117814540863\n",
      "Step 7  Loss: 0.28495272994041443\n",
      "Step 8  Loss: 0.36930182576179504\n",
      "Step 9  Loss: 0.3110935688018799\n",
      "Step 10  Loss: 0.24613504111766815\n",
      "total Loss of epoch  404  is  3.6295302659273148\n",
      "Step 0  Loss: 0.36511653661727905\n",
      "Step 1  Loss: 0.3970869183540344\n",
      "Step 2  Loss: 0.35191094875335693\n",
      "Step 3  Loss: 0.4370875060558319\n",
      "Step 4  Loss: 0.38842087984085083\n",
      "Step 5  Loss: 0.36235031485557556\n",
      "Step 6  Loss: 0.346650093793869\n",
      "Step 7  Loss: 0.40742233395576477\n",
      "Step 8  Loss: 0.3290393352508545\n",
      "Step 9  Loss: 0.4059712290763855\n",
      "Step 10  Loss: 0.2583344876766205\n",
      "total Loss of epoch  405  is  4.049390584230423\n",
      "Step 0  Loss: 0.4034471809864044\n",
      "Step 1  Loss: 0.34674468636512756\n",
      "Step 2  Loss: 0.4569028615951538\n",
      "Step 3  Loss: 0.3491639792919159\n",
      "Step 4  Loss: 0.37230348587036133\n",
      "Step 5  Loss: 0.4813750684261322\n",
      "Step 6  Loss: 0.3355296552181244\n",
      "Step 7  Loss: 0.3579920828342438\n",
      "Step 8  Loss: 0.3266545534133911\n",
      "Step 9  Loss: 0.5218683481216431\n",
      "Step 10  Loss: 0.35689589381217957\n",
      "total Loss of epoch  406  is  4.308877795934677\n",
      "Step 0  Loss: 0.2598934471607208\n",
      "Step 1  Loss: 0.27306872606277466\n",
      "Step 2  Loss: 0.28853222727775574\n",
      "Step 3  Loss: 0.37405890226364136\n",
      "Step 4  Loss: 0.3722282648086548\n",
      "Step 5  Loss: 0.4282882511615753\n",
      "Step 6  Loss: 0.40231892466545105\n",
      "Step 7  Loss: 0.3488304316997528\n",
      "Step 8  Loss: 0.2854022681713104\n",
      "Step 9  Loss: 0.29126104712486267\n",
      "Step 10  Loss: 0.3509223759174347\n",
      "total Loss of epoch  407  is  3.6748048663139343\n",
      "Step 0  Loss: 0.32166436314582825\n",
      "Step 1  Loss: 0.37843549251556396\n",
      "Step 2  Loss: 0.24176812171936035\n",
      "Step 3  Loss: 0.33359190821647644\n",
      "Step 4  Loss: 0.4597663879394531\n",
      "Step 5  Loss: 0.2237977534532547\n",
      "Step 6  Loss: 0.1316230446100235\n",
      "Step 7  Loss: 0.38498517870903015\n",
      "Step 8  Loss: 0.2723329961299896\n",
      "Step 9  Loss: 0.2850724756717682\n",
      "Step 10  Loss: 0.4629630744457245\n",
      "total Loss of epoch  408  is  3.496000796556473\n",
      "Step 0  Loss: 0.3424738943576813\n",
      "Step 1  Loss: 0.3288516402244568\n",
      "Step 2  Loss: 0.38784149289131165\n",
      "Step 3  Loss: 0.4108911156654358\n",
      "Step 4  Loss: 0.3437687158584595\n",
      "Step 5  Loss: 0.3582252860069275\n",
      "Step 6  Loss: 0.4414844214916229\n",
      "Step 7  Loss: 0.3039122521877289\n",
      "Step 8  Loss: 0.3732178807258606\n",
      "Step 9  Loss: 0.3810173273086548\n",
      "Step 10  Loss: 0.32072120904922485\n",
      "total Loss of epoch  409  is  3.9924052357673645\n",
      "Step 0  Loss: 0.23419559001922607\n",
      "Step 1  Loss: 0.37671273946762085\n",
      "Step 2  Loss: 0.3575654923915863\n",
      "Step 3  Loss: 0.3270912766456604\n",
      "Step 4  Loss: 0.3012775480747223\n",
      "Step 5  Loss: 0.2497054487466812\n",
      "Step 6  Loss: 0.39746221899986267\n",
      "Step 7  Loss: 0.30141788721084595\n",
      "Step 8  Loss: 0.2973065972328186\n",
      "Step 9  Loss: 0.408193975687027\n",
      "Step 10  Loss: 0.4096498191356659\n",
      "total Loss of epoch  410  is  3.6605785936117172\n",
      "Step 0  Loss: 0.387211412191391\n",
      "Step 1  Loss: 0.388216495513916\n",
      "Step 2  Loss: 0.44910895824432373\n",
      "Step 3  Loss: 0.28235921263694763\n",
      "Step 4  Loss: 0.34155339002609253\n",
      "Step 5  Loss: 0.3338828384876251\n",
      "Step 6  Loss: 0.3810333013534546\n",
      "Step 7  Loss: 0.30313584208488464\n",
      "Step 8  Loss: 0.40194207429885864\n",
      "Step 9  Loss: 0.3879848122596741\n",
      "Step 10  Loss: 0.38333505392074585\n",
      "total Loss of epoch  411  is  4.039763391017914\n",
      "Step 0  Loss: 0.3022018074989319\n",
      "Step 1  Loss: 0.36222103238105774\n",
      "Step 2  Loss: 0.29978805780410767\n",
      "Step 3  Loss: 0.43742892146110535\n",
      "Step 4  Loss: 0.2828523516654968\n",
      "Step 5  Loss: 0.3433257043361664\n",
      "Step 6  Loss: 0.3843671679496765\n",
      "Step 7  Loss: 0.3288476765155792\n",
      "Step 8  Loss: 0.2826809585094452\n",
      "Step 9  Loss: 0.3360157012939453\n",
      "Step 10  Loss: 0.2872866094112396\n",
      "total Loss of epoch  412  is  3.6470159888267517\n",
      "Step 0  Loss: 0.31111833453178406\n",
      "Step 1  Loss: 0.29887622594833374\n",
      "Step 2  Loss: 0.2958184778690338\n",
      "Step 3  Loss: 0.39740169048309326\n",
      "Step 4  Loss: 0.31933945417404175\n",
      "Step 5  Loss: 0.33136624097824097\n",
      "Step 6  Loss: 0.4699554443359375\n",
      "Step 7  Loss: 0.3197713792324066\n",
      "Step 8  Loss: 0.3480600118637085\n",
      "Step 9  Loss: 0.31462645530700684\n",
      "Step 10  Loss: 0.3617936670780182\n",
      "total Loss of epoch  413  is  3.7681273818016052\n",
      "Step 0  Loss: 0.3793695569038391\n",
      "Step 1  Loss: 0.4231488108634949\n",
      "Step 2  Loss: 0.42327797412872314\n",
      "Step 3  Loss: 0.4302382171154022\n",
      "Step 4  Loss: 0.3834904432296753\n",
      "Step 5  Loss: 0.29686716198921204\n",
      "Step 6  Loss: 0.3494899868965149\n",
      "Step 7  Loss: 0.35121145844459534\n",
      "Step 8  Loss: 0.32544538378715515\n",
      "Step 9  Loss: 0.3675958812236786\n",
      "Step 10  Loss: 0.17813342809677124\n",
      "total Loss of epoch  414  is  3.908268302679062\n",
      "Step 0  Loss: 0.30203378200531006\n",
      "Step 1  Loss: 0.32075947523117065\n",
      "Step 2  Loss: 0.37385648488998413\n",
      "Step 3  Loss: 0.40930065512657166\n",
      "Step 4  Loss: 0.2680145502090454\n",
      "Step 5  Loss: 0.2790589928627014\n",
      "Step 6  Loss: 0.27775177359580994\n",
      "Step 7  Loss: 0.20518159866333008\n",
      "Step 8  Loss: 0.2420143038034439\n",
      "Step 9  Loss: 0.31049132347106934\n",
      "Step 10  Loss: 0.34395313262939453\n",
      "total Loss of epoch  415  is  3.332416072487831\n",
      "Step 0  Loss: 0.2892221510410309\n",
      "Step 1  Loss: 0.2358115017414093\n",
      "Step 2  Loss: 0.38302960991859436\n",
      "Step 3  Loss: 0.3801955282688141\n",
      "Step 4  Loss: 0.23981527984142303\n",
      "Step 5  Loss: 0.2850536108016968\n",
      "Step 6  Loss: 0.31191182136535645\n",
      "Step 7  Loss: 0.3833942115306854\n",
      "Step 8  Loss: 0.3362436592578888\n",
      "Step 9  Loss: 0.3783673644065857\n",
      "Step 10  Loss: 0.31694135069847107\n",
      "total Loss of epoch  416  is  3.539986088871956\n",
      "Step 0  Loss: 0.34418925642967224\n",
      "Step 1  Loss: 0.35522687435150146\n",
      "Step 2  Loss: 0.31689393520355225\n",
      "Step 3  Loss: 0.419015496969223\n",
      "Step 4  Loss: 0.3485979437828064\n",
      "Step 5  Loss: 0.38377809524536133\n",
      "Step 6  Loss: 0.2539616823196411\n",
      "Step 7  Loss: 0.3889840841293335\n",
      "Step 8  Loss: 0.2658396065235138\n",
      "Step 9  Loss: 0.2683238089084625\n",
      "Step 10  Loss: 0.4399208128452301\n",
      "total Loss of epoch  417  is  3.7847315967082977\n",
      "Step 0  Loss: 0.3486871123313904\n",
      "Step 1  Loss: 0.41837915778160095\n",
      "Step 2  Loss: 0.34663042426109314\n",
      "Step 3  Loss: 0.3105383813381195\n",
      "Step 4  Loss: 0.317769318819046\n",
      "Step 5  Loss: 0.4395441710948944\n",
      "Step 6  Loss: 0.354359894990921\n",
      "Step 7  Loss: 0.3928355872631073\n",
      "Step 8  Loss: 0.3695061206817627\n",
      "Step 9  Loss: 0.29377108812332153\n",
      "Step 10  Loss: 0.24971385300159454\n",
      "total Loss of epoch  418  is  3.8417351096868515\n",
      "Step 0  Loss: 0.4286050498485565\n",
      "Step 1  Loss: 0.4416644871234894\n",
      "Step 2  Loss: 0.3242151439189911\n",
      "Step 3  Loss: 0.34589117765426636\n",
      "Step 4  Loss: 0.29732972383499146\n",
      "Step 5  Loss: 0.34568339586257935\n",
      "Step 6  Loss: 0.24701541662216187\n",
      "Step 7  Loss: 0.2993108928203583\n",
      "Step 8  Loss: 0.3415093421936035\n",
      "Step 9  Loss: 0.31489554047584534\n",
      "Step 10  Loss: 0.32774874567985535\n",
      "total Loss of epoch  419  is  3.7138689160346985\n",
      "Step 0  Loss: 0.4052581489086151\n",
      "Step 1  Loss: 0.3269944190979004\n",
      "Step 2  Loss: 0.2978925108909607\n",
      "Step 3  Loss: 0.35436493158340454\n",
      "Step 4  Loss: 0.3851833939552307\n",
      "Step 5  Loss: 0.2833104729652405\n",
      "Step 6  Loss: 0.27537432312965393\n",
      "Step 7  Loss: 0.4661405384540558\n",
      "Step 8  Loss: 0.2500278353691101\n",
      "Step 9  Loss: 0.37286898493766785\n",
      "Step 10  Loss: 0.3636985421180725\n",
      "total Loss of epoch  420  is  3.781114101409912\n",
      "Step 0  Loss: 0.46458739042282104\n",
      "Step 1  Loss: 0.3341042995452881\n",
      "Step 2  Loss: 0.35953834652900696\n",
      "Step 3  Loss: 0.2910468578338623\n",
      "Step 4  Loss: 0.23140479624271393\n",
      "Step 5  Loss: 0.40057024359703064\n",
      "Step 6  Loss: 0.3313281834125519\n",
      "Step 7  Loss: 0.4068397581577301\n",
      "Step 8  Loss: 0.37808936834335327\n",
      "Step 9  Loss: 0.37462425231933594\n",
      "Step 10  Loss: 0.3954445719718933\n",
      "total Loss of epoch  421  is  3.9675780683755875\n",
      "Step 0  Loss: 0.2955332398414612\n",
      "Step 1  Loss: 0.3826345205307007\n",
      "Step 2  Loss: 0.29035651683807373\n",
      "Step 3  Loss: 0.2631426751613617\n",
      "Step 4  Loss: 0.357234925031662\n",
      "Step 5  Loss: 0.3664492070674896\n",
      "Step 6  Loss: 0.3739377558231354\n",
      "Step 7  Loss: 0.3548087179660797\n",
      "Step 8  Loss: 0.30874669551849365\n",
      "Step 9  Loss: 0.2907430827617645\n",
      "Step 10  Loss: 0.5026915669441223\n",
      "total Loss of epoch  422  is  3.7862789034843445\n",
      "Step 0  Loss: 0.38822972774505615\n",
      "Step 1  Loss: 0.3046582341194153\n",
      "Step 2  Loss: 0.3850950300693512\n",
      "Step 3  Loss: 0.38007599115371704\n",
      "Step 4  Loss: 0.3623082935810089\n",
      "Step 5  Loss: 0.39690646529197693\n",
      "Step 6  Loss: 0.399624228477478\n",
      "Step 7  Loss: 0.36382588744163513\n",
      "Step 8  Loss: 0.32795679569244385\n",
      "Step 9  Loss: 0.26303204894065857\n",
      "Step 10  Loss: 0.27380961179733276\n",
      "total Loss of epoch  423  is  3.845522314310074\n",
      "Step 0  Loss: 0.2768479585647583\n",
      "Step 1  Loss: 0.36044201254844666\n",
      "Step 2  Loss: 0.37667909264564514\n",
      "Step 3  Loss: 0.4146105945110321\n",
      "Step 4  Loss: 0.4372667968273163\n",
      "Step 5  Loss: 0.2909230589866638\n",
      "Step 6  Loss: 0.3060382604598999\n",
      "Step 7  Loss: 0.4286825656890869\n",
      "Step 8  Loss: 0.3692720830440521\n",
      "Step 9  Loss: 0.42365002632141113\n",
      "Step 10  Loss: 0.23079922795295715\n",
      "total Loss of epoch  424  is  3.9152116775512695\n",
      "Step 0  Loss: 0.32653459906578064\n",
      "Step 1  Loss: 0.3402167856693268\n",
      "Step 2  Loss: 0.33971643447875977\n",
      "Step 3  Loss: 0.42202433943748474\n",
      "Step 4  Loss: 0.41905122995376587\n",
      "Step 5  Loss: 0.4404906928539276\n",
      "Step 6  Loss: 0.2875325083732605\n",
      "Step 7  Loss: 0.3265283703804016\n",
      "Step 8  Loss: 0.4011358320713043\n",
      "Step 9  Loss: 0.43750685453414917\n",
      "Step 10  Loss: 0.3385586440563202\n",
      "total Loss of epoch  425  is  4.079296290874481\n",
      "Step 0  Loss: 0.3301205635070801\n",
      "Step 1  Loss: 0.3369706869125366\n",
      "Step 2  Loss: 0.32277393341064453\n",
      "Step 3  Loss: 0.29711395502090454\n",
      "Step 4  Loss: 0.29452458024024963\n",
      "Step 5  Loss: 0.3418461084365845\n",
      "Step 6  Loss: 0.34501537680625916\n",
      "Step 7  Loss: 0.3693820536136627\n",
      "Step 8  Loss: 0.30558934807777405\n",
      "Step 9  Loss: 0.41323789954185486\n",
      "Step 10  Loss: 0.4798455536365509\n",
      "total Loss of epoch  426  is  3.8364200592041016\n",
      "Step 0  Loss: 0.3799314498901367\n",
      "Step 1  Loss: 0.33801940083503723\n",
      "Step 2  Loss: 0.40784454345703125\n",
      "Step 3  Loss: 0.355918288230896\n",
      "Step 4  Loss: 0.27018094062805176\n",
      "Step 5  Loss: 0.3052675426006317\n",
      "Step 6  Loss: 0.3569256365299225\n",
      "Step 7  Loss: 0.3109847605228424\n",
      "Step 8  Loss: 0.3675042390823364\n",
      "Step 9  Loss: 0.28246065974235535\n",
      "Step 10  Loss: 0.4140041172504425\n",
      "total Loss of epoch  427  is  3.789041578769684\n",
      "Step 0  Loss: 0.18859216570854187\n",
      "Step 1  Loss: 0.38650521636009216\n",
      "Step 2  Loss: 0.30376511812210083\n",
      "Step 3  Loss: 0.2356945276260376\n",
      "Step 4  Loss: 0.4655599892139435\n",
      "Step 5  Loss: 0.3530034124851227\n",
      "Step 6  Loss: 0.29032114148139954\n",
      "Step 7  Loss: 0.41925105452537537\n",
      "Step 8  Loss: 0.40353983640670776\n",
      "Step 9  Loss: 0.3413617014884949\n",
      "Step 10  Loss: 0.2581266462802887\n",
      "total Loss of epoch  428  is  3.645720809698105\n",
      "Step 0  Loss: 0.1841825693845749\n",
      "Step 1  Loss: 0.36386826634407043\n",
      "Step 2  Loss: 0.2845183312892914\n",
      "Step 3  Loss: 0.28471580147743225\n",
      "Step 4  Loss: 0.34006887674331665\n",
      "Step 5  Loss: 0.42320603132247925\n",
      "Step 6  Loss: 0.24512405693531036\n",
      "Step 7  Loss: 0.3083718717098236\n",
      "Step 8  Loss: 0.34055015444755554\n",
      "Step 9  Loss: 0.3610326051712036\n",
      "Step 10  Loss: 0.4216775894165039\n",
      "total Loss of epoch  429  is  3.557316154241562\n",
      "Step 0  Loss: 0.36760467290878296\n",
      "Step 1  Loss: 0.3495451509952545\n",
      "Step 2  Loss: 0.3705330491065979\n",
      "Step 3  Loss: 0.3216369152069092\n",
      "Step 4  Loss: 0.31486842036247253\n",
      "Step 5  Loss: 0.37855619192123413\n",
      "Step 6  Loss: 0.2955678403377533\n",
      "Step 7  Loss: 0.3699840307235718\n",
      "Step 8  Loss: 0.35349971055984497\n",
      "Step 9  Loss: 0.4041936695575714\n",
      "Step 10  Loss: 0.34427887201309204\n",
      "total Loss of epoch  430  is  3.8702685236930847\n",
      "Step 0  Loss: 0.27148109674453735\n",
      "Step 1  Loss: 0.3404447138309479\n",
      "Step 2  Loss: 0.3851008713245392\n",
      "Step 3  Loss: 0.3787885308265686\n",
      "Step 4  Loss: 0.28995680809020996\n",
      "Step 5  Loss: 0.46877145767211914\n",
      "Step 6  Loss: 0.45763522386550903\n",
      "Step 7  Loss: 0.4331805408000946\n",
      "Step 8  Loss: 0.5193560719490051\n",
      "Step 9  Loss: 0.4470210373401642\n",
      "Step 10  Loss: 0.21374551951885223\n",
      "total Loss of epoch  431  is  4.205481871962547\n",
      "Step 0  Loss: 0.3376627564430237\n",
      "Step 1  Loss: 0.4004152715206146\n",
      "Step 2  Loss: 0.3156221807003021\n",
      "Step 3  Loss: 0.32033586502075195\n",
      "Step 4  Loss: 0.40189284086227417\n",
      "Step 5  Loss: 0.22316133975982666\n",
      "Step 6  Loss: 0.2408199906349182\n",
      "Step 7  Loss: 0.4071427285671234\n",
      "Step 8  Loss: 0.32181182503700256\n",
      "Step 9  Loss: 0.3395024836063385\n",
      "Step 10  Loss: 0.45695605874061584\n",
      "total Loss of epoch  432  is  3.7653233408927917\n",
      "Step 0  Loss: 0.3731309771537781\n",
      "Step 1  Loss: 0.2749646008014679\n",
      "Step 2  Loss: 0.3075915277004242\n",
      "Step 3  Loss: 0.330191969871521\n",
      "Step 4  Loss: 0.3446787893772125\n",
      "Step 5  Loss: 0.4509647488594055\n",
      "Step 6  Loss: 0.3895629644393921\n",
      "Step 7  Loss: 0.4222709536552429\n",
      "Step 8  Loss: 0.38362812995910645\n",
      "Step 9  Loss: 0.38801437616348267\n",
      "Step 10  Loss: 0.3628450334072113\n",
      "total Loss of epoch  433  is  4.027844071388245\n",
      "Step 0  Loss: 0.3196394145488739\n",
      "Step 1  Loss: 0.3734903335571289\n",
      "Step 2  Loss: 0.2915497124195099\n",
      "Step 3  Loss: 0.3187512159347534\n",
      "Step 4  Loss: 0.3633847236633301\n",
      "Step 5  Loss: 0.42345693707466125\n",
      "Step 6  Loss: 0.3329107165336609\n",
      "Step 7  Loss: 0.35234010219573975\n",
      "Step 8  Loss: 0.31963205337524414\n",
      "Step 9  Loss: 0.19324038922786713\n",
      "Step 10  Loss: 0.40183794498443604\n",
      "total Loss of epoch  434  is  3.6902335435152054\n",
      "Step 0  Loss: 0.39888495206832886\n",
      "Step 1  Loss: 0.3403487801551819\n",
      "Step 2  Loss: 0.44220560789108276\n",
      "Step 3  Loss: 0.4231671392917633\n",
      "Step 4  Loss: 0.3513336181640625\n",
      "Step 5  Loss: 0.3727740943431854\n",
      "Step 6  Loss: 0.4524909555912018\n",
      "Step 7  Loss: 0.375620037317276\n",
      "Step 8  Loss: 0.2742881178855896\n",
      "Step 9  Loss: 0.4294866621494293\n",
      "Step 10  Loss: 0.39487412571907043\n",
      "total Loss of epoch  435  is  4.255474090576172\n",
      "Step 0  Loss: 0.3467104732990265\n",
      "Step 1  Loss: 0.379187673330307\n",
      "Step 2  Loss: 0.34505221247673035\n",
      "Step 3  Loss: 0.32730215787887573\n",
      "Step 4  Loss: 0.31173187494277954\n",
      "Step 5  Loss: 0.3156324028968811\n",
      "Step 6  Loss: 0.25559407472610474\n",
      "Step 7  Loss: 0.31467339396476746\n",
      "Step 8  Loss: 0.34514307975769043\n",
      "Step 9  Loss: 0.40243470668792725\n",
      "Step 10  Loss: 0.28834328055381775\n",
      "total Loss of epoch  436  is  3.631805330514908\n",
      "Step 0  Loss: 0.38540077209472656\n",
      "Step 1  Loss: 0.4600397050380707\n",
      "Step 2  Loss: 0.3057149350643158\n",
      "Step 3  Loss: 0.33443328738212585\n",
      "Step 4  Loss: 0.3149150311946869\n",
      "Step 5  Loss: 0.4306083619594574\n",
      "Step 6  Loss: 0.32738858461380005\n",
      "Step 7  Loss: 0.3984028100967407\n",
      "Step 8  Loss: 0.3858695328235626\n",
      "Step 9  Loss: 0.421735554933548\n",
      "Step 10  Loss: 0.38769641518592834\n",
      "total Loss of epoch  437  is  4.152204990386963\n",
      "Step 0  Loss: 0.4195975959300995\n",
      "Step 1  Loss: 0.46636924147605896\n",
      "Step 2  Loss: 0.39196380972862244\n",
      "Step 3  Loss: 0.4240932762622833\n",
      "Step 4  Loss: 0.29106733202934265\n",
      "Step 5  Loss: 0.3230127990245819\n",
      "Step 6  Loss: 0.44027575850486755\n",
      "Step 7  Loss: 0.3469795882701874\n",
      "Step 8  Loss: 0.3095031678676605\n",
      "Step 9  Loss: 0.3263256549835205\n",
      "Step 10  Loss: 0.2605137228965759\n",
      "total Loss of epoch  438  is  3.9997019469738007\n",
      "Step 0  Loss: 0.3191796541213989\n",
      "Step 1  Loss: 0.32585620880126953\n",
      "Step 2  Loss: 0.2192152440547943\n",
      "Step 3  Loss: 0.3688298463821411\n",
      "Step 4  Loss: 0.2694184482097626\n",
      "Step 5  Loss: 0.33334794640541077\n",
      "Step 6  Loss: 0.1851770430803299\n",
      "Step 7  Loss: 0.44276729226112366\n",
      "Step 8  Loss: 0.38692912459373474\n",
      "Step 9  Loss: 0.34244418144226074\n",
      "Step 10  Loss: 0.376444935798645\n",
      "total Loss of epoch  439  is  3.5696099251508713\n",
      "Step 0  Loss: 0.3927030861377716\n",
      "Step 1  Loss: 0.3415515422821045\n",
      "Step 2  Loss: 0.3401203155517578\n",
      "Step 3  Loss: 0.35671818256378174\n",
      "Step 4  Loss: 0.3604455292224884\n",
      "Step 5  Loss: 0.3365512192249298\n",
      "Step 6  Loss: 0.292054682970047\n",
      "Step 7  Loss: 0.35799872875213623\n",
      "Step 8  Loss: 0.4122886657714844\n",
      "Step 9  Loss: 0.3292522132396698\n",
      "Step 10  Loss: 0.30054405331611633\n",
      "total Loss of epoch  440  is  3.8202282190322876\n",
      "Step 0  Loss: 0.360600084066391\n",
      "Step 1  Loss: 0.31172093749046326\n",
      "Step 2  Loss: 0.36132457852363586\n",
      "Step 3  Loss: 0.429117888212204\n",
      "Step 4  Loss: 0.31495141983032227\n",
      "Step 5  Loss: 0.2791120111942291\n",
      "Step 6  Loss: 0.2795315384864807\n",
      "Step 7  Loss: 0.26384177803993225\n",
      "Step 8  Loss: 0.39443179965019226\n",
      "Step 9  Loss: 0.40522539615631104\n",
      "Step 10  Loss: 0.2765099108219147\n",
      "total Loss of epoch  441  is  3.6763673424720764\n",
      "Step 0  Loss: 0.3139224350452423\n",
      "Step 1  Loss: 0.39776891469955444\n",
      "Step 2  Loss: 0.4762286841869354\n",
      "Step 3  Loss: 0.3820864260196686\n",
      "Step 4  Loss: 0.25524258613586426\n",
      "Step 5  Loss: 0.38420161604881287\n",
      "Step 6  Loss: 0.3607294261455536\n",
      "Step 7  Loss: 0.5102465152740479\n",
      "Step 8  Loss: 0.361369788646698\n",
      "Step 9  Loss: 0.3081597685813904\n",
      "Step 10  Loss: 0.3018111288547516\n",
      "total Loss of epoch  442  is  4.051767289638519\n",
      "Step 0  Loss: 0.3837699890136719\n",
      "Step 1  Loss: 0.3468201756477356\n",
      "Step 2  Loss: 0.39321187138557434\n",
      "Step 3  Loss: 0.42111852765083313\n",
      "Step 4  Loss: 0.2679170072078705\n",
      "Step 5  Loss: 0.3964287042617798\n",
      "Step 6  Loss: 0.4290042221546173\n",
      "Step 7  Loss: 0.3136966824531555\n",
      "Step 8  Loss: 0.2753194272518158\n",
      "Step 9  Loss: 0.3945629596710205\n",
      "Step 10  Loss: 0.45032596588134766\n",
      "total Loss of epoch  443  is  4.072175532579422\n",
      "Step 0  Loss: 0.3371446132659912\n",
      "Step 1  Loss: 0.2939899265766144\n",
      "Step 2  Loss: 0.25711607933044434\n",
      "Step 3  Loss: 0.3418803811073303\n",
      "Step 4  Loss: 0.3112356960773468\n",
      "Step 5  Loss: 0.36210495233535767\n",
      "Step 6  Loss: 0.2996852993965149\n",
      "Step 7  Loss: 0.323110431432724\n",
      "Step 8  Loss: 0.2690110504627228\n",
      "Step 9  Loss: 0.36340847611427307\n",
      "Step 10  Loss: 0.32564255595207214\n",
      "total Loss of epoch  444  is  3.4843294620513916\n",
      "Step 0  Loss: 0.3787536919116974\n",
      "Step 1  Loss: 0.34651175141334534\n",
      "Step 2  Loss: 0.3150594234466553\n",
      "Step 3  Loss: 0.4555150270462036\n",
      "Step 4  Loss: 0.33258429169654846\n",
      "Step 5  Loss: 0.3498508334159851\n",
      "Step 6  Loss: 0.41329890489578247\n",
      "Step 7  Loss: 0.31389719247817993\n",
      "Step 8  Loss: 0.3495595455169678\n",
      "Step 9  Loss: 0.48457109928131104\n",
      "Step 10  Loss: 0.3497433364391327\n",
      "total Loss of epoch  445  is  4.089345097541809\n",
      "Step 0  Loss: 0.30113568902015686\n",
      "Step 1  Loss: 0.35551029443740845\n",
      "Step 2  Loss: 0.29646047949790955\n",
      "Step 3  Loss: 0.34545645117759705\n",
      "Step 4  Loss: 0.4333968460559845\n",
      "Step 5  Loss: 0.3206748068332672\n",
      "Step 6  Loss: 0.34120216965675354\n",
      "Step 7  Loss: 0.28012001514434814\n",
      "Step 8  Loss: 0.24406595528125763\n",
      "Step 9  Loss: 0.4124574065208435\n",
      "Step 10  Loss: 0.2815987169742584\n",
      "total Loss of epoch  446  is  3.612078830599785\n",
      "Step 0  Loss: 0.3514758050441742\n",
      "Step 1  Loss: 0.3404988944530487\n",
      "Step 2  Loss: 0.37314462661743164\n",
      "Step 3  Loss: 0.3411208987236023\n",
      "Step 4  Loss: 0.3944258987903595\n",
      "Step 5  Loss: 0.44576960802078247\n",
      "Step 6  Loss: 0.3833783268928528\n",
      "Step 7  Loss: 0.3158458173274994\n",
      "Step 8  Loss: 0.38014695048332214\n",
      "Step 9  Loss: 0.29058489203453064\n",
      "Step 10  Loss: 0.2750326693058014\n",
      "total Loss of epoch  447  is  3.891424387693405\n",
      "Step 0  Loss: 0.35871800780296326\n",
      "Step 1  Loss: 0.30641674995422363\n",
      "Step 2  Loss: 0.36818233132362366\n",
      "Step 3  Loss: 0.24035443365573883\n",
      "Step 4  Loss: 0.38328641653060913\n",
      "Step 5  Loss: 0.4909186065196991\n",
      "Step 6  Loss: 0.21521984040737152\n",
      "Step 7  Loss: 0.24182118475437164\n",
      "Step 8  Loss: 0.33239614963531494\n",
      "Step 9  Loss: 0.36434611678123474\n",
      "Step 10  Loss: 0.3760068416595459\n",
      "total Loss of epoch  448  is  3.6776666790246964\n",
      "Step 0  Loss: 0.2750126123428345\n",
      "Step 1  Loss: 0.40794214606285095\n",
      "Step 2  Loss: 0.3259042501449585\n",
      "Step 3  Loss: 0.4035404920578003\n",
      "Step 4  Loss: 0.3695220649242401\n",
      "Step 5  Loss: 0.344939261674881\n",
      "Step 6  Loss: 0.42783665657043457\n",
      "Step 7  Loss: 0.2800620496273041\n",
      "Step 8  Loss: 0.3754998743534088\n",
      "Step 9  Loss: 0.3687646985054016\n",
      "Step 10  Loss: 0.3212262690067291\n",
      "total Loss of epoch  449  is  3.9002503752708435\n",
      "Step 0  Loss: 0.3857921361923218\n",
      "Step 1  Loss: 0.4630851447582245\n",
      "Step 2  Loss: 0.22917714715003967\n",
      "Step 3  Loss: 0.37303394079208374\n",
      "Step 4  Loss: 0.36973127722740173\n",
      "Step 5  Loss: 0.30442729592323303\n",
      "Step 6  Loss: 0.4679071605205536\n",
      "Step 7  Loss: 0.39404699206352234\n",
      "Step 8  Loss: 0.4007168114185333\n",
      "Step 9  Loss: 0.393023282289505\n",
      "Step 10  Loss: 0.4975891709327698\n",
      "total Loss of epoch  450  is  4.2785303592681885\n",
      "Step 0  Loss: 0.3081532418727875\n",
      "Step 1  Loss: 0.46813011169433594\n",
      "Step 2  Loss: 0.3314287066459656\n",
      "Step 3  Loss: 0.3529365062713623\n",
      "Step 4  Loss: 0.33936822414398193\n",
      "Step 5  Loss: 0.18295401334762573\n",
      "Step 6  Loss: 0.26625490188598633\n",
      "Step 7  Loss: 0.3642841577529907\n",
      "Step 8  Loss: 0.31152647733688354\n",
      "Step 9  Loss: 0.4132069945335388\n",
      "Step 10  Loss: 0.39391636848449707\n",
      "total Loss of epoch  451  is  3.7321597039699554\n",
      "Step 0  Loss: 0.4646218419075012\n",
      "Step 1  Loss: 0.28245264291763306\n",
      "Step 2  Loss: 0.28197336196899414\n",
      "Step 3  Loss: 0.23139016330242157\n",
      "Step 4  Loss: 0.2871348261833191\n",
      "Step 5  Loss: 0.3318878412246704\n",
      "Step 6  Loss: 0.35118329524993896\n",
      "Step 7  Loss: 0.34742966294288635\n",
      "Step 8  Loss: 0.3245472311973572\n",
      "Step 9  Loss: 0.2675967514514923\n",
      "Step 10  Loss: 0.4319794774055481\n",
      "total Loss of epoch  452  is  3.6021970957517624\n",
      "Step 0  Loss: 0.36529991030693054\n",
      "Step 1  Loss: 0.2583453953266144\n",
      "Step 2  Loss: 0.3974023461341858\n",
      "Step 3  Loss: 0.31335005164146423\n",
      "Step 4  Loss: 0.3718003034591675\n",
      "Step 5  Loss: 0.28124549984931946\n",
      "Step 6  Loss: 0.34922972321510315\n",
      "Step 7  Loss: 0.3224957585334778\n",
      "Step 8  Loss: 0.3952814042568207\n",
      "Step 9  Loss: 0.3930194675922394\n",
      "Step 10  Loss: 0.22386029362678528\n",
      "total Loss of epoch  453  is  3.671330153942108\n",
      "Step 0  Loss: 0.3251343369483948\n",
      "Step 1  Loss: 0.43597856163978577\n",
      "Step 2  Loss: 0.4240472614765167\n",
      "Step 3  Loss: 0.2641919255256653\n",
      "Step 4  Loss: 0.33768022060394287\n",
      "Step 5  Loss: 0.3350474536418915\n",
      "Step 6  Loss: 0.5182898640632629\n",
      "Step 7  Loss: 0.3596416115760803\n",
      "Step 8  Loss: 0.3293496370315552\n",
      "Step 9  Loss: 0.42233213782310486\n",
      "Step 10  Loss: 0.34668776392936707\n",
      "total Loss of epoch  454  is  4.098380774259567\n",
      "Step 0  Loss: 0.38557443022727966\n",
      "Step 1  Loss: 0.3642829358577728\n",
      "Step 2  Loss: 0.32870638370513916\n",
      "Step 3  Loss: 0.31630682945251465\n",
      "Step 4  Loss: 0.2583920955657959\n",
      "Step 5  Loss: 0.3682595491409302\n",
      "Step 6  Loss: 0.43445268273353577\n",
      "Step 7  Loss: 0.4528217911720276\n",
      "Step 8  Loss: 0.34735268354415894\n",
      "Step 9  Loss: 0.441782683134079\n",
      "Step 10  Loss: 0.40781548619270325\n",
      "total Loss of epoch  455  is  4.105747550725937\n",
      "Step 0  Loss: 0.35935571789741516\n",
      "Step 1  Loss: 0.3763057291507721\n",
      "Step 2  Loss: 0.3683395981788635\n",
      "Step 3  Loss: 0.2997741103172302\n",
      "Step 4  Loss: 0.3187060058116913\n",
      "Step 5  Loss: 0.27391165494918823\n",
      "Step 6  Loss: 0.434572696685791\n",
      "Step 7  Loss: 0.3317256271839142\n",
      "Step 8  Loss: 0.4875755310058594\n",
      "Step 9  Loss: 0.391383558511734\n",
      "Step 10  Loss: 0.32008108496665955\n",
      "total Loss of epoch  456  is  3.9617313146591187\n",
      "Step 0  Loss: 0.3101193904876709\n",
      "Step 1  Loss: 0.3046590983867645\n",
      "Step 2  Loss: 0.3790373206138611\n",
      "Step 3  Loss: 0.3080389201641083\n",
      "Step 4  Loss: 0.3672913908958435\n",
      "Step 5  Loss: 0.3979613482952118\n",
      "Step 6  Loss: 0.33241742849349976\n",
      "Step 7  Loss: 0.3446906805038452\n",
      "Step 8  Loss: 0.3347182869911194\n",
      "Step 9  Loss: 0.3591044247150421\n",
      "Step 10  Loss: 0.3458794355392456\n",
      "total Loss of epoch  457  is  3.783917725086212\n",
      "Step 0  Loss: 0.38333624601364136\n",
      "Step 1  Loss: 0.38471296429634094\n",
      "Step 2  Loss: 0.3197430670261383\n",
      "Step 3  Loss: 0.3246154487133026\n",
      "Step 4  Loss: 0.3407721221446991\n",
      "Step 5  Loss: 0.398395299911499\n",
      "Step 6  Loss: 0.30025362968444824\n",
      "Step 7  Loss: 0.34534695744514465\n",
      "Step 8  Loss: 0.31386256217956543\n",
      "Step 9  Loss: 0.361331582069397\n",
      "Step 10  Loss: 0.3809806704521179\n",
      "total Loss of epoch  458  is  3.8533505499362946\n",
      "Step 0  Loss: 0.29764628410339355\n",
      "Step 1  Loss: 0.33991172909736633\n",
      "Step 2  Loss: 0.33805811405181885\n",
      "Step 3  Loss: 0.3015044629573822\n",
      "Step 4  Loss: 0.41710686683654785\n",
      "Step 5  Loss: 0.4896089434623718\n",
      "Step 6  Loss: 0.3352871537208557\n",
      "Step 7  Loss: 0.3513157069683075\n",
      "Step 8  Loss: 0.447799950838089\n",
      "Step 9  Loss: 0.3898424804210663\n",
      "Step 10  Loss: 0.4236428141593933\n",
      "total Loss of epoch  459  is  4.131724506616592\n",
      "Step 0  Loss: 0.37176457047462463\n",
      "Step 1  Loss: 0.3209281265735626\n",
      "Step 2  Loss: 0.38737937808036804\n",
      "Step 3  Loss: 0.4664694368839264\n",
      "Step 4  Loss: 0.41774415969848633\n",
      "Step 5  Loss: 0.33631521463394165\n",
      "Step 6  Loss: 0.2614167332649231\n",
      "Step 7  Loss: 0.2981363832950592\n",
      "Step 8  Loss: 0.356786847114563\n",
      "Step 9  Loss: 0.3524331748485565\n",
      "Step 10  Loss: 0.510718584060669\n",
      "total Loss of epoch  460  is  4.08009260892868\n",
      "Step 0  Loss: 0.3146432638168335\n",
      "Step 1  Loss: 0.3770803213119507\n",
      "Step 2  Loss: 0.2239151895046234\n",
      "Step 3  Loss: 0.3580784499645233\n",
      "Step 4  Loss: 0.3779754042625427\n",
      "Step 5  Loss: 0.31777989864349365\n",
      "Step 6  Loss: 0.2889587879180908\n",
      "Step 7  Loss: 0.411679744720459\n",
      "Step 8  Loss: 0.2282337099313736\n",
      "Step 9  Loss: 0.3668002188205719\n",
      "Step 10  Loss: 0.34929823875427246\n",
      "total Loss of epoch  461  is  3.614443227648735\n",
      "Step 0  Loss: 0.2869599461555481\n",
      "Step 1  Loss: 0.2957819998264313\n",
      "Step 2  Loss: 0.35149168968200684\n",
      "Step 3  Loss: 0.26573681831359863\n",
      "Step 4  Loss: 0.42427802085876465\n",
      "Step 5  Loss: 0.26377445459365845\n",
      "Step 6  Loss: 0.3496380150318146\n",
      "Step 7  Loss: 0.2574518024921417\n",
      "Step 8  Loss: 0.36168423295021057\n",
      "Step 9  Loss: 0.3057766556739807\n",
      "Step 10  Loss: 0.3013986051082611\n",
      "total Loss of epoch  462  is  3.4639722406864166\n",
      "Step 0  Loss: 0.3141014575958252\n",
      "Step 1  Loss: 0.33389654755592346\n",
      "Step 2  Loss: 0.418075293302536\n",
      "Step 3  Loss: 0.3243884742259979\n",
      "Step 4  Loss: 0.2803422808647156\n",
      "Step 5  Loss: 0.3751937747001648\n",
      "Step 6  Loss: 0.3549845218658447\n",
      "Step 7  Loss: 0.34156954288482666\n",
      "Step 8  Loss: 0.3210222125053406\n",
      "Step 9  Loss: 0.371061772108078\n",
      "Step 10  Loss: 0.42170774936676025\n",
      "total Loss of epoch  463  is  3.856343626976013\n",
      "Step 0  Loss: 0.27868539094924927\n",
      "Step 1  Loss: 0.4320354163646698\n",
      "Step 2  Loss: 0.48687291145324707\n",
      "Step 3  Loss: 0.2965272068977356\n",
      "Step 4  Loss: 0.34852728247642517\n",
      "Step 5  Loss: 0.4871149957180023\n",
      "Step 6  Loss: 0.1992277204990387\n",
      "Step 7  Loss: 0.31790611147880554\n",
      "Step 8  Loss: 0.3765060305595398\n",
      "Step 9  Loss: 0.30389493703842163\n",
      "Step 10  Loss: 0.2587127089500427\n",
      "total Loss of epoch  464  is  3.7860107123851776\n",
      "Step 0  Loss: 0.39215588569641113\n",
      "Step 1  Loss: 0.22823068499565125\n",
      "Step 2  Loss: 0.33166757225990295\n",
      "Step 3  Loss: 0.3676755428314209\n",
      "Step 4  Loss: 0.2517850399017334\n",
      "Step 5  Loss: 0.3336242437362671\n",
      "Step 6  Loss: 0.20358826220035553\n",
      "Step 7  Loss: 0.3105368912220001\n",
      "Step 8  Loss: 0.31085288524627686\n",
      "Step 9  Loss: 0.24750567972660065\n",
      "Step 10  Loss: 0.37121647596359253\n",
      "total Loss of epoch  465  is  3.3488391637802124\n",
      "Step 0  Loss: 0.33055946230888367\n",
      "Step 1  Loss: 0.38137462735176086\n",
      "Step 2  Loss: 0.3328722417354584\n",
      "Step 3  Loss: 0.3876186013221741\n",
      "Step 4  Loss: 0.3019612431526184\n",
      "Step 5  Loss: 0.3486686944961548\n",
      "Step 6  Loss: 0.3283975124359131\n",
      "Step 7  Loss: 0.37558260560035706\n",
      "Step 8  Loss: 0.43421122431755066\n",
      "Step 9  Loss: 0.36721423268318176\n",
      "Step 10  Loss: 0.386463463306427\n",
      "total Loss of epoch  466  is  3.9749239087104797\n",
      "Step 0  Loss: 0.4219655692577362\n",
      "Step 1  Loss: 0.33260685205459595\n",
      "Step 2  Loss: 0.33746427297592163\n",
      "Step 3  Loss: 0.4059799909591675\n",
      "Step 4  Loss: 0.32303985953330994\n",
      "Step 5  Loss: 0.23488111793994904\n",
      "Step 6  Loss: 0.279293417930603\n",
      "Step 7  Loss: 0.41801756620407104\n",
      "Step 8  Loss: 0.22921352088451385\n",
      "Step 9  Loss: 0.44690102338790894\n",
      "Step 10  Loss: 0.43229103088378906\n",
      "total Loss of epoch  467  is  3.861654222011566\n",
      "Step 0  Loss: 0.2454853653907776\n",
      "Step 1  Loss: 0.3692554235458374\n",
      "Step 2  Loss: 0.389510840177536\n",
      "Step 3  Loss: 0.2791813611984253\n",
      "Step 4  Loss: 0.4678908884525299\n",
      "Step 5  Loss: 0.5064772367477417\n",
      "Step 6  Loss: 0.3022281527519226\n",
      "Step 7  Loss: 0.28464189171791077\n",
      "Step 8  Loss: 0.31258389353752136\n",
      "Step 9  Loss: 0.4321824312210083\n",
      "Step 10  Loss: 0.26970598101615906\n",
      "total Loss of epoch  468  is  3.85914346575737\n",
      "Step 0  Loss: 0.4139632284641266\n",
      "Step 1  Loss: 0.41219010949134827\n",
      "Step 2  Loss: 0.35972803831100464\n",
      "Step 3  Loss: 0.41226667165756226\n",
      "Step 4  Loss: 0.287014901638031\n",
      "Step 5  Loss: 0.48126354813575745\n",
      "Step 6  Loss: 0.34331777691841125\n",
      "Step 7  Loss: 0.4367476999759674\n",
      "Step 8  Loss: 0.3936471939086914\n",
      "Step 9  Loss: 0.4744237959384918\n",
      "Step 10  Loss: 0.29482465982437134\n",
      "total Loss of epoch  469  is  4.309387624263763\n",
      "Step 0  Loss: 0.4418540894985199\n",
      "Step 1  Loss: 0.4141380786895752\n",
      "Step 2  Loss: 0.1981532722711563\n",
      "Step 3  Loss: 0.33095088601112366\n",
      "Step 4  Loss: 0.3012349605560303\n",
      "Step 5  Loss: 0.40271657705307007\n",
      "Step 6  Loss: 0.3676295280456543\n",
      "Step 7  Loss: 0.23986247181892395\n",
      "Step 8  Loss: 0.33644580841064453\n",
      "Step 9  Loss: 0.34037113189697266\n",
      "Step 10  Loss: 0.35387709736824036\n",
      "total Loss of epoch  470  is  3.727233901619911\n",
      "Step 0  Loss: 0.34103405475616455\n",
      "Step 1  Loss: 0.471833735704422\n",
      "Step 2  Loss: 0.31131821870803833\n",
      "Step 3  Loss: 0.4124376177787781\n",
      "Step 4  Loss: 0.4807274341583252\n",
      "Step 5  Loss: 0.2195809930562973\n",
      "Step 6  Loss: 0.3196773827075958\n",
      "Step 7  Loss: 0.4124664068222046\n",
      "Step 8  Loss: 0.3667142987251282\n",
      "Step 9  Loss: 0.3446711301803589\n",
      "Step 10  Loss: 0.3682762384414673\n",
      "total Loss of epoch  471  is  4.04873751103878\n",
      "Step 0  Loss: 0.40037888288497925\n",
      "Step 1  Loss: 0.3221954107284546\n",
      "Step 2  Loss: 0.2830931544303894\n",
      "Step 3  Loss: 0.2610990107059479\n",
      "Step 4  Loss: 0.2540930211544037\n",
      "Step 5  Loss: 0.28465932607650757\n",
      "Step 6  Loss: 0.2455148547887802\n",
      "Step 7  Loss: 0.3205011785030365\n",
      "Step 8  Loss: 0.2754581570625305\n",
      "Step 9  Loss: 0.3057957589626312\n",
      "Step 10  Loss: 0.3954913020133972\n",
      "total Loss of epoch  472  is  3.348280057311058\n",
      "Step 0  Loss: 0.36315175890922546\n",
      "Step 1  Loss: 0.2667137384414673\n",
      "Step 2  Loss: 0.25501149892807007\n",
      "Step 3  Loss: 0.31619182229042053\n",
      "Step 4  Loss: 0.3103295564651489\n",
      "Step 5  Loss: 0.349793016910553\n",
      "Step 6  Loss: 0.262664258480072\n",
      "Step 7  Loss: 0.3445124328136444\n",
      "Step 8  Loss: 0.38544923067092896\n",
      "Step 9  Loss: 0.2816145718097687\n",
      "Step 10  Loss: 0.3954630494117737\n",
      "total Loss of epoch  473  is  3.530894935131073\n",
      "Step 0  Loss: 0.41281870007514954\n",
      "Step 1  Loss: 0.39320918917655945\n",
      "Step 2  Loss: 0.31455039978027344\n",
      "Step 3  Loss: 0.38256749510765076\n",
      "Step 4  Loss: 0.4416602849960327\n",
      "Step 5  Loss: 0.19586075842380524\n",
      "Step 6  Loss: 0.3267620801925659\n",
      "Step 7  Loss: 0.29327091574668884\n",
      "Step 8  Loss: 0.4397740960121155\n",
      "Step 9  Loss: 0.5114348530769348\n",
      "Step 10  Loss: 0.2805310785770416\n",
      "total Loss of epoch  474  is  3.992439851164818\n",
      "Step 0  Loss: 0.3059593439102173\n",
      "Step 1  Loss: 0.3496522605419159\n",
      "Step 2  Loss: 0.3332195580005646\n",
      "Step 3  Loss: 0.37925994396209717\n",
      "Step 4  Loss: 0.27563461661338806\n",
      "Step 5  Loss: 0.42507049441337585\n",
      "Step 6  Loss: 0.37541908025741577\n",
      "Step 7  Loss: 0.37984880805015564\n",
      "Step 8  Loss: 0.3518649935722351\n",
      "Step 9  Loss: 0.44632402062416077\n",
      "Step 10  Loss: 0.5468098521232605\n",
      "total Loss of epoch  475  is  4.169062972068787\n",
      "Step 0  Loss: 0.22821277379989624\n",
      "Step 1  Loss: 0.2951180338859558\n",
      "Step 2  Loss: 0.4152752161026001\n",
      "Step 3  Loss: 0.33446231484413147\n",
      "Step 4  Loss: 0.371561735868454\n",
      "Step 5  Loss: 0.29129719734191895\n",
      "Step 6  Loss: 0.36474063992500305\n",
      "Step 7  Loss: 0.3819497227668762\n",
      "Step 8  Loss: 0.3656396269798279\n",
      "Step 9  Loss: 0.3273617625236511\n",
      "Step 10  Loss: 0.2865816354751587\n",
      "total Loss of epoch  476  is  3.6622006595134735\n",
      "Step 0  Loss: 0.24241597950458527\n",
      "Step 1  Loss: 0.44882428646087646\n",
      "Step 2  Loss: 0.3800399899482727\n",
      "Step 3  Loss: 0.3223627209663391\n",
      "Step 4  Loss: 0.44965609908103943\n",
      "Step 5  Loss: 0.39037224650382996\n",
      "Step 6  Loss: 0.2978394031524658\n",
      "Step 7  Loss: 0.3089158535003662\n",
      "Step 8  Loss: 0.5148966908454895\n",
      "Step 9  Loss: 0.30926236510276794\n",
      "Step 10  Loss: 0.4351898431777954\n",
      "total Loss of epoch  477  is  4.099775478243828\n",
      "Step 0  Loss: 0.33668357133865356\n",
      "Step 1  Loss: 0.38582843542099\n",
      "Step 2  Loss: 0.33370187878608704\n",
      "Step 3  Loss: 0.3174617886543274\n",
      "Step 4  Loss: 0.39167705178260803\n",
      "Step 5  Loss: 0.3664960265159607\n",
      "Step 6  Loss: 0.3702651560306549\n",
      "Step 7  Loss: 0.28470101952552795\n",
      "Step 8  Loss: 0.4955420196056366\n",
      "Step 9  Loss: 0.3690074384212494\n",
      "Step 10  Loss: 0.32119759917259216\n",
      "total Loss of epoch  478  is  3.9725619852542877\n",
      "Step 0  Loss: 0.2280234545469284\n",
      "Step 1  Loss: 0.3229801654815674\n",
      "Step 2  Loss: 0.3406100869178772\n",
      "Step 3  Loss: 0.32388588786125183\n",
      "Step 4  Loss: 0.32999277114868164\n",
      "Step 5  Loss: 0.3637702167034149\n",
      "Step 6  Loss: 0.3029056787490845\n",
      "Step 7  Loss: 0.40660667419433594\n",
      "Step 8  Loss: 0.3335348665714264\n",
      "Step 9  Loss: 0.27779754996299744\n",
      "Step 10  Loss: 0.19266550242900848\n",
      "total Loss of epoch  479  is  3.422772854566574\n",
      "Step 0  Loss: 0.49563711881637573\n",
      "Step 1  Loss: 0.2688222825527191\n",
      "Step 2  Loss: 0.28068864345550537\n",
      "Step 3  Loss: 0.3562282621860504\n",
      "Step 4  Loss: 0.4196295142173767\n",
      "Step 5  Loss: 0.35608771443367004\n",
      "Step 6  Loss: 0.4075869023799896\n",
      "Step 7  Loss: 0.42214030027389526\n",
      "Step 8  Loss: 0.3286797106266022\n",
      "Step 9  Loss: 0.37679120898246765\n",
      "Step 10  Loss: 0.41228538751602173\n",
      "total Loss of epoch  480  is  4.124577045440674\n",
      "Step 0  Loss: 0.3988635540008545\n",
      "Step 1  Loss: 0.27082788944244385\n",
      "Step 2  Loss: 0.3508308231830597\n",
      "Step 3  Loss: 0.4141883850097656\n",
      "Step 4  Loss: 0.45904120802879333\n",
      "Step 5  Loss: 0.3378439247608185\n",
      "Step 6  Loss: 0.4583119750022888\n",
      "Step 7  Loss: 0.3195352256298065\n",
      "Step 8  Loss: 0.30220770835876465\n",
      "Step 9  Loss: 0.3904097378253937\n",
      "Step 10  Loss: 0.4069517254829407\n",
      "total Loss of epoch  481  is  4.10901215672493\n",
      "Step 0  Loss: 0.3061702847480774\n",
      "Step 1  Loss: 0.34798339009284973\n",
      "Step 2  Loss: 0.23971813917160034\n",
      "Step 3  Loss: 0.3218356966972351\n",
      "Step 4  Loss: 0.36652684211730957\n",
      "Step 5  Loss: 0.318170964717865\n",
      "Step 6  Loss: 0.406990110874176\n",
      "Step 7  Loss: 0.41749680042266846\n",
      "Step 8  Loss: 0.36009132862091064\n",
      "Step 9  Loss: 0.30278486013412476\n",
      "Step 10  Loss: 0.3392334282398224\n",
      "total Loss of epoch  482  is  3.7270018458366394\n",
      "Step 0  Loss: 0.38797488808631897\n",
      "Step 1  Loss: 0.3002631366252899\n",
      "Step 2  Loss: 0.2844510078430176\n",
      "Step 3  Loss: 0.4554789364337921\n",
      "Step 4  Loss: 0.30035778880119324\n",
      "Step 5  Loss: 0.352579265832901\n",
      "Step 6  Loss: 0.2952454686164856\n",
      "Step 7  Loss: 0.32556596398353577\n",
      "Step 8  Loss: 0.40368616580963135\n",
      "Step 9  Loss: 0.31843701004981995\n",
      "Step 10  Loss: 0.2947220206260681\n",
      "total Loss of epoch  483  is  3.7187616527080536\n",
      "Step 0  Loss: 0.3804871439933777\n",
      "Step 1  Loss: 0.3284667730331421\n",
      "Step 2  Loss: 0.2660573422908783\n",
      "Step 3  Loss: 0.38829007744789124\n",
      "Step 4  Loss: 0.2579007148742676\n",
      "Step 5  Loss: 0.49190977215766907\n",
      "Step 6  Loss: 0.33477309346199036\n",
      "Step 7  Loss: 0.4203443229198456\n",
      "Step 8  Loss: 0.3238341212272644\n",
      "Step 9  Loss: 0.41235244274139404\n",
      "Step 10  Loss: 0.19123396277427673\n",
      "total Loss of epoch  484  is  3.795649766921997\n",
      "Step 0  Loss: 0.36883267760276794\n",
      "Step 1  Loss: 0.43061843514442444\n",
      "Step 2  Loss: 0.4081920385360718\n",
      "Step 3  Loss: 0.31476062536239624\n",
      "Step 4  Loss: 0.42318013310432434\n",
      "Step 5  Loss: 0.36162248253822327\n",
      "Step 6  Loss: 0.3538527488708496\n",
      "Step 7  Loss: 0.41311630606651306\n",
      "Step 8  Loss: 0.2728654444217682\n",
      "Step 9  Loss: 0.4217558801174164\n",
      "Step 10  Loss: 0.3003084063529968\n",
      "total Loss of epoch  485  is  4.069105178117752\n",
      "Step 0  Loss: 0.37632519006729126\n",
      "Step 1  Loss: 0.2832798659801483\n",
      "Step 2  Loss: 0.3451904058456421\n",
      "Step 3  Loss: 0.32691219449043274\n",
      "Step 4  Loss: 0.3070165812969208\n",
      "Step 5  Loss: 0.33160051703453064\n",
      "Step 6  Loss: 0.25176456570625305\n",
      "Step 7  Loss: 0.29986318945884705\n",
      "Step 8  Loss: 0.42582276463508606\n",
      "Step 9  Loss: 0.3209727108478546\n",
      "Step 10  Loss: 0.41857150197029114\n",
      "total Loss of epoch  486  is  3.6873194873332977\n",
      "Step 0  Loss: 0.2440568059682846\n",
      "Step 1  Loss: 0.42881086468696594\n",
      "Step 2  Loss: 0.25508084893226624\n",
      "Step 3  Loss: 0.33600395917892456\n",
      "Step 4  Loss: 0.35076338052749634\n",
      "Step 5  Loss: 0.36369526386260986\n",
      "Step 6  Loss: 0.2441175878047943\n",
      "Step 7  Loss: 0.399293452501297\n",
      "Step 8  Loss: 0.4214276671409607\n",
      "Step 9  Loss: 0.3947156071662903\n",
      "Step 10  Loss: 0.3264544904232025\n",
      "total Loss of epoch  487  is  3.7644199281930923\n",
      "Step 0  Loss: 0.34073883295059204\n",
      "Step 1  Loss: 0.37186720967292786\n",
      "Step 2  Loss: 0.3864319920539856\n",
      "Step 3  Loss: 0.40027835965156555\n",
      "Step 4  Loss: 0.366830974817276\n",
      "Step 5  Loss: 0.3602515161037445\n",
      "Step 6  Loss: 0.3222416639328003\n",
      "Step 7  Loss: 0.33535078167915344\n",
      "Step 8  Loss: 0.2824643552303314\n",
      "Step 9  Loss: 0.387433797121048\n",
      "Step 10  Loss: 0.2895125448703766\n",
      "total Loss of epoch  488  is  3.8434020280838013\n",
      "Step 0  Loss: 0.2767827808856964\n",
      "Step 1  Loss: 0.40223589539527893\n",
      "Step 2  Loss: 0.3685742914676666\n",
      "Step 3  Loss: 0.3975936770439148\n",
      "Step 4  Loss: 0.32460662722587585\n",
      "Step 5  Loss: 0.36794978380203247\n",
      "Step 6  Loss: 0.4904266595840454\n",
      "Step 7  Loss: 0.2981904447078705\n",
      "Step 8  Loss: 0.3379920721054077\n",
      "Step 9  Loss: 0.3175434172153473\n",
      "Step 10  Loss: 0.39212921261787415\n",
      "total Loss of epoch  489  is  3.97402486205101\n",
      "Step 0  Loss: 0.4381341338157654\n",
      "Step 1  Loss: 0.3050258159637451\n",
      "Step 2  Loss: 0.2505407929420471\n",
      "Step 3  Loss: 0.42372676730155945\n",
      "Step 4  Loss: 0.3208726942539215\n",
      "Step 5  Loss: 0.29411250352859497\n",
      "Step 6  Loss: 0.3735096752643585\n",
      "Step 7  Loss: 0.38070929050445557\n",
      "Step 8  Loss: 0.3713032901287079\n",
      "Step 9  Loss: 0.42237362265586853\n",
      "Step 10  Loss: 0.35561442375183105\n",
      "total Loss of epoch  490  is  3.935923010110855\n",
      "Step 0  Loss: 0.2966018319129944\n",
      "Step 1  Loss: 0.41111499071121216\n",
      "Step 2  Loss: 0.4556313157081604\n",
      "Step 3  Loss: 0.2657085359096527\n",
      "Step 4  Loss: 0.4632315933704376\n",
      "Step 5  Loss: 0.33946871757507324\n",
      "Step 6  Loss: 0.378143846988678\n",
      "Step 7  Loss: 0.3750821352005005\n",
      "Step 8  Loss: 0.19618456065654755\n",
      "Step 9  Loss: 0.3098912835121155\n",
      "Step 10  Loss: 0.36834198236465454\n",
      "total Loss of epoch  491  is  3.8594007939100266\n",
      "Step 0  Loss: 0.35552024841308594\n",
      "Step 1  Loss: 0.3545913100242615\n",
      "Step 2  Loss: 0.4479790925979614\n",
      "Step 3  Loss: 0.45557209849357605\n",
      "Step 4  Loss: 0.33300015330314636\n",
      "Step 5  Loss: 0.3990168869495392\n",
      "Step 6  Loss: 0.3157331943511963\n",
      "Step 7  Loss: 0.3238533139228821\n",
      "Step 8  Loss: 0.48798638582229614\n",
      "Step 9  Loss: 0.3369406759738922\n",
      "Step 10  Loss: 0.4073368310928345\n",
      "total Loss of epoch  492  is  4.217530190944672\n",
      "Step 0  Loss: 0.4291301369667053\n",
      "Step 1  Loss: 0.36572301387786865\n",
      "Step 2  Loss: 0.4139680564403534\n",
      "Step 3  Loss: 0.4460684359073639\n",
      "Step 4  Loss: 0.4253447949886322\n",
      "Step 5  Loss: 0.3694016933441162\n",
      "Step 6  Loss: 0.25401464104652405\n",
      "Step 7  Loss: 0.31678929924964905\n",
      "Step 8  Loss: 0.30520302057266235\n",
      "Step 9  Loss: 0.3207496702671051\n",
      "Step 10  Loss: 0.2945278584957123\n",
      "total Loss of epoch  493  is  3.9409206211566925\n",
      "Step 0  Loss: 0.30142316222190857\n",
      "Step 1  Loss: 0.4084445834159851\n",
      "Step 2  Loss: 0.2339818924665451\n",
      "Step 3  Loss: 0.29599428176879883\n",
      "Step 4  Loss: 0.3607794940471649\n",
      "Step 5  Loss: 0.38369056582450867\n",
      "Step 6  Loss: 0.30751991271972656\n",
      "Step 7  Loss: 0.305225133895874\n",
      "Step 8  Loss: 0.4488317668437958\n",
      "Step 9  Loss: 0.3483666181564331\n",
      "Step 10  Loss: 0.25439831614494324\n",
      "total Loss of epoch  494  is  3.648655727505684\n",
      "Step 0  Loss: 0.44228002429008484\n",
      "Step 1  Loss: 0.28233200311660767\n",
      "Step 2  Loss: 0.4242197573184967\n",
      "Step 3  Loss: 0.47334492206573486\n",
      "Step 4  Loss: 0.4428098201751709\n",
      "Step 5  Loss: 0.2763631045818329\n",
      "Step 6  Loss: 0.23909564316272736\n",
      "Step 7  Loss: 0.39074674248695374\n",
      "Step 8  Loss: 0.2873866558074951\n",
      "Step 9  Loss: 0.27230390906333923\n",
      "Step 10  Loss: 0.19165121018886566\n",
      "total Loss of epoch  495  is  3.722533792257309\n",
      "Step 0  Loss: 0.3608470559120178\n",
      "Step 1  Loss: 0.290666788816452\n",
      "Step 2  Loss: 0.49311473965644836\n",
      "Step 3  Loss: 0.33349844813346863\n",
      "Step 4  Loss: 0.34436216950416565\n",
      "Step 5  Loss: 0.45433616638183594\n",
      "Step 6  Loss: 0.3816543221473694\n",
      "Step 7  Loss: 0.4103776812553406\n",
      "Step 8  Loss: 0.317074179649353\n",
      "Step 9  Loss: 0.3246156573295593\n",
      "Step 10  Loss: 0.3890535235404968\n",
      "total Loss of epoch  496  is  4.099600732326508\n",
      "Step 0  Loss: 0.3829498887062073\n",
      "Step 1  Loss: 0.3389544188976288\n",
      "Step 2  Loss: 0.32963892817497253\n",
      "Step 3  Loss: 0.30095693469047546\n",
      "Step 4  Loss: 0.34495627880096436\n",
      "Step 5  Loss: 0.41304558515548706\n",
      "Step 6  Loss: 0.32504427433013916\n",
      "Step 7  Loss: 0.30239054560661316\n",
      "Step 8  Loss: 0.29710379242897034\n",
      "Step 9  Loss: 0.3174825608730316\n",
      "Step 10  Loss: 0.3509818911552429\n",
      "total Loss of epoch  497  is  3.7035050988197327\n",
      "Step 0  Loss: 0.4172162711620331\n",
      "Step 1  Loss: 0.41208067536354065\n",
      "Step 2  Loss: 0.3000396192073822\n",
      "Step 3  Loss: 0.42545801401138306\n",
      "Step 4  Loss: 0.31415891647338867\n",
      "Step 5  Loss: 0.30106768012046814\n",
      "Step 6  Loss: 0.4005517363548279\n",
      "Step 7  Loss: 0.35803136229515076\n",
      "Step 8  Loss: 0.4216918647289276\n",
      "Step 9  Loss: 0.24722512066364288\n",
      "Step 10  Loss: 0.3114405870437622\n",
      "total Loss of epoch  498  is  3.908961847424507\n",
      "Step 0  Loss: 0.3416084051132202\n",
      "Step 1  Loss: 0.38812726736068726\n",
      "Step 2  Loss: 0.4353608787059784\n",
      "Step 3  Loss: 0.343423992395401\n",
      "Step 4  Loss: 0.2681058943271637\n",
      "Step 5  Loss: 0.3114546835422516\n",
      "Step 6  Loss: 0.39629799127578735\n",
      "Step 7  Loss: 0.3798074424266815\n",
      "Step 8  Loss: 0.35732361674308777\n",
      "Step 9  Loss: 0.33562594652175903\n",
      "Step 10  Loss: 0.41600072383880615\n",
      "total Loss of epoch  499  is  3.973136842250824\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(n_epochs)):\n",
    "    spike_gen_obj = get_batches(real_train_trial_spikes_stand,batch_size)\n",
    "    emg_gen_obj = get_batches(real_train_trial_vel_tide,batch_size)\n",
    "    for ii in range(n_batches):\n",
    "        optimizer.zero_grad()\n",
    "        spike_batch = next(spike_gen_obj)\n",
    "        emg_batch = next(emg_gen_obj)\n",
    "\n",
    "        spike_batch = Variable(torch.from_numpy(spike_batch)).float()\n",
    "        emg_batch = Variable(torch.from_numpy(emg_batch)).float()\n",
    "\n",
    "        # Loss\n",
    "        batch_loss = get_loss(model, spike_batch, emg_batch)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_total_loss = get_loss(model, spike_val, emg_val)\n",
    "        loss_list.append(val_total_loss.item())\n",
    "\n",
    "        _, _, train_latents, _ = model(spike_train, train_flag = False)\n",
    "\n",
    "        if val_total_loss < pre_total_loss_: \n",
    "            pre_total_loss_ = val_total_loss\n",
    "            torch.save(model.state_dict(),'model_checkpoints/source_vae_model_new')\n",
    "\n",
    "\n",
    "            np.save(\"./npy_files/train_latents_new.npy\",train_latents)\n",
    "\n",
    "        \n",
    "    train_latents = np.expand_dims(train_latents,1).astype(np.float32)\n",
    "    train_spike_data = train_latents.transpose(0,1,3,2)\n",
    "\n",
    "\n",
    "    dataloader = DataLoader(train_spike_data, batch_size=global_batch_size)\n",
    "\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        dm_optimizer.zero_grad()\n",
    "\n",
    "        batch_size = batch.shape[0]\n",
    "        batch = batch.to(device)\n",
    "\n",
    "\n",
    "        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "        loss = p_losses(dm_model, batch, t)\n",
    "\n",
    "        print(\"Step\", step, \" Loss:\", loss.item())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        dm_optimizer.step()\n",
    "\n",
    "    print(\"total Loss of epoch \", epoch, \" is \", total_loss)\n",
    "\n",
    "    if total_loss < pre_loss:\n",
    "        pre_loss = total_loss\n",
    "        torch.save(dm_model.state_dict(), 'model_checkpoints/source_diffusion_model_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
