{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for running ERDiff alignment step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Source Domain: Training\n",
    "\n",
    "Code for training is `VAE_Diffusion_CoTrain.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from model_functions.Diffusion import *\n",
    "from model_functions.VAE import *\n",
    "from model_functions.ERDiff_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set loggers to save the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('train_logger')\n",
    "logger.setLevel(level=logging.INFO)\n",
    "handler = logging.FileHandler('train.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "# logger.addHandler(console)\n",
    "logger.info('python logging test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load source domain data\n",
    "\n",
    "- trial spikes: neural firing rates\n",
    "- trial vel: velocity\n",
    "- trial dir: labels of direction, 8 classes\n",
    "\n",
    "<img src=\"images/monkey_data.png\" width=\"10%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the trial length and number of neurons\n",
    "len_trial,num_neurons = 37, 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/Neural_Source.pkl', 'rb') as f:\n",
    "    train_data1 = pickle.load(f)['data']\n",
    "train_trial_spikes1, train_trial_vel1, train_trial_dir1 = train_data1['firing_rates'], train_data1['velocity'], train_data1['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 209 trials, for each trial, the time length to use is 37 (minimal trial length - 1), number of neurons is 187, dimension of velocity is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_trial_spikes1[i].shape[0] for i in range(len(train_trial_spikes1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 37, 187)\n",
      "(209, 37, 2)\n"
     ]
    }
   ],
   "source": [
    "start_pos = 1 \n",
    "end_pos = 1\n",
    "\n",
    "train_trial_spikes_tide1 = np.array([spike[start_pos:len_trial+start_pos, :num_neurons] for spike in train_trial_spikes1])\n",
    "print(np.shape(train_trial_spikes_tide1))\n",
    "\n",
    "train_trial_vel_tide1 = np.array([spike[start_pos:len_trial+start_pos, :] for spike in train_trial_vel1])\n",
    "print(np.shape(train_trial_vel_tide1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209,)\n"
     ]
    }
   ],
   "source": [
    "array_train_trial_dir1 = np.expand_dims(np.array((train_trial_dir1), dtype=object),1)\n",
    "\n",
    "train_trial_spikes_tide = train_trial_spikes_tide1\n",
    "train_trial_vel_tide = train_trial_vel_tide1\n",
    "train_trial_dic_tide = np.squeeze(np.vstack([array_train_trial_dir1]))\n",
    "print(np.shape(train_trial_dic_tide))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data preprocessing\n",
    "\n",
    "Apply gaussian smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431380/2824986634.py:5: DeprecationWarning: Importing gaussian from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.gaussian' or the convenience function 'scipy.signal.get_window' instead.\n",
      "  window = signal.gaussian(kern_sd, kern_sd, sym=True)\n"
     ]
    }
   ],
   "source": [
    "bin_width = float(0.02) * 1000\n",
    "\n",
    "kern_sd_ms = 100\n",
    "kern_sd = int(round(kern_sd_ms / bin_width))\n",
    "window = signal.gaussian(kern_sd, kern_sd, sym=True)\n",
    "window /= np.sum(window)\n",
    "filt = lambda x: np.convolve(x, window, 'same')\n",
    "\n",
    "train_trial_spikes_smoothed = np.apply_along_axis(filt, 1, train_trial_spikes_tide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 37, 187)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trial_spikes_smoothed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Randomly shuffled and split to train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_trial_spikes_tide.shape[0])\n",
    "np.random.seed(2023) \n",
    "np.random.shuffle(indices)\n",
    "train_len = round(len(indices) * 0.80)\n",
    "real_train_trial_spikes_smed, val_trial_spikes_smed = train_trial_spikes_smoothed[indices[:train_len]], train_trial_spikes_smoothed[indices[train_len:]]\n",
    "real_train_trial_vel_tide, val_trial_vel_tide = train_trial_vel_tide[indices[:train_len]], train_trial_vel_tide[indices[train_len:]]\n",
    "real_train_trial_dic_tide, val_trial_dic_tide = train_trial_dic_tide[indices[:train_len]], train_trial_dic_tide[indices[train_len:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches: 10\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1\n",
    "n_epochs = 500\n",
    "batch_size = 16\n",
    "ae_res_weight = 10\n",
    "kld_weight = 1\n",
    "n_batches = len(real_train_trial_spikes_smed)//batch_size\n",
    "print(\"number of batches:\", n_batches)\n",
    "\n",
    "mse_criterion = nn.MSELoss()\n",
    "poisson_criterion = nn.PoissonNLLLoss(log_input=False)\n",
    "\n",
    "l_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Build the model\n",
    "\n",
    "<img src=\"images/training.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, spike, emg):\n",
    "    re_sp_, vel_hat_,mu, log_var = model(spike, train_flag= True)\n",
    "    ae_loss = poisson_criterion(re_sp_, spike)\n",
    "    emg_loss = mse_criterion(vel_hat_, emg)\n",
    "    kld_loss = torch.mean(0.5 * (- log_var + mu ** 2 + log_var.exp() - 1))\n",
    "    total_loss = ae_res_weight * ae_loss + emg_loss + kld_weight * kld_loss\n",
    "    # total_loss = ae_res_weight * ae_loss \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "\n",
    "# define beta schedule\n",
    "betas = quadratic_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spikes = np.load(\"npy_files/train_latents.npy\")\n",
    "train_spike_data = np.expand_dims(train_spikes,1).astype(np.float32)\n",
    "train_spike_data = train_spike_data.transpose(0,1,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 1, 8, 37)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spike_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_trial_spikes_stand = (real_train_trial_spikes_smed)\n",
    "val_trial_spikes_stand = (val_trial_spikes_smed)\n",
    "\n",
    "spike_train = Variable(torch.from_numpy(real_train_trial_spikes_stand)).float()\n",
    "spike_val = Variable(torch.from_numpy(val_trial_spikes_stand)).float()\n",
    "\n",
    "emg_train = Variable(torch.from_numpy(real_train_trial_vel_tide)).float()\n",
    "emg_val = Variable(torch.from_numpy(val_trial_vel_tide)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 16\n",
    "dataloader = DataLoader(train_spike_data, batch_size=global_batch_size)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "dm_model = diff_STBlock(input_dim)\n",
    "dm_model.to(device)\n",
    "\n",
    "dm_optimizer = Adam(dm_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_loss = 1e10 # Save the loss\n",
    "\n",
    "pre_total_loss_ = 1e18\n",
    "last_improvement = 0\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431380/3446123673.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(n_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381b4c6d2e73415d9fadddc618b909be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0  Loss: 0.8132175207138062\n",
      "Step 1  Loss: 0.8100867867469788\n",
      "Step 2  Loss: 0.815028727054596\n",
      "Step 3  Loss: 0.7940422296524048\n",
      "Step 4  Loss: 0.8037274479866028\n",
      "Step 5  Loss: 0.7856090664863586\n",
      "Step 6  Loss: 0.7988925576210022\n",
      "Step 7  Loss: 0.759097158908844\n",
      "Step 8  Loss: 0.78489089012146\n",
      "Step 9  Loss: 0.7787379622459412\n",
      "Step 10  Loss: 0.7785270810127258\n",
      "total Loss of epoch  0  is  8.72185742855072\n",
      "Step 0  Loss: 0.7721797227859497\n",
      "Step 1  Loss: 0.7777519822120667\n",
      "Step 2  Loss: 0.7556346654891968\n",
      "Step 3  Loss: 0.7643831372261047\n",
      "Step 4  Loss: 0.7534956932067871\n",
      "Step 5  Loss: 0.7568359375\n",
      "Step 6  Loss: 0.6874943971633911\n",
      "Step 7  Loss: 0.7476314902305603\n",
      "Step 8  Loss: 0.750187337398529\n",
      "Step 9  Loss: 0.6666913628578186\n",
      "Step 10  Loss: 0.6706206798553467\n",
      "total Loss of epoch  1  is  8.10290640592575\n",
      "Step 0  Loss: 0.722862184047699\n",
      "Step 1  Loss: 0.6638414859771729\n",
      "Step 2  Loss: 0.6517336964607239\n",
      "Step 3  Loss: 0.6163535118103027\n",
      "Step 4  Loss: 0.640303373336792\n",
      "Step 5  Loss: 0.6266642212867737\n",
      "Step 6  Loss: 0.6678681969642639\n",
      "Step 7  Loss: 0.6049181222915649\n",
      "Step 8  Loss: 0.6292149424552917\n",
      "Step 9  Loss: 0.6248226761817932\n",
      "Step 10  Loss: 0.7344162464141846\n",
      "total Loss of epoch  2  is  7.1829986572265625\n",
      "Step 0  Loss: 0.5855158567428589\n",
      "Step 1  Loss: 0.5557811260223389\n",
      "Step 2  Loss: 0.5984665155410767\n",
      "Step 3  Loss: 0.5684541463851929\n",
      "Step 4  Loss: 0.6509855389595032\n",
      "Step 5  Loss: 0.6316131949424744\n",
      "Step 6  Loss: 0.5740971565246582\n",
      "Step 7  Loss: 0.508941113948822\n",
      "Step 8  Loss: 0.5564259886741638\n",
      "Step 9  Loss: 0.5295884609222412\n",
      "Step 10  Loss: 0.49420884251594543\n",
      "total Loss of epoch  3  is  6.2540779411792755\n",
      "Step 0  Loss: 0.6627985835075378\n",
      "Step 1  Loss: 0.5442561507225037\n",
      "Step 2  Loss: 0.5179654955863953\n",
      "Step 3  Loss: 0.5598078370094299\n",
      "Step 4  Loss: 0.520146906375885\n",
      "Step 5  Loss: 0.49900999665260315\n",
      "Step 6  Loss: 0.4576256275177002\n",
      "Step 7  Loss: 0.43096885085105896\n",
      "Step 8  Loss: 0.5451064109802246\n",
      "Step 9  Loss: 0.5211852192878723\n",
      "Step 10  Loss: 0.57140052318573\n",
      "total Loss of epoch  4  is  5.830271601676941\n",
      "Step 0  Loss: 0.47860151529312134\n",
      "Step 1  Loss: 0.5463253855705261\n",
      "Step 2  Loss: 0.4640824794769287\n",
      "Step 3  Loss: 0.4995194673538208\n",
      "Step 4  Loss: 0.46400555968284607\n",
      "Step 5  Loss: 0.48599934577941895\n",
      "Step 6  Loss: 0.48662811517715454\n",
      "Step 7  Loss: 0.49021804332733154\n",
      "Step 8  Loss: 0.4558158814907074\n",
      "Step 9  Loss: 0.5156055092811584\n",
      "Step 10  Loss: 0.512175440788269\n",
      "total Loss of epoch  5  is  5.398976743221283\n",
      "Step 0  Loss: 0.4642431437969208\n",
      "Step 1  Loss: 0.5754060745239258\n",
      "Step 2  Loss: 0.451386034488678\n",
      "Step 3  Loss: 0.6759236454963684\n",
      "Step 4  Loss: 0.5035780072212219\n",
      "Step 5  Loss: 0.4346003830432892\n",
      "Step 6  Loss: 0.5316064357757568\n",
      "Step 7  Loss: 0.6006717085838318\n",
      "Step 8  Loss: 0.46112382411956787\n",
      "Step 9  Loss: 0.5895775556564331\n",
      "Step 10  Loss: 0.5628286600112915\n",
      "total Loss of epoch  6  is  5.850945472717285\n",
      "Step 0  Loss: 0.570776641368866\n",
      "Step 1  Loss: 0.5326471328735352\n",
      "Step 2  Loss: 0.5474341511726379\n",
      "Step 3  Loss: 0.39854422211647034\n",
      "Step 4  Loss: 0.4037722051143646\n",
      "Step 5  Loss: 0.5018683671951294\n",
      "Step 6  Loss: 0.5505801439285278\n",
      "Step 7  Loss: 0.43109190464019775\n",
      "Step 8  Loss: 0.4273293614387512\n",
      "Step 9  Loss: 0.5168551802635193\n",
      "Step 10  Loss: 0.49855682253837585\n",
      "total Loss of epoch  7  is  5.379456132650375\n",
      "Step 0  Loss: 0.4102737009525299\n",
      "Step 1  Loss: 0.5119010210037231\n",
      "Step 2  Loss: 0.5283455848693848\n",
      "Step 3  Loss: 0.54054856300354\n",
      "Step 4  Loss: 0.5461592078208923\n",
      "Step 5  Loss: 0.457454651594162\n",
      "Step 6  Loss: 0.5408343076705933\n",
      "Step 7  Loss: 0.4739660322666168\n",
      "Step 8  Loss: 0.6301785111427307\n",
      "Step 9  Loss: 0.42095664143562317\n",
      "Step 10  Loss: 0.5912430882453918\n",
      "total Loss of epoch  8  is  5.651861310005188\n",
      "Step 0  Loss: 0.5442198514938354\n",
      "Step 1  Loss: 0.5980894565582275\n",
      "Step 2  Loss: 0.5033489465713501\n",
      "Step 3  Loss: 0.4787169396877289\n",
      "Step 4  Loss: 0.5307159423828125\n",
      "Step 5  Loss: 0.48480623960494995\n",
      "Step 6  Loss: 0.5370659828186035\n",
      "Step 7  Loss: 0.45919960737228394\n",
      "Step 8  Loss: 0.539596438407898\n",
      "Step 9  Loss: 0.42107704281806946\n",
      "Step 10  Loss: 0.6437847018241882\n",
      "total Loss of epoch  9  is  5.7406211495399475\n",
      "Step 0  Loss: 0.5570430159568787\n",
      "Step 1  Loss: 0.5151507258415222\n",
      "Step 2  Loss: 0.5177521109580994\n",
      "Step 3  Loss: 0.5119715929031372\n",
      "Step 4  Loss: 0.4712999761104584\n",
      "Step 5  Loss: 0.48549044132232666\n",
      "Step 6  Loss: 0.45935720205307007\n",
      "Step 7  Loss: 0.4656224846839905\n",
      "Step 8  Loss: 0.4256158769130707\n",
      "Step 9  Loss: 0.5489023327827454\n",
      "Step 10  Loss: 0.35849663615226746\n",
      "total Loss of epoch  10  is  5.3167023956775665\n",
      "Step 0  Loss: 0.5622599720954895\n",
      "Step 1  Loss: 0.4484643340110779\n",
      "Step 2  Loss: 0.4096761643886566\n",
      "Step 3  Loss: 0.5390247702598572\n",
      "Step 4  Loss: 0.4484761357307434\n",
      "Step 5  Loss: 0.4501982033252716\n",
      "Step 6  Loss: 0.39356228709220886\n",
      "Step 7  Loss: 0.5638990998268127\n",
      "Step 8  Loss: 0.45171913504600525\n",
      "Step 9  Loss: 0.46888425946235657\n",
      "Step 10  Loss: 0.42844006419181824\n",
      "total Loss of epoch  11  is  5.164604425430298\n",
      "Step 0  Loss: 0.4667604863643646\n",
      "Step 1  Loss: 0.5448434352874756\n",
      "Step 2  Loss: 0.5696102976799011\n",
      "Step 3  Loss: 0.42665570974349976\n",
      "Step 4  Loss: 0.5687262415885925\n",
      "Step 5  Loss: 0.44321879744529724\n",
      "Step 6  Loss: 0.521186351776123\n",
      "Step 7  Loss: 0.4591991901397705\n",
      "Step 8  Loss: 0.46337246894836426\n",
      "Step 9  Loss: 0.6116235852241516\n",
      "Step 10  Loss: 0.4032515585422516\n",
      "total Loss of epoch  12  is  5.478448122739792\n",
      "Step 0  Loss: 0.4654763340950012\n",
      "Step 1  Loss: 0.4560513496398926\n",
      "Step 2  Loss: 0.4346829056739807\n",
      "Step 3  Loss: 0.6387239694595337\n",
      "Step 4  Loss: 0.5179254412651062\n",
      "Step 5  Loss: 0.43969011306762695\n",
      "Step 6  Loss: 0.4932602643966675\n",
      "Step 7  Loss: 0.5021906495094299\n",
      "Step 8  Loss: 0.4172872304916382\n",
      "Step 9  Loss: 0.5366186499595642\n",
      "Step 10  Loss: 0.3129168450832367\n",
      "total Loss of epoch  13  is  5.214823752641678\n",
      "Step 0  Loss: 0.5508594512939453\n",
      "Step 1  Loss: 0.43352600932121277\n",
      "Step 2  Loss: 0.4865747392177582\n",
      "Step 3  Loss: 0.48902109265327454\n",
      "Step 4  Loss: 0.3376682698726654\n",
      "Step 5  Loss: 0.5119100213050842\n",
      "Step 6  Loss: 0.4643394351005554\n",
      "Step 7  Loss: 0.45026683807373047\n",
      "Step 8  Loss: 0.5161059498786926\n",
      "Step 9  Loss: 0.4159877598285675\n",
      "Step 10  Loss: 0.5736621022224426\n",
      "total Loss of epoch  14  is  5.229921668767929\n",
      "Step 0  Loss: 0.5611841678619385\n",
      "Step 1  Loss: 0.4893495738506317\n",
      "Step 2  Loss: 0.5124757885932922\n",
      "Step 3  Loss: 0.5169920921325684\n",
      "Step 4  Loss: 0.4200367331504822\n",
      "Step 5  Loss: 0.4784836769104004\n",
      "Step 6  Loss: 0.5254791975021362\n",
      "Step 7  Loss: 0.3587948679924011\n",
      "Step 8  Loss: 0.4918157458305359\n",
      "Step 9  Loss: 0.5578185319900513\n",
      "Step 10  Loss: 0.4572138488292694\n",
      "total Loss of epoch  15  is  5.369644224643707\n",
      "Step 0  Loss: 0.4796302020549774\n",
      "Step 1  Loss: 0.4804774224758148\n",
      "Step 2  Loss: 0.5866367220878601\n",
      "Step 3  Loss: 0.45957469940185547\n",
      "Step 4  Loss: 0.5428488254547119\n",
      "Step 5  Loss: 0.4180341958999634\n",
      "Step 6  Loss: 0.5581017732620239\n",
      "Step 7  Loss: 0.4984334707260132\n",
      "Step 8  Loss: 0.5484061241149902\n",
      "Step 9  Loss: 0.4650615453720093\n",
      "Step 10  Loss: 0.49232640862464905\n",
      "total Loss of epoch  16  is  5.529531389474869\n",
      "Step 0  Loss: 0.47511085867881775\n",
      "Step 1  Loss: 0.5052916407585144\n",
      "Step 2  Loss: 0.48041149973869324\n",
      "Step 3  Loss: 0.5926764011383057\n",
      "Step 4  Loss: 0.5677995681762695\n",
      "Step 5  Loss: 0.43172264099121094\n",
      "Step 6  Loss: 0.5214723348617554\n",
      "Step 7  Loss: 0.5709399580955505\n",
      "Step 8  Loss: 0.5851143598556519\n",
      "Step 9  Loss: 0.4752674698829651\n",
      "Step 10  Loss: 0.35090747475624084\n",
      "total Loss of epoch  17  is  5.556714206933975\n",
      "Step 0  Loss: 0.48450687527656555\n",
      "Step 1  Loss: 0.5247214436531067\n",
      "Step 2  Loss: 0.511725902557373\n",
      "Step 3  Loss: 0.49593162536621094\n",
      "Step 4  Loss: 0.44137945771217346\n",
      "Step 5  Loss: 0.46903228759765625\n",
      "Step 6  Loss: 0.5927451252937317\n",
      "Step 7  Loss: 0.41373294591903687\n",
      "Step 8  Loss: 0.6096620559692383\n",
      "Step 9  Loss: 0.5152313709259033\n",
      "Step 10  Loss: 0.5982556343078613\n",
      "total Loss of epoch  18  is  5.656924724578857\n",
      "Step 0  Loss: 0.4527554512023926\n",
      "Step 1  Loss: 0.5084694027900696\n",
      "Step 2  Loss: 0.43674007058143616\n",
      "Step 3  Loss: 0.4509385824203491\n",
      "Step 4  Loss: 0.5163775682449341\n",
      "Step 5  Loss: 0.5020498633384705\n",
      "Step 6  Loss: 0.5516501665115356\n",
      "Step 7  Loss: 0.5119187831878662\n",
      "Step 8  Loss: 0.4538121819496155\n",
      "Step 9  Loss: 0.5240572690963745\n",
      "Step 10  Loss: 0.3241572380065918\n",
      "total Loss of epoch  19  is  5.232926577329636\n",
      "Step 0  Loss: 0.4203302264213562\n",
      "Step 1  Loss: 0.4993884265422821\n",
      "Step 2  Loss: 0.5740464925765991\n",
      "Step 3  Loss: 0.589870274066925\n",
      "Step 4  Loss: 0.3743259906768799\n",
      "Step 5  Loss: 0.4092845618724823\n",
      "Step 6  Loss: 0.4558018445968628\n",
      "Step 7  Loss: 0.5374305248260498\n",
      "Step 8  Loss: 0.5381537675857544\n",
      "Step 9  Loss: 0.57313472032547\n",
      "Step 10  Loss: 0.4455050826072693\n",
      "total Loss of epoch  20  is  5.417271912097931\n",
      "Step 0  Loss: 0.4463115632534027\n",
      "Step 1  Loss: 0.4406232237815857\n",
      "Step 2  Loss: 0.5692676901817322\n",
      "Step 3  Loss: 0.4883287250995636\n",
      "Step 4  Loss: 0.5104271173477173\n",
      "Step 5  Loss: 0.3959019184112549\n",
      "Step 6  Loss: 0.5660547018051147\n",
      "Step 7  Loss: 0.6044840216636658\n",
      "Step 8  Loss: 0.36740371584892273\n",
      "Step 9  Loss: 0.3745380640029907\n",
      "Step 10  Loss: 0.5522255897521973\n",
      "total Loss of epoch  21  is  5.315566331148148\n",
      "Step 0  Loss: 0.46923381090164185\n",
      "Step 1  Loss: 0.5229243040084839\n",
      "Step 2  Loss: 0.502830982208252\n",
      "Step 3  Loss: 0.5739914178848267\n",
      "Step 4  Loss: 0.428118497133255\n",
      "Step 5  Loss: 0.4744649827480316\n",
      "Step 6  Loss: 0.4982774257659912\n",
      "Step 7  Loss: 0.5513308644294739\n",
      "Step 8  Loss: 0.4513710141181946\n",
      "Step 9  Loss: 0.46390023827552795\n",
      "Step 10  Loss: 0.4097876250743866\n",
      "total Loss of epoch  22  is  5.346231162548065\n",
      "Step 0  Loss: 0.5556499361991882\n",
      "Step 1  Loss: 0.614231288433075\n",
      "Step 2  Loss: 0.4835014343261719\n",
      "Step 3  Loss: 0.4814120829105377\n",
      "Step 4  Loss: 0.44924643635749817\n",
      "Step 5  Loss: 0.409172385931015\n",
      "Step 6  Loss: 0.37700653076171875\n",
      "Step 7  Loss: 0.3820568323135376\n",
      "Step 8  Loss: 0.3005615770816803\n",
      "Step 9  Loss: 0.4626580476760864\n",
      "Step 10  Loss: 0.4494413435459137\n",
      "total Loss of epoch  23  is  4.964937895536423\n",
      "Step 0  Loss: 0.5891737937927246\n",
      "Step 1  Loss: 0.46907421946525574\n",
      "Step 2  Loss: 0.42078354954719543\n",
      "Step 3  Loss: 0.5450412631034851\n",
      "Step 4  Loss: 0.4012306332588196\n",
      "Step 5  Loss: 0.5623846054077148\n",
      "Step 6  Loss: 0.5526450276374817\n",
      "Step 7  Loss: 0.4251205325126648\n",
      "Step 8  Loss: 0.4766257107257843\n",
      "Step 9  Loss: 0.48282790184020996\n",
      "Step 10  Loss: 0.6050426363945007\n",
      "total Loss of epoch  24  is  5.529949873685837\n",
      "Step 0  Loss: 0.4347998797893524\n",
      "Step 1  Loss: 0.3612307012081146\n",
      "Step 2  Loss: 0.4149758219718933\n",
      "Step 3  Loss: 0.5355459451675415\n",
      "Step 4  Loss: 0.5560131669044495\n",
      "Step 5  Loss: 0.44215044379234314\n",
      "Step 6  Loss: 0.5296244621276855\n",
      "Step 7  Loss: 0.5133639574050903\n",
      "Step 8  Loss: 0.4225701689720154\n",
      "Step 9  Loss: 0.5725961327552795\n",
      "Step 10  Loss: 0.3564944863319397\n",
      "total Loss of epoch  25  is  5.139365166425705\n",
      "Step 0  Loss: 0.5458857417106628\n",
      "Step 1  Loss: 0.6058558225631714\n",
      "Step 2  Loss: 0.5548204183578491\n",
      "Step 3  Loss: 0.5698885917663574\n",
      "Step 4  Loss: 0.41069266200065613\n",
      "Step 5  Loss: 0.4824847877025604\n",
      "Step 6  Loss: 0.5700249075889587\n",
      "Step 7  Loss: 0.5597625374794006\n",
      "Step 8  Loss: 0.4426524341106415\n",
      "Step 9  Loss: 0.5913934707641602\n",
      "Step 10  Loss: 0.5342351794242859\n",
      "total Loss of epoch  26  is  5.867696553468704\n",
      "Step 0  Loss: 0.415113240480423\n",
      "Step 1  Loss: 0.4323381185531616\n",
      "Step 2  Loss: 0.604767382144928\n",
      "Step 3  Loss: 0.4875234365463257\n",
      "Step 4  Loss: 0.2939285635948181\n",
      "Step 5  Loss: 0.5577197074890137\n",
      "Step 6  Loss: 0.5903112292289734\n",
      "Step 7  Loss: 0.5356606245040894\n",
      "Step 8  Loss: 0.46529632806777954\n",
      "Step 9  Loss: 0.5114074945449829\n",
      "Step 10  Loss: 0.5090047717094421\n",
      "total Loss of epoch  27  is  5.403070896863937\n",
      "Step 0  Loss: 0.30166003108024597\n",
      "Step 1  Loss: 0.5363610982894897\n",
      "Step 2  Loss: 0.5729321241378784\n",
      "Step 3  Loss: 0.5767335891723633\n",
      "Step 4  Loss: 0.4594723582267761\n",
      "Step 5  Loss: 0.5776621103286743\n",
      "Step 6  Loss: 0.45732375979423523\n",
      "Step 7  Loss: 0.566957950592041\n",
      "Step 8  Loss: 0.440996378660202\n",
      "Step 9  Loss: 0.32548433542251587\n",
      "Step 10  Loss: 0.40029752254486084\n",
      "total Loss of epoch  28  is  5.215881258249283\n",
      "Step 0  Loss: 0.5594042539596558\n",
      "Step 1  Loss: 0.5464015007019043\n",
      "Step 2  Loss: 0.5816348195075989\n",
      "Step 3  Loss: 0.5064852237701416\n",
      "Step 4  Loss: 0.5363202691078186\n",
      "Step 5  Loss: 0.5564452409744263\n",
      "Step 6  Loss: 0.45774954557418823\n",
      "Step 7  Loss: 0.5155301690101624\n",
      "Step 8  Loss: 0.635185956954956\n",
      "Step 9  Loss: 0.3912440836429596\n",
      "Step 10  Loss: 0.6384882926940918\n",
      "total Loss of epoch  29  is  5.924889355897903\n",
      "Step 0  Loss: 0.536514937877655\n",
      "Step 1  Loss: 0.5294317603111267\n",
      "Step 2  Loss: 0.5096818208694458\n",
      "Step 3  Loss: 0.4466208517551422\n",
      "Step 4  Loss: 0.5409687161445618\n",
      "Step 5  Loss: 0.4908512830734253\n",
      "Step 6  Loss: 0.4642871618270874\n",
      "Step 7  Loss: 0.5919104814529419\n",
      "Step 8  Loss: 0.4538307785987854\n",
      "Step 9  Loss: 0.5329394936561584\n",
      "Step 10  Loss: 0.3941367566585541\n",
      "total Loss of epoch  30  is  5.491174042224884\n",
      "Step 0  Loss: 0.5836533308029175\n",
      "Step 1  Loss: 0.557737410068512\n",
      "Step 2  Loss: 0.3467450439929962\n",
      "Step 3  Loss: 0.40505120158195496\n",
      "Step 4  Loss: 0.44731688499450684\n",
      "Step 5  Loss: 0.4557814300060272\n",
      "Step 6  Loss: 0.469630628824234\n",
      "Step 7  Loss: 0.45937231183052063\n",
      "Step 8  Loss: 0.5941436290740967\n",
      "Step 9  Loss: 0.4103793799877167\n",
      "Step 10  Loss: 0.3227141201496124\n",
      "total Loss of epoch  31  is  5.052525371313095\n",
      "Step 0  Loss: 0.4820646345615387\n",
      "Step 1  Loss: 0.4481598734855652\n",
      "Step 2  Loss: 0.5251890420913696\n",
      "Step 3  Loss: 0.43457120656967163\n",
      "Step 4  Loss: 0.4410199820995331\n",
      "Step 5  Loss: 0.4914579391479492\n",
      "Step 6  Loss: 0.3724638521671295\n",
      "Step 7  Loss: 0.6254836916923523\n",
      "Step 8  Loss: 0.4222313165664673\n",
      "Step 9  Loss: 0.40301477909088135\n",
      "Step 10  Loss: 0.469711035490036\n",
      "total Loss of epoch  32  is  5.115367352962494\n",
      "Step 0  Loss: 0.3565824329853058\n",
      "Step 1  Loss: 0.3920133113861084\n",
      "Step 2  Loss: 0.3777865469455719\n",
      "Step 3  Loss: 0.5490157008171082\n",
      "Step 4  Loss: 0.4904911518096924\n",
      "Step 5  Loss: 0.4701719284057617\n",
      "Step 6  Loss: 0.47436824440956116\n",
      "Step 7  Loss: 0.4504717290401459\n",
      "Step 8  Loss: 0.45559605956077576\n",
      "Step 9  Loss: 0.320505291223526\n",
      "Step 10  Loss: 0.5983614325523376\n",
      "total Loss of epoch  33  is  4.935363829135895\n",
      "Step 0  Loss: 0.5468725562095642\n",
      "Step 1  Loss: 0.5380308032035828\n",
      "Step 2  Loss: 0.36862435936927795\n",
      "Step 3  Loss: 0.42226457595825195\n",
      "Step 4  Loss: 0.47416457533836365\n",
      "Step 5  Loss: 0.4684526324272156\n",
      "Step 6  Loss: 0.33481743931770325\n",
      "Step 7  Loss: 0.48978322744369507\n",
      "Step 8  Loss: 0.5059562921524048\n",
      "Step 9  Loss: 0.5124145746231079\n",
      "Step 10  Loss: 0.45220428705215454\n",
      "total Loss of epoch  34  is  5.113585323095322\n",
      "Step 0  Loss: 0.5594474673271179\n",
      "Step 1  Loss: 0.3939659595489502\n",
      "Step 2  Loss: 0.4366195797920227\n",
      "Step 3  Loss: 0.5092596411705017\n",
      "Step 4  Loss: 0.449360728263855\n",
      "Step 5  Loss: 0.39464715123176575\n",
      "Step 6  Loss: 0.6147710084915161\n",
      "Step 7  Loss: 0.5678642988204956\n",
      "Step 8  Loss: 0.47185245156288147\n",
      "Step 9  Loss: 0.5221976637840271\n",
      "Step 10  Loss: 0.4697682559490204\n",
      "total Loss of epoch  35  is  5.389754205942154\n",
      "Step 0  Loss: 0.46934521198272705\n",
      "Step 1  Loss: 0.5170479416847229\n",
      "Step 2  Loss: 0.42442935705184937\n",
      "Step 3  Loss: 0.48845916986465454\n",
      "Step 4  Loss: 0.42765381932258606\n",
      "Step 5  Loss: 0.421697199344635\n",
      "Step 6  Loss: 0.5095008015632629\n",
      "Step 7  Loss: 0.471518874168396\n",
      "Step 8  Loss: 0.36841848492622375\n",
      "Step 9  Loss: 0.5073418617248535\n",
      "Step 10  Loss: 0.4189675748348236\n",
      "total Loss of epoch  36  is  5.024380296468735\n",
      "Step 0  Loss: 0.46881428360939026\n",
      "Step 1  Loss: 0.4706224501132965\n",
      "Step 2  Loss: 0.4840937554836273\n",
      "Step 3  Loss: 0.5150029063224792\n",
      "Step 4  Loss: 0.3851698338985443\n",
      "Step 5  Loss: 0.5482533574104309\n",
      "Step 6  Loss: 0.5603578090667725\n",
      "Step 7  Loss: 0.4495316743850708\n",
      "Step 8  Loss: 0.4161502718925476\n",
      "Step 9  Loss: 0.4816263020038605\n",
      "Step 10  Loss: 0.5252107977867126\n",
      "total Loss of epoch  37  is  5.3048334419727325\n",
      "Step 0  Loss: 0.5078168511390686\n",
      "Step 1  Loss: 0.5061461329460144\n",
      "Step 2  Loss: 0.4718128442764282\n",
      "Step 3  Loss: 0.5551320910453796\n",
      "Step 4  Loss: 0.5844060778617859\n",
      "Step 5  Loss: 0.4741968810558319\n",
      "Step 6  Loss: 0.45510783791542053\n",
      "Step 7  Loss: 0.3921707272529602\n",
      "Step 8  Loss: 0.5340257883071899\n",
      "Step 9  Loss: 0.5309376120567322\n",
      "Step 10  Loss: 0.5052633285522461\n",
      "total Loss of epoch  38  is  5.517016172409058\n",
      "Step 0  Loss: 0.4115825891494751\n",
      "Step 1  Loss: 0.4208364188671112\n",
      "Step 2  Loss: 0.45570889115333557\n",
      "Step 3  Loss: 0.4640040099620819\n",
      "Step 4  Loss: 0.4483759105205536\n",
      "Step 5  Loss: 0.5222674608230591\n",
      "Step 6  Loss: 0.5185695290565491\n",
      "Step 7  Loss: 0.4142633378505707\n",
      "Step 8  Loss: 0.5069092512130737\n",
      "Step 9  Loss: 0.4678471088409424\n",
      "Step 10  Loss: 0.39894920587539673\n",
      "total Loss of epoch  39  is  5.029313713312149\n",
      "Step 0  Loss: 0.38456302881240845\n",
      "Step 1  Loss: 0.52161705493927\n",
      "Step 2  Loss: 0.4881467819213867\n",
      "Step 3  Loss: 0.4283849895000458\n",
      "Step 4  Loss: 0.47531402111053467\n",
      "Step 5  Loss: 0.3373717963695526\n",
      "Step 6  Loss: 0.4958832263946533\n",
      "Step 7  Loss: 0.4969364404678345\n",
      "Step 8  Loss: 0.4803268015384674\n",
      "Step 9  Loss: 0.5291830897331238\n",
      "Step 10  Loss: 0.5390976667404175\n",
      "total Loss of epoch  40  is  5.176824897527695\n",
      "Step 0  Loss: 0.37499144673347473\n",
      "Step 1  Loss: 0.4989235997200012\n",
      "Step 2  Loss: 0.44671064615249634\n",
      "Step 3  Loss: 0.41760769486427307\n",
      "Step 4  Loss: 0.42432790994644165\n",
      "Step 5  Loss: 0.3962174952030182\n",
      "Step 6  Loss: 0.5262019634246826\n",
      "Step 7  Loss: 0.4257645905017853\n",
      "Step 8  Loss: 0.39788514375686646\n",
      "Step 9  Loss: 0.42083895206451416\n",
      "Step 10  Loss: 0.4735738933086395\n",
      "total Loss of epoch  41  is  4.803043335676193\n",
      "Step 0  Loss: 0.3769187033176422\n",
      "Step 1  Loss: 0.4183933734893799\n",
      "Step 2  Loss: 0.46184277534484863\n",
      "Step 3  Loss: 0.4698675572872162\n",
      "Step 4  Loss: 0.5242232084274292\n",
      "Step 5  Loss: 0.32837963104248047\n",
      "Step 6  Loss: 0.3914378881454468\n",
      "Step 7  Loss: 0.5126349329948425\n",
      "Step 8  Loss: 0.48297441005706787\n",
      "Step 9  Loss: 0.369222491979599\n",
      "Step 10  Loss: 0.4539623260498047\n",
      "total Loss of epoch  42  is  4.7898572981357574\n",
      "Step 0  Loss: 0.42568516731262207\n",
      "Step 1  Loss: 0.5353933572769165\n",
      "Step 2  Loss: 0.5266131162643433\n",
      "Step 3  Loss: 0.4523480534553528\n",
      "Step 4  Loss: 0.48120468854904175\n",
      "Step 5  Loss: 0.45100048184394836\n",
      "Step 6  Loss: 0.450334757566452\n",
      "Step 7  Loss: 0.4712030589580536\n",
      "Step 8  Loss: 0.5220569968223572\n",
      "Step 9  Loss: 0.3008919656276703\n",
      "Step 10  Loss: 0.3732517659664154\n",
      "total Loss of epoch  43  is  4.989983409643173\n",
      "Step 0  Loss: 0.4886356294155121\n",
      "Step 1  Loss: 0.4755866825580597\n",
      "Step 2  Loss: 0.3449634313583374\n",
      "Step 3  Loss: 0.4541177749633789\n",
      "Step 4  Loss: 0.3724555969238281\n",
      "Step 5  Loss: 0.6209849715232849\n",
      "Step 6  Loss: 0.5029443502426147\n",
      "Step 7  Loss: 0.39735978841781616\n",
      "Step 8  Loss: 0.4623998701572418\n",
      "Step 9  Loss: 0.42436960339546204\n",
      "Step 10  Loss: 0.4937082529067993\n",
      "total Loss of epoch  44  is  5.037525951862335\n",
      "Step 0  Loss: 0.3809603154659271\n",
      "Step 1  Loss: 0.4632922112941742\n",
      "Step 2  Loss: 0.4444158971309662\n",
      "Step 3  Loss: 0.4243617057800293\n",
      "Step 4  Loss: 0.41661930084228516\n",
      "Step 5  Loss: 0.45453140139579773\n",
      "Step 6  Loss: 0.41891488432884216\n",
      "Step 7  Loss: 0.46267542243003845\n",
      "Step 8  Loss: 0.4855700433254242\n",
      "Step 9  Loss: 0.43249884247779846\n",
      "Step 10  Loss: 0.46141281723976135\n",
      "total Loss of epoch  45  is  4.845252841711044\n",
      "Step 0  Loss: 0.4048523008823395\n",
      "Step 1  Loss: 0.5035995244979858\n",
      "Step 2  Loss: 0.42344930768013\n",
      "Step 3  Loss: 0.47985872626304626\n",
      "Step 4  Loss: 0.5010411143302917\n",
      "Step 5  Loss: 0.4840729236602783\n",
      "Step 6  Loss: 0.42522546648979187\n",
      "Step 7  Loss: 0.4437081217765808\n",
      "Step 8  Loss: 0.30955418944358826\n",
      "Step 9  Loss: 0.3888125717639923\n",
      "Step 10  Loss: 0.5793915390968323\n",
      "total Loss of epoch  46  is  4.943565785884857\n",
      "Step 0  Loss: 0.4328782856464386\n",
      "Step 1  Loss: 0.39080965518951416\n",
      "Step 2  Loss: 0.5003852844238281\n",
      "Step 3  Loss: 0.41147345304489136\n",
      "Step 4  Loss: 0.43282344937324524\n",
      "Step 5  Loss: 0.4834640324115753\n",
      "Step 6  Loss: 0.5277165174484253\n",
      "Step 7  Loss: 0.5230156183242798\n",
      "Step 8  Loss: 0.4147093594074249\n",
      "Step 9  Loss: 0.38389304280281067\n",
      "Step 10  Loss: 0.5382438898086548\n",
      "total Loss of epoch  47  is  5.039412587881088\n",
      "Step 0  Loss: 0.44789567589759827\n",
      "Step 1  Loss: 0.4944758117198944\n",
      "Step 2  Loss: 0.5719440579414368\n",
      "Step 3  Loss: 0.4217911958694458\n",
      "Step 4  Loss: 0.5285617113113403\n",
      "Step 5  Loss: 0.45615118741989136\n",
      "Step 6  Loss: 0.5579383373260498\n",
      "Step 7  Loss: 0.47723254561424255\n",
      "Step 8  Loss: 0.5001770257949829\n",
      "Step 9  Loss: 0.4884878695011139\n",
      "Step 10  Loss: 0.4084615111351013\n",
      "total Loss of epoch  48  is  5.353116929531097\n",
      "Step 0  Loss: 0.48554807901382446\n",
      "Step 1  Loss: 0.39722704887390137\n",
      "Step 2  Loss: 0.411739706993103\n",
      "Step 3  Loss: 0.4289286732673645\n",
      "Step 4  Loss: 0.36408334970474243\n",
      "Step 5  Loss: 0.35513386130332947\n",
      "Step 6  Loss: 0.518291175365448\n",
      "Step 7  Loss: 0.5337960124015808\n",
      "Step 8  Loss: 0.46500417590141296\n",
      "Step 9  Loss: 0.4162602126598358\n",
      "Step 10  Loss: 0.43473055958747864\n",
      "total Loss of epoch  49  is  4.8107428550720215\n",
      "Step 0  Loss: 0.34403446316719055\n",
      "Step 1  Loss: 0.5572511553764343\n",
      "Step 2  Loss: 0.46028468012809753\n",
      "Step 3  Loss: 0.4158414304256439\n",
      "Step 4  Loss: 0.44557851552963257\n",
      "Step 5  Loss: 0.43649324774742126\n",
      "Step 6  Loss: 0.49598318338394165\n",
      "Step 7  Loss: 0.41984403133392334\n",
      "Step 8  Loss: 0.35718804597854614\n",
      "Step 9  Loss: 0.41476333141326904\n",
      "Step 10  Loss: 0.24429285526275635\n",
      "total Loss of epoch  50  is  4.591554939746857\n",
      "Step 0  Loss: 0.45293891429901123\n",
      "Step 1  Loss: 0.4651767611503601\n",
      "Step 2  Loss: 0.4514736533164978\n",
      "Step 3  Loss: 0.46898192167282104\n",
      "Step 4  Loss: 0.40099820494651794\n",
      "Step 5  Loss: 0.36968380212783813\n",
      "Step 6  Loss: 0.44072961807250977\n",
      "Step 7  Loss: 0.4421809911727905\n",
      "Step 8  Loss: 0.578617513179779\n",
      "Step 9  Loss: 0.4207844138145447\n",
      "Step 10  Loss: 0.4765661656856537\n",
      "total Loss of epoch  51  is  4.968131959438324\n",
      "Step 0  Loss: 0.4765619933605194\n",
      "Step 1  Loss: 0.5599459409713745\n",
      "Step 2  Loss: 0.41348525881767273\n",
      "Step 3  Loss: 0.4158809781074524\n",
      "Step 4  Loss: 0.45280227065086365\n",
      "Step 5  Loss: 0.49939796328544617\n",
      "Step 6  Loss: 0.4540467858314514\n",
      "Step 7  Loss: 0.5170378684997559\n",
      "Step 8  Loss: 0.4164571166038513\n",
      "Step 9  Loss: 0.5658731460571289\n",
      "Step 10  Loss: 0.5795392990112305\n",
      "total Loss of epoch  52  is  5.351028621196747\n",
      "Step 0  Loss: 0.3377740681171417\n",
      "Step 1  Loss: 0.3433864712715149\n",
      "Step 2  Loss: 0.21036362648010254\n",
      "Step 3  Loss: 0.4262140989303589\n",
      "Step 4  Loss: 0.550916314125061\n",
      "Step 5  Loss: 0.3160589039325714\n",
      "Step 6  Loss: 0.39376839995384216\n",
      "Step 7  Loss: 0.5263815522193909\n",
      "Step 8  Loss: 0.49896055459976196\n",
      "Step 9  Loss: 0.5080828666687012\n",
      "Step 10  Loss: 0.3849550783634186\n",
      "total Loss of epoch  53  is  4.496861934661865\n",
      "Step 0  Loss: 0.46539461612701416\n",
      "Step 1  Loss: 0.4064262807369232\n",
      "Step 2  Loss: 0.40943363308906555\n",
      "Step 3  Loss: 0.48108649253845215\n",
      "Step 4  Loss: 0.44504523277282715\n",
      "Step 5  Loss: 0.4439241588115692\n",
      "Step 6  Loss: 0.3854263126850128\n",
      "Step 7  Loss: 0.4958650469779968\n",
      "Step 8  Loss: 0.369902640581131\n",
      "Step 9  Loss: 0.32247692346572876\n",
      "Step 10  Loss: 0.4692690968513489\n",
      "total Loss of epoch  54  is  4.69425043463707\n",
      "Step 0  Loss: 0.4709981679916382\n",
      "Step 1  Loss: 0.4311780035495758\n",
      "Step 2  Loss: 0.5497714281082153\n",
      "Step 3  Loss: 0.4892914295196533\n",
      "Step 4  Loss: 0.407600462436676\n",
      "Step 5  Loss: 0.4405067265033722\n",
      "Step 6  Loss: 0.39275428652763367\n",
      "Step 7  Loss: 0.5098927021026611\n",
      "Step 8  Loss: 0.49819061160087585\n",
      "Step 9  Loss: 0.4983679950237274\n",
      "Step 10  Loss: 0.5014979243278503\n",
      "total Loss of epoch  55  is  5.190049737691879\n",
      "Step 0  Loss: 0.4933692514896393\n",
      "Step 1  Loss: 0.506380558013916\n",
      "Step 2  Loss: 0.41623082756996155\n",
      "Step 3  Loss: 0.4367932975292206\n",
      "Step 4  Loss: 0.4309612214565277\n",
      "Step 5  Loss: 0.4001529812812805\n",
      "Step 6  Loss: 0.4178851842880249\n",
      "Step 7  Loss: 0.4718126952648163\n",
      "Step 8  Loss: 0.33310753107070923\n",
      "Step 9  Loss: 0.4130937457084656\n",
      "Step 10  Loss: 0.475425124168396\n",
      "total Loss of epoch  56  is  4.795212417840958\n",
      "Step 0  Loss: 0.40739017724990845\n",
      "Step 1  Loss: 0.42873308062553406\n",
      "Step 2  Loss: 0.35988593101501465\n",
      "Step 3  Loss: 0.3756851553916931\n",
      "Step 4  Loss: 0.5091677904129028\n",
      "Step 5  Loss: 0.497978538274765\n",
      "Step 6  Loss: 0.4607233703136444\n",
      "Step 7  Loss: 0.40458062291145325\n",
      "Step 8  Loss: 0.31166768074035645\n",
      "Step 9  Loss: 0.49753648042678833\n",
      "Step 10  Loss: 0.49406903982162476\n",
      "total Loss of epoch  57  is  4.747417867183685\n",
      "Step 0  Loss: 0.38574349880218506\n",
      "Step 1  Loss: 0.47496435046195984\n",
      "Step 2  Loss: 0.5135026574134827\n",
      "Step 3  Loss: 0.41622039675712585\n",
      "Step 4  Loss: 0.454164981842041\n",
      "Step 5  Loss: 0.47874483466148376\n",
      "Step 6  Loss: 0.42263326048851013\n",
      "Step 7  Loss: 0.5258845090866089\n",
      "Step 8  Loss: 0.3927152454853058\n",
      "Step 9  Loss: 0.43483230471611023\n",
      "Step 10  Loss: 0.46122750639915466\n",
      "total Loss of epoch  58  is  4.960633546113968\n",
      "Step 0  Loss: 0.3684066832065582\n",
      "Step 1  Loss: 0.46841421723365784\n",
      "Step 2  Loss: 0.5069444179534912\n",
      "Step 3  Loss: 0.3468126952648163\n",
      "Step 4  Loss: 0.3726375699043274\n",
      "Step 5  Loss: 0.514191210269928\n",
      "Step 6  Loss: 0.3076499402523041\n",
      "Step 7  Loss: 0.30944085121154785\n",
      "Step 8  Loss: 0.3582295775413513\n",
      "Step 9  Loss: 0.5598466396331787\n",
      "Step 10  Loss: 0.5509639382362366\n",
      "total Loss of epoch  59  is  4.6635377407073975\n",
      "Step 0  Loss: 0.3199934661388397\n",
      "Step 1  Loss: 0.3264516294002533\n",
      "Step 2  Loss: 0.4376431107521057\n",
      "Step 3  Loss: 0.4382247030735016\n",
      "Step 4  Loss: 0.38414448499679565\n",
      "Step 5  Loss: 0.49155572056770325\n",
      "Step 6  Loss: 0.3222500681877136\n",
      "Step 7  Loss: 0.47906216979026794\n",
      "Step 8  Loss: 0.36156025528907776\n",
      "Step 9  Loss: 0.49266862869262695\n",
      "Step 10  Loss: 0.4466852843761444\n",
      "total Loss of epoch  60  is  4.50023952126503\n",
      "Step 0  Loss: 0.3548387885093689\n",
      "Step 1  Loss: 0.47957858443260193\n",
      "Step 2  Loss: 0.42343243956565857\n",
      "Step 3  Loss: 0.4206944704055786\n",
      "Step 4  Loss: 0.33698686957359314\n",
      "Step 5  Loss: 0.4895673394203186\n",
      "Step 6  Loss: 0.44961002469062805\n",
      "Step 7  Loss: 0.3455415964126587\n",
      "Step 8  Loss: 0.44474098086357117\n",
      "Step 9  Loss: 0.389180064201355\n",
      "Step 10  Loss: 0.45108509063720703\n",
      "total Loss of epoch  61  is  4.58525624871254\n",
      "Step 0  Loss: 0.5069818496704102\n",
      "Step 1  Loss: 0.3451494872570038\n",
      "Step 2  Loss: 0.4011848270893097\n",
      "Step 3  Loss: 0.48624250292778015\n",
      "Step 4  Loss: 0.4902840256690979\n",
      "Step 5  Loss: 0.41292908787727356\n",
      "Step 6  Loss: 0.34086450934410095\n",
      "Step 7  Loss: 0.4415777027606964\n",
      "Step 8  Loss: 0.48209232091903687\n",
      "Step 9  Loss: 0.42848122119903564\n",
      "Step 10  Loss: 0.41760513186454773\n",
      "total Loss of epoch  62  is  4.753392666578293\n",
      "Step 0  Loss: 0.449371874332428\n",
      "Step 1  Loss: 0.4864601194858551\n",
      "Step 2  Loss: 0.43480435013771057\n",
      "Step 3  Loss: 0.36431947350502014\n",
      "Step 4  Loss: 0.3421860337257385\n",
      "Step 5  Loss: 0.48615017533302307\n",
      "Step 6  Loss: 0.5372787714004517\n",
      "Step 7  Loss: 0.47178569436073303\n",
      "Step 8  Loss: 0.44101062417030334\n",
      "Step 9  Loss: 0.29436159133911133\n",
      "Step 10  Loss: 0.35747799277305603\n",
      "total Loss of epoch  63  is  4.665206700563431\n",
      "Step 0  Loss: 0.33081376552581787\n",
      "Step 1  Loss: 0.47732746601104736\n",
      "Step 2  Loss: 0.41057246923446655\n",
      "Step 3  Loss: 0.3842739462852478\n",
      "Step 4  Loss: 0.5646079778671265\n",
      "Step 5  Loss: 0.4258285164833069\n",
      "Step 6  Loss: 0.44291141629219055\n",
      "Step 7  Loss: 0.416537344455719\n",
      "Step 8  Loss: 0.47216910123825073\n",
      "Step 9  Loss: 0.5675588846206665\n",
      "Step 10  Loss: 0.44692304730415344\n",
      "total Loss of epoch  64  is  4.939523935317993\n",
      "Step 0  Loss: 0.4036312401294708\n",
      "Step 1  Loss: 0.41546517610549927\n",
      "Step 2  Loss: 0.45033085346221924\n",
      "Step 3  Loss: 0.3832872807979584\n",
      "Step 4  Loss: 0.43029147386550903\n",
      "Step 5  Loss: 0.32534611225128174\n",
      "Step 6  Loss: 0.4223296344280243\n",
      "Step 7  Loss: 0.4823501706123352\n",
      "Step 8  Loss: 0.5015825033187866\n",
      "Step 9  Loss: 0.481910765171051\n",
      "Step 10  Loss: 0.4119076430797577\n",
      "total Loss of epoch  65  is  4.708432853221893\n",
      "Step 0  Loss: 0.2777027487754822\n",
      "Step 1  Loss: 0.4001118540763855\n",
      "Step 2  Loss: 0.31727758049964905\n",
      "Step 3  Loss: 0.5283511281013489\n",
      "Step 4  Loss: 0.38055694103240967\n",
      "Step 5  Loss: 0.4598635137081146\n",
      "Step 6  Loss: 0.3621692657470703\n",
      "Step 7  Loss: 0.3904377520084381\n",
      "Step 8  Loss: 0.4024354815483093\n",
      "Step 9  Loss: 0.502656877040863\n",
      "Step 10  Loss: 0.5707076191902161\n",
      "total Loss of epoch  66  is  4.592270761728287\n",
      "Step 0  Loss: 0.4361680746078491\n",
      "Step 1  Loss: 0.5225995182991028\n",
      "Step 2  Loss: 0.3259733021259308\n",
      "Step 3  Loss: 0.3563280403614044\n",
      "Step 4  Loss: 0.4065597355365753\n",
      "Step 5  Loss: 0.47208982706069946\n",
      "Step 6  Loss: 0.4701246917247772\n",
      "Step 7  Loss: 0.4290889501571655\n",
      "Step 8  Loss: 0.3239815831184387\n",
      "Step 9  Loss: 0.38124963641166687\n",
      "Step 10  Loss: 0.3418462574481964\n",
      "total Loss of epoch  67  is  4.466009616851807\n",
      "Step 0  Loss: 0.39428722858428955\n",
      "Step 1  Loss: 0.40205469727516174\n",
      "Step 2  Loss: 0.43583449721336365\n",
      "Step 3  Loss: 0.46181684732437134\n",
      "Step 4  Loss: 0.39421072602272034\n",
      "Step 5  Loss: 0.353796124458313\n",
      "Step 6  Loss: 0.39176684617996216\n",
      "Step 7  Loss: 0.5000945329666138\n",
      "Step 8  Loss: 0.6058471202850342\n",
      "Step 9  Loss: 0.4580356478691101\n",
      "Step 10  Loss: 0.5347782373428345\n",
      "total Loss of epoch  68  is  4.932522505521774\n",
      "Step 0  Loss: 0.4755312502384186\n",
      "Step 1  Loss: 0.49290549755096436\n",
      "Step 2  Loss: 0.3718748390674591\n",
      "Step 3  Loss: 0.37834420800209045\n",
      "Step 4  Loss: 0.4309152364730835\n",
      "Step 5  Loss: 0.4563119411468506\n",
      "Step 6  Loss: 0.469422847032547\n",
      "Step 7  Loss: 0.2677253782749176\n",
      "Step 8  Loss: 0.42752283811569214\n",
      "Step 9  Loss: 0.5498701930046082\n",
      "Step 10  Loss: 0.5263122916221619\n",
      "total Loss of epoch  69  is  4.846736520528793\n",
      "Step 0  Loss: 0.4316382110118866\n",
      "Step 1  Loss: 0.3885151147842407\n",
      "Step 2  Loss: 0.4824412167072296\n",
      "Step 3  Loss: 0.42142534255981445\n",
      "Step 4  Loss: 0.2853353023529053\n",
      "Step 5  Loss: 0.44391849637031555\n",
      "Step 6  Loss: 0.3593919277191162\n",
      "Step 7  Loss: 0.42956066131591797\n",
      "Step 8  Loss: 0.3933061361312866\n",
      "Step 9  Loss: 0.42070239782333374\n",
      "Step 10  Loss: 0.48642483353614807\n",
      "total Loss of epoch  70  is  4.542659640312195\n",
      "Step 0  Loss: 0.38074159622192383\n",
      "Step 1  Loss: 0.3782004117965698\n",
      "Step 2  Loss: 0.39776647090911865\n",
      "Step 3  Loss: 0.40313720703125\n",
      "Step 4  Loss: 0.30661651492118835\n",
      "Step 5  Loss: 0.46514108777046204\n",
      "Step 6  Loss: 0.4210529625415802\n",
      "Step 7  Loss: 0.3741307854652405\n",
      "Step 8  Loss: 0.4129902720451355\n",
      "Step 9  Loss: 0.35595396161079407\n",
      "Step 10  Loss: 0.5608717203140259\n",
      "total Loss of epoch  71  is  4.456602990627289\n",
      "Step 0  Loss: 0.36782634258270264\n",
      "Step 1  Loss: 0.3510608375072479\n",
      "Step 2  Loss: 0.4334873557090759\n",
      "Step 3  Loss: 0.36140477657318115\n",
      "Step 4  Loss: 0.37872856855392456\n",
      "Step 5  Loss: 0.35529381036758423\n",
      "Step 6  Loss: 0.377652645111084\n",
      "Step 7  Loss: 0.3403950333595276\n",
      "Step 8  Loss: 0.25857868790626526\n",
      "Step 9  Loss: 0.3513318598270416\n",
      "Step 10  Loss: 0.3772784471511841\n",
      "total Loss of epoch  72  is  3.953038364648819\n",
      "Step 0  Loss: 0.45602571964263916\n",
      "Step 1  Loss: 0.35085731744766235\n",
      "Step 2  Loss: 0.42716512084007263\n",
      "Step 3  Loss: 0.4777066111564636\n",
      "Step 4  Loss: 0.5103501081466675\n",
      "Step 5  Loss: 0.47508662939071655\n",
      "Step 6  Loss: 0.4406801164150238\n",
      "Step 7  Loss: 0.4370673894882202\n",
      "Step 8  Loss: 0.4347449243068695\n",
      "Step 9  Loss: 0.5095705986022949\n",
      "Step 10  Loss: 0.36485254764556885\n",
      "total Loss of epoch  73  is  4.884107083082199\n",
      "Step 0  Loss: 0.3770042061805725\n",
      "Step 1  Loss: 0.4254745543003082\n",
      "Step 2  Loss: 0.44739624857902527\n",
      "Step 3  Loss: 0.5034443736076355\n",
      "Step 4  Loss: 0.38744252920150757\n",
      "Step 5  Loss: 0.4628349542617798\n",
      "Step 6  Loss: 0.3102867007255554\n",
      "Step 7  Loss: 0.3978966474533081\n",
      "Step 8  Loss: 0.46914637088775635\n",
      "Step 9  Loss: 0.4582977294921875\n",
      "Step 10  Loss: 0.45619022846221924\n",
      "total Loss of epoch  74  is  4.6954145431518555\n",
      "Step 0  Loss: 0.4912748634815216\n",
      "Step 1  Loss: 0.5244476199150085\n",
      "Step 2  Loss: 0.4630902409553528\n",
      "Step 3  Loss: 0.45325517654418945\n",
      "Step 4  Loss: 0.5640624761581421\n",
      "Step 5  Loss: 0.410590261220932\n",
      "Step 6  Loss: 0.3683241605758667\n",
      "Step 7  Loss: 0.35112571716308594\n",
      "Step 8  Loss: 0.4561140239238739\n",
      "Step 9  Loss: 0.42453277111053467\n",
      "Step 10  Loss: 0.33181750774383545\n",
      "total Loss of epoch  75  is  4.838634818792343\n",
      "Step 0  Loss: 0.4174417555332184\n",
      "Step 1  Loss: 0.3651610314846039\n",
      "Step 2  Loss: 0.37777382135391235\n",
      "Step 3  Loss: 0.395267128944397\n",
      "Step 4  Loss: 0.37427806854248047\n",
      "Step 5  Loss: 0.4612703323364258\n",
      "Step 6  Loss: 0.454233855009079\n",
      "Step 7  Loss: 0.441489040851593\n",
      "Step 8  Loss: 0.4120006263256073\n",
      "Step 9  Loss: 0.40259289741516113\n",
      "Step 10  Loss: 0.33086350560188293\n",
      "total Loss of epoch  76  is  4.432372063398361\n",
      "Step 0  Loss: 0.45867592096328735\n",
      "Step 1  Loss: 0.4891652464866638\n",
      "Step 2  Loss: 0.3645845353603363\n",
      "Step 3  Loss: 0.27208322286605835\n",
      "Step 4  Loss: 0.46810510754585266\n",
      "Step 5  Loss: 0.39353176951408386\n",
      "Step 6  Loss: 0.49590736627578735\n",
      "Step 7  Loss: 0.37018871307373047\n",
      "Step 8  Loss: 0.3886226415634155\n",
      "Step 9  Loss: 0.4352701008319855\n",
      "Step 10  Loss: 0.44085693359375\n",
      "total Loss of epoch  77  is  4.576991558074951\n",
      "Step 0  Loss: 0.5382912158966064\n",
      "Step 1  Loss: 0.3237064480781555\n",
      "Step 2  Loss: 0.3545210063457489\n",
      "Step 3  Loss: 0.33711087703704834\n",
      "Step 4  Loss: 0.4266747832298279\n",
      "Step 5  Loss: 0.3744641840457916\n",
      "Step 6  Loss: 0.3734897971153259\n",
      "Step 7  Loss: 0.5359132885932922\n",
      "Step 8  Loss: 0.3723197281360626\n",
      "Step 9  Loss: 0.4140264689922333\n",
      "Step 10  Loss: 0.5043140649795532\n",
      "total Loss of epoch  78  is  4.554831862449646\n",
      "Step 0  Loss: 0.5107981562614441\n",
      "Step 1  Loss: 0.3702692687511444\n",
      "Step 2  Loss: 0.36862245202064514\n",
      "Step 3  Loss: 0.4619760513305664\n",
      "Step 4  Loss: 0.523107647895813\n",
      "Step 5  Loss: 0.42868125438690186\n",
      "Step 6  Loss: 0.38379934430122375\n",
      "Step 7  Loss: 0.508320152759552\n",
      "Step 8  Loss: 0.49253350496292114\n",
      "Step 9  Loss: 0.3800642192363739\n",
      "Step 10  Loss: 0.544768214225769\n",
      "total Loss of epoch  79  is  4.972940266132355\n",
      "Step 0  Loss: 0.3496304452419281\n",
      "Step 1  Loss: 0.4337482154369354\n",
      "Step 2  Loss: 0.4676082730293274\n",
      "Step 3  Loss: 0.5593185424804688\n",
      "Step 4  Loss: 0.3206639289855957\n",
      "Step 5  Loss: 0.4164220988750458\n",
      "Step 6  Loss: 0.3776529133319855\n",
      "Step 7  Loss: 0.4801487922668457\n",
      "Step 8  Loss: 0.4810749888420105\n",
      "Step 9  Loss: 0.5322785377502441\n",
      "Step 10  Loss: 0.5187665224075317\n",
      "total Loss of epoch  80  is  4.937313258647919\n",
      "Step 0  Loss: 0.35699766874313354\n",
      "Step 1  Loss: 0.4943964183330536\n",
      "Step 2  Loss: 0.4156063199043274\n",
      "Step 3  Loss: 0.33579960465431213\n",
      "Step 4  Loss: 0.41610008478164673\n",
      "Step 5  Loss: 0.38060781359672546\n",
      "Step 6  Loss: 0.39398765563964844\n",
      "Step 7  Loss: 0.374475359916687\n",
      "Step 8  Loss: 0.4673822820186615\n",
      "Step 9  Loss: 0.36074110865592957\n",
      "Step 10  Loss: 0.4630896747112274\n",
      "total Loss of epoch  81  is  4.459183990955353\n",
      "Step 0  Loss: 0.32665032148361206\n",
      "Step 1  Loss: 0.45501410961151123\n",
      "Step 2  Loss: 0.3903658390045166\n",
      "Step 3  Loss: 0.34058326482772827\n",
      "Step 4  Loss: 0.3374335467815399\n",
      "Step 5  Loss: 0.386982262134552\n",
      "Step 6  Loss: 0.47756654024124146\n",
      "Step 7  Loss: 0.4395712912082672\n",
      "Step 8  Loss: 0.44715172052383423\n",
      "Step 9  Loss: 0.3649667799472809\n",
      "Step 10  Loss: 0.46168243885040283\n",
      "total Loss of epoch  82  is  4.427968114614487\n",
      "Step 0  Loss: 0.3130558431148529\n",
      "Step 1  Loss: 0.3815409243106842\n",
      "Step 2  Loss: 0.44783103466033936\n",
      "Step 3  Loss: 0.358254611492157\n",
      "Step 4  Loss: 0.504236102104187\n",
      "Step 5  Loss: 0.5236719846725464\n",
      "Step 6  Loss: 0.3805844485759735\n",
      "Step 7  Loss: 0.4693702161312103\n",
      "Step 8  Loss: 0.40124136209487915\n",
      "Step 9  Loss: 0.45623070001602173\n",
      "Step 10  Loss: 0.5147271156311035\n",
      "total Loss of epoch  83  is  4.750744342803955\n",
      "Step 0  Loss: 0.41370365023612976\n",
      "Step 1  Loss: 0.4724515676498413\n",
      "Step 2  Loss: 0.5287899374961853\n",
      "Step 3  Loss: 0.3787156641483307\n",
      "Step 4  Loss: 0.4084332585334778\n",
      "Step 5  Loss: 0.4682846665382385\n",
      "Step 6  Loss: 0.48206979036331177\n",
      "Step 7  Loss: 0.4668046236038208\n",
      "Step 8  Loss: 0.41605791449546814\n",
      "Step 9  Loss: 0.4587033987045288\n",
      "Step 10  Loss: 0.5244858860969543\n",
      "total Loss of epoch  84  is  5.018500357866287\n",
      "Step 0  Loss: 0.43461495637893677\n",
      "Step 1  Loss: 0.4411775767803192\n",
      "Step 2  Loss: 0.5098382234573364\n",
      "Step 3  Loss: 0.40324845910072327\n",
      "Step 4  Loss: 0.44129180908203125\n",
      "Step 5  Loss: 0.4780266284942627\n",
      "Step 6  Loss: 0.41458258032798767\n",
      "Step 7  Loss: 0.4334627687931061\n",
      "Step 8  Loss: 0.49603694677352905\n",
      "Step 9  Loss: 0.4342114329338074\n",
      "Step 10  Loss: 0.3828528821468353\n",
      "total Loss of epoch  85  is  4.869344264268875\n",
      "Step 0  Loss: 0.3167157769203186\n",
      "Step 1  Loss: 0.36576560139656067\n",
      "Step 2  Loss: 0.44279202818870544\n",
      "Step 3  Loss: 0.4586165249347687\n",
      "Step 4  Loss: 0.36415839195251465\n",
      "Step 5  Loss: 0.3268392086029053\n",
      "Step 6  Loss: 0.40593332052230835\n",
      "Step 7  Loss: 0.4564235806465149\n",
      "Step 8  Loss: 0.45816370844841003\n",
      "Step 9  Loss: 0.5281028747558594\n",
      "Step 10  Loss: 0.2769637405872345\n",
      "total Loss of epoch  86  is  4.4004747569561005\n",
      "Step 0  Loss: 0.44884905219078064\n",
      "Step 1  Loss: 0.48925724625587463\n",
      "Step 2  Loss: 0.39100340008735657\n",
      "Step 3  Loss: 0.3823122978210449\n",
      "Step 4  Loss: 0.43440932035446167\n",
      "Step 5  Loss: 0.3835982382297516\n",
      "Step 6  Loss: 0.3697749674320221\n",
      "Step 7  Loss: 0.44292008876800537\n",
      "Step 8  Loss: 0.37898769974708557\n",
      "Step 9  Loss: 0.53495854139328\n",
      "Step 10  Loss: 0.3536505401134491\n",
      "total Loss of epoch  87  is  4.609721392393112\n",
      "Step 0  Loss: 0.4778405427932739\n",
      "Step 1  Loss: 0.4921821653842926\n",
      "Step 2  Loss: 0.38530418276786804\n",
      "Step 3  Loss: 0.4289930760860443\n",
      "Step 4  Loss: 0.4622659981250763\n",
      "Step 5  Loss: 0.355790913105011\n",
      "Step 6  Loss: 0.4605470597743988\n",
      "Step 7  Loss: 0.47307392954826355\n",
      "Step 8  Loss: 0.4078080952167511\n",
      "Step 9  Loss: 0.351780503988266\n",
      "Step 10  Loss: 0.4976021349430084\n",
      "total Loss of epoch  88  is  4.793188601732254\n",
      "Step 0  Loss: 0.4596850574016571\n",
      "Step 1  Loss: 0.31559860706329346\n",
      "Step 2  Loss: 0.36837491393089294\n",
      "Step 3  Loss: 0.3751317262649536\n",
      "Step 4  Loss: 0.39790990948677063\n",
      "Step 5  Loss: 0.3934520184993744\n",
      "Step 6  Loss: 0.42342516779899597\n",
      "Step 7  Loss: 0.42688190937042236\n",
      "Step 8  Loss: 0.3955935537815094\n",
      "Step 9  Loss: 0.4093664884567261\n",
      "Step 10  Loss: 0.3713107109069824\n",
      "total Loss of epoch  89  is  4.336730062961578\n",
      "Step 0  Loss: 0.4639357626438141\n",
      "Step 1  Loss: 0.5143914222717285\n",
      "Step 2  Loss: 0.33656036853790283\n",
      "Step 3  Loss: 0.3063833713531494\n",
      "Step 4  Loss: 0.3846591114997864\n",
      "Step 5  Loss: 0.3806420564651489\n",
      "Step 6  Loss: 0.3481051027774811\n",
      "Step 7  Loss: 0.34462299942970276\n",
      "Step 8  Loss: 0.48619359731674194\n",
      "Step 9  Loss: 0.47223803400993347\n",
      "Step 10  Loss: 0.42739182710647583\n",
      "total Loss of epoch  90  is  4.465123653411865\n",
      "Step 0  Loss: 0.455576628446579\n",
      "Step 1  Loss: 0.46850183606147766\n",
      "Step 2  Loss: 0.43505194783210754\n",
      "Step 3  Loss: 0.42275238037109375\n",
      "Step 4  Loss: 0.4164334535598755\n",
      "Step 5  Loss: 0.3213077485561371\n",
      "Step 6  Loss: 0.43764713406562805\n",
      "Step 7  Loss: 0.473497599363327\n",
      "Step 8  Loss: 0.5061548352241516\n",
      "Step 9  Loss: 0.41900137066841125\n",
      "Step 10  Loss: 0.3799300491809845\n",
      "total Loss of epoch  91  is  4.735854983329773\n",
      "Step 0  Loss: 0.4951852560043335\n",
      "Step 1  Loss: 0.3203786015510559\n",
      "Step 2  Loss: 0.48691311478614807\n",
      "Step 3  Loss: 0.33917784690856934\n",
      "Step 4  Loss: 0.4059284031391144\n",
      "Step 5  Loss: 0.424595445394516\n",
      "Step 6  Loss: 0.43502727150917053\n",
      "Step 7  Loss: 0.3617795407772064\n",
      "Step 8  Loss: 0.41841205954551697\n",
      "Step 9  Loss: 0.44017598032951355\n",
      "Step 10  Loss: 0.2699134647846222\n",
      "total Loss of epoch  92  is  4.397486984729767\n",
      "Step 0  Loss: 0.38329243659973145\n",
      "Step 1  Loss: 0.32091444730758667\n",
      "Step 2  Loss: 0.43754860758781433\n",
      "Step 3  Loss: 0.46808069944381714\n",
      "Step 4  Loss: 0.48207202553749084\n",
      "Step 5  Loss: 0.44024741649627686\n",
      "Step 6  Loss: 0.41775673627853394\n",
      "Step 7  Loss: 0.37584877014160156\n",
      "Step 8  Loss: 0.42396876215934753\n",
      "Step 9  Loss: 0.3788156807422638\n",
      "Step 10  Loss: 0.44366776943206787\n",
      "total Loss of epoch  93  is  4.572213351726532\n",
      "Step 0  Loss: 0.44614437222480774\n",
      "Step 1  Loss: 0.3823312222957611\n",
      "Step 2  Loss: 0.515477180480957\n",
      "Step 3  Loss: 0.546495795249939\n",
      "Step 4  Loss: 0.5334920287132263\n",
      "Step 5  Loss: 0.4030669927597046\n",
      "Step 6  Loss: 0.35493770241737366\n",
      "Step 7  Loss: 0.395233154296875\n",
      "Step 8  Loss: 0.41547733545303345\n",
      "Step 9  Loss: 0.4489518404006958\n",
      "Step 10  Loss: 0.4900103211402893\n",
      "total Loss of epoch  94  is  4.931617945432663\n",
      "Step 0  Loss: 0.4173176884651184\n",
      "Step 1  Loss: 0.5956125259399414\n",
      "Step 2  Loss: 0.44269561767578125\n",
      "Step 3  Loss: 0.3257867097854614\n",
      "Step 4  Loss: 0.46276310086250305\n",
      "Step 5  Loss: 0.3607419729232788\n",
      "Step 6  Loss: 0.40420013666152954\n",
      "Step 7  Loss: 0.46721118688583374\n",
      "Step 8  Loss: 0.41632765531539917\n",
      "Step 9  Loss: 0.38311877846717834\n",
      "Step 10  Loss: 0.41650018095970154\n",
      "total Loss of epoch  95  is  4.692275553941727\n",
      "Step 0  Loss: 0.49098485708236694\n",
      "Step 1  Loss: 0.4041235148906708\n",
      "Step 2  Loss: 0.4213981032371521\n",
      "Step 3  Loss: 0.5293899178504944\n",
      "Step 4  Loss: 0.3315373957157135\n",
      "Step 5  Loss: 0.4598485827445984\n",
      "Step 6  Loss: 0.38321438431739807\n",
      "Step 7  Loss: 0.44928988814353943\n",
      "Step 8  Loss: 0.4352707862854004\n",
      "Step 9  Loss: 0.4572879672050476\n",
      "Step 10  Loss: 0.41645094752311707\n",
      "total Loss of epoch  96  is  4.778796344995499\n",
      "Step 0  Loss: 0.44807693362236023\n",
      "Step 1  Loss: 0.39876237511634827\n",
      "Step 2  Loss: 0.4471626281738281\n",
      "Step 3  Loss: 0.44990622997283936\n",
      "Step 4  Loss: 0.42057129740715027\n",
      "Step 5  Loss: 0.4339975416660309\n",
      "Step 6  Loss: 0.3998416066169739\n",
      "Step 7  Loss: 0.3063756227493286\n",
      "Step 8  Loss: 0.3353300392627716\n",
      "Step 9  Loss: 0.4481087923049927\n",
      "Step 10  Loss: 0.49878740310668945\n",
      "total Loss of epoch  97  is  4.586920469999313\n",
      "Step 0  Loss: 0.36531922221183777\n",
      "Step 1  Loss: 0.39148658514022827\n",
      "Step 2  Loss: 0.48876646161079407\n",
      "Step 3  Loss: 0.45913103222846985\n",
      "Step 4  Loss: 0.4391782283782959\n",
      "Step 5  Loss: 0.5014876127243042\n",
      "Step 6  Loss: 0.5088508725166321\n",
      "Step 7  Loss: 0.4398563504219055\n",
      "Step 8  Loss: 0.3861190378665924\n",
      "Step 9  Loss: 0.44948238134384155\n",
      "Step 10  Loss: 0.38492655754089355\n",
      "total Loss of epoch  98  is  4.814604341983795\n",
      "Step 0  Loss: 0.5214880108833313\n",
      "Step 1  Loss: 0.40277206897735596\n",
      "Step 2  Loss: 0.3008934259414673\n",
      "Step 3  Loss: 0.338566392660141\n",
      "Step 4  Loss: 0.44688794016838074\n",
      "Step 5  Loss: 0.48866066336631775\n",
      "Step 6  Loss: 0.4120917022228241\n",
      "Step 7  Loss: 0.4635013937950134\n",
      "Step 8  Loss: 0.5626193284988403\n",
      "Step 9  Loss: 0.4118965268135071\n",
      "Step 10  Loss: 0.517536997795105\n",
      "total Loss of epoch  99  is  4.866914451122284\n",
      "Step 0  Loss: 0.459481418132782\n",
      "Step 1  Loss: 0.3935950994491577\n",
      "Step 2  Loss: 0.3998948931694031\n",
      "Step 3  Loss: 0.4310436546802521\n",
      "Step 4  Loss: 0.40987318754196167\n",
      "Step 5  Loss: 0.4322384297847748\n",
      "Step 6  Loss: 0.306986927986145\n",
      "Step 7  Loss: 0.4842877984046936\n",
      "Step 8  Loss: 0.3956349194049835\n",
      "Step 9  Loss: 0.4013822376728058\n",
      "Step 10  Loss: 0.3301909863948822\n",
      "total Loss of epoch  100  is  4.444609552621841\n",
      "Step 0  Loss: 0.4155481159687042\n",
      "Step 1  Loss: 0.536872386932373\n",
      "Step 2  Loss: 0.4082663357257843\n",
      "Step 3  Loss: 0.47168195247650146\n",
      "Step 4  Loss: 0.3936764895915985\n",
      "Step 5  Loss: 0.4417060613632202\n",
      "Step 6  Loss: 0.44277191162109375\n",
      "Step 7  Loss: 0.3887782096862793\n",
      "Step 8  Loss: 0.5026980638504028\n",
      "Step 9  Loss: 0.5013675093650818\n",
      "Step 10  Loss: 0.37338021397590637\n",
      "total Loss of epoch  101  is  4.876747250556946\n",
      "Step 0  Loss: 0.5200538635253906\n",
      "Step 1  Loss: 0.3818904757499695\n",
      "Step 2  Loss: 0.46113720536231995\n",
      "Step 3  Loss: 0.4849211275577545\n",
      "Step 4  Loss: 0.43987181782722473\n",
      "Step 5  Loss: 0.46681734919548035\n",
      "Step 6  Loss: 0.3741689920425415\n",
      "Step 7  Loss: 0.41272637248039246\n",
      "Step 8  Loss: 0.2782377302646637\n",
      "Step 9  Loss: 0.373908132314682\n",
      "Step 10  Loss: 0.3729311525821686\n",
      "total Loss of epoch  102  is  4.566664218902588\n",
      "Step 0  Loss: 0.3975900411605835\n",
      "Step 1  Loss: 0.36396080255508423\n",
      "Step 2  Loss: 0.4057067632675171\n",
      "Step 3  Loss: 0.34330981969833374\n",
      "Step 4  Loss: 0.4295518696308136\n",
      "Step 5  Loss: 0.40501102805137634\n",
      "Step 6  Loss: 0.31320348381996155\n",
      "Step 7  Loss: 0.45479637384414673\n",
      "Step 8  Loss: 0.3298516571521759\n",
      "Step 9  Loss: 0.398110568523407\n",
      "Step 10  Loss: 0.4376824200153351\n",
      "total Loss of epoch  103  is  4.278774827718735\n",
      "Step 0  Loss: 0.40525034070014954\n",
      "Step 1  Loss: 0.4126153588294983\n",
      "Step 2  Loss: 0.24587075412273407\n",
      "Step 3  Loss: 0.3460317552089691\n",
      "Step 4  Loss: 0.3325005769729614\n",
      "Step 5  Loss: 0.44752976298332214\n",
      "Step 6  Loss: 0.4006059467792511\n",
      "Step 7  Loss: 0.5336039662361145\n",
      "Step 8  Loss: 0.41624999046325684\n",
      "Step 9  Loss: 0.40312865376472473\n",
      "Step 10  Loss: 0.5580883622169495\n",
      "total Loss of epoch  104  is  4.501475468277931\n",
      "Step 0  Loss: 0.5004200339317322\n",
      "Step 1  Loss: 0.4216573238372803\n",
      "Step 2  Loss: 0.3824591338634491\n",
      "Step 3  Loss: 0.4404558837413788\n",
      "Step 4  Loss: 0.5048069357872009\n",
      "Step 5  Loss: 0.3951531648635864\n",
      "Step 6  Loss: 0.3644123673439026\n",
      "Step 7  Loss: 0.48462873697280884\n",
      "Step 8  Loss: 0.4689832329750061\n",
      "Step 9  Loss: 0.4739525318145752\n",
      "Step 10  Loss: 0.47480061650276184\n",
      "total Loss of epoch  105  is  4.911729961633682\n",
      "Step 0  Loss: 0.3513213098049164\n",
      "Step 1  Loss: 0.32159754633903503\n",
      "Step 2  Loss: 0.3890993297100067\n",
      "Step 3  Loss: 0.5423933863639832\n",
      "Step 4  Loss: 0.49959295988082886\n",
      "Step 5  Loss: 0.3277532756328583\n",
      "Step 6  Loss: 0.3098120391368866\n",
      "Step 7  Loss: 0.4766656160354614\n",
      "Step 8  Loss: 0.5469168424606323\n",
      "Step 9  Loss: 0.30262771248817444\n",
      "Step 10  Loss: 0.30795156955718994\n",
      "total Loss of epoch  106  is  4.375731587409973\n",
      "Step 0  Loss: 0.4392458498477936\n",
      "Step 1  Loss: 0.3879896104335785\n",
      "Step 2  Loss: 0.3817855417728424\n",
      "Step 3  Loss: 0.4808163046836853\n",
      "Step 4  Loss: 0.25080469250679016\n",
      "Step 5  Loss: 0.43140262365341187\n",
      "Step 6  Loss: 0.3682763874530792\n",
      "Step 7  Loss: 0.4407947361469269\n",
      "Step 8  Loss: 0.3184089958667755\n",
      "Step 9  Loss: 0.4906288981437683\n",
      "Step 10  Loss: 0.4418344497680664\n",
      "total Loss of epoch  107  is  4.431988090276718\n",
      "Step 0  Loss: 0.3495675325393677\n",
      "Step 1  Loss: 0.41823866963386536\n",
      "Step 2  Loss: 0.39817509055137634\n",
      "Step 3  Loss: 0.4227876663208008\n",
      "Step 4  Loss: 0.395106703042984\n",
      "Step 5  Loss: 0.42168253660202026\n",
      "Step 6  Loss: 0.42788922786712646\n",
      "Step 7  Loss: 0.5135409235954285\n",
      "Step 8  Loss: 0.4537408649921417\n",
      "Step 9  Loss: 0.5458483695983887\n",
      "Step 10  Loss: 0.4148998260498047\n",
      "total Loss of epoch  108  is  4.761477410793304\n",
      "Step 0  Loss: 0.3974515199661255\n",
      "Step 1  Loss: 0.4413911998271942\n",
      "Step 2  Loss: 0.43240028619766235\n",
      "Step 3  Loss: 0.3535107970237732\n",
      "Step 4  Loss: 0.3072347939014435\n",
      "Step 5  Loss: 0.3769557476043701\n",
      "Step 6  Loss: 0.3921835720539093\n",
      "Step 7  Loss: 0.35704460740089417\n",
      "Step 8  Loss: 0.3101407289505005\n",
      "Step 9  Loss: 0.25797003507614136\n",
      "Step 10  Loss: 0.4722807705402374\n",
      "total Loss of epoch  109  is  4.098564058542252\n",
      "Step 0  Loss: 0.3971138596534729\n",
      "Step 1  Loss: 0.4311501383781433\n",
      "Step 2  Loss: 0.3575737178325653\n",
      "Step 3  Loss: 0.4485154151916504\n",
      "Step 4  Loss: 0.4368142783641815\n",
      "Step 5  Loss: 0.3831329047679901\n",
      "Step 6  Loss: 0.42990243434906006\n",
      "Step 7  Loss: 0.4964050352573395\n",
      "Step 8  Loss: 0.42349883913993835\n",
      "Step 9  Loss: 0.26517611742019653\n",
      "Step 10  Loss: 0.345913827419281\n",
      "total Loss of epoch  110  is  4.415196567773819\n",
      "Step 0  Loss: 0.45182856917381287\n",
      "Step 1  Loss: 0.5493636727333069\n",
      "Step 2  Loss: 0.4319698214530945\n",
      "Step 3  Loss: 0.31156113743782043\n",
      "Step 4  Loss: 0.4165068566799164\n",
      "Step 5  Loss: 0.4341771900653839\n",
      "Step 6  Loss: 0.4223257005214691\n",
      "Step 7  Loss: 0.3839592933654785\n",
      "Step 8  Loss: 0.437654048204422\n",
      "Step 9  Loss: 0.410232812166214\n",
      "Step 10  Loss: 0.3500196933746338\n",
      "total Loss of epoch  111  is  4.599598795175552\n",
      "Step 0  Loss: 0.44688230752944946\n",
      "Step 1  Loss: 0.4348926246166229\n",
      "Step 2  Loss: 0.4288352131843567\n",
      "Step 3  Loss: 0.43390166759490967\n",
      "Step 4  Loss: 0.32241225242614746\n",
      "Step 5  Loss: 0.5295443534851074\n",
      "Step 6  Loss: 0.38941022753715515\n",
      "Step 7  Loss: 0.38327860832214355\n",
      "Step 8  Loss: 0.47523078322410583\n",
      "Step 9  Loss: 0.33989855647087097\n",
      "Step 10  Loss: 0.5084304809570312\n",
      "total Loss of epoch  112  is  4.6927170753479\n",
      "Step 0  Loss: 0.4064055383205414\n",
      "Step 1  Loss: 0.32054147124290466\n",
      "Step 2  Loss: 0.4787384271621704\n",
      "Step 3  Loss: 0.3650626242160797\n",
      "Step 4  Loss: 0.3100215792655945\n",
      "Step 5  Loss: 0.4747546911239624\n",
      "Step 6  Loss: 0.4334842264652252\n",
      "Step 7  Loss: 0.3240847885608673\n",
      "Step 8  Loss: 0.2725915014743805\n",
      "Step 9  Loss: 0.4433484971523285\n",
      "Step 10  Loss: 0.564957857131958\n",
      "total Loss of epoch  113  is  4.393991202116013\n",
      "Step 0  Loss: 0.4346042573451996\n",
      "Step 1  Loss: 0.3484281301498413\n",
      "Step 2  Loss: 0.48498329520225525\n",
      "Step 3  Loss: 0.37993448972702026\n",
      "Step 4  Loss: 0.3740081489086151\n",
      "Step 5  Loss: 0.39551395177841187\n",
      "Step 6  Loss: 0.49459943175315857\n",
      "Step 7  Loss: 0.45021647214889526\n",
      "Step 8  Loss: 0.37500303983688354\n",
      "Step 9  Loss: 0.4915410876274109\n",
      "Step 10  Loss: 0.4733707904815674\n",
      "total Loss of epoch  114  is  4.702203094959259\n",
      "Step 0  Loss: 0.4197049140930176\n",
      "Step 1  Loss: 0.2637776732444763\n",
      "Step 2  Loss: 0.34677696228027344\n",
      "Step 3  Loss: 0.4033569395542145\n",
      "Step 4  Loss: 0.44219714403152466\n",
      "Step 5  Loss: 0.30219635367393494\n",
      "Step 6  Loss: 0.4002959430217743\n",
      "Step 7  Loss: 0.3660741448402405\n",
      "Step 8  Loss: 0.44939929246902466\n",
      "Step 9  Loss: 0.48000603914260864\n",
      "Step 10  Loss: 0.34952694177627563\n",
      "total Loss of epoch  115  is  4.223312348127365\n",
      "Step 0  Loss: 0.4678705632686615\n",
      "Step 1  Loss: 0.46633005142211914\n",
      "Step 2  Loss: 0.5158811211585999\n",
      "Step 3  Loss: 0.47192418575286865\n",
      "Step 4  Loss: 0.47850629687309265\n",
      "Step 5  Loss: 0.4694732427597046\n",
      "Step 6  Loss: 0.4164291322231293\n",
      "Step 7  Loss: 0.4178294241428375\n",
      "Step 8  Loss: 0.38573330640792847\n",
      "Step 9  Loss: 0.4772203862667084\n",
      "Step 10  Loss: 0.38060981035232544\n",
      "total Loss of epoch  116  is  4.9478075206279755\n",
      "Step 0  Loss: 0.42680180072784424\n",
      "Step 1  Loss: 0.4298535883426666\n",
      "Step 2  Loss: 0.37982895970344543\n",
      "Step 3  Loss: 0.29271161556243896\n",
      "Step 4  Loss: 0.388624370098114\n",
      "Step 5  Loss: 0.49653512239456177\n",
      "Step 6  Loss: 0.3969309628009796\n",
      "Step 7  Loss: 0.4251802861690521\n",
      "Step 8  Loss: 0.44287192821502686\n",
      "Step 9  Loss: 0.3895667791366577\n",
      "Step 10  Loss: 0.444014310836792\n",
      "total Loss of epoch  117  is  4.512919723987579\n",
      "Step 0  Loss: 0.3011796474456787\n",
      "Step 1  Loss: 0.3730306029319763\n",
      "Step 2  Loss: 0.42130202054977417\n",
      "Step 3  Loss: 0.3140902817249298\n",
      "Step 4  Loss: 0.5186401605606079\n",
      "Step 5  Loss: 0.3854620158672333\n",
      "Step 6  Loss: 0.2860379219055176\n",
      "Step 7  Loss: 0.3333042860031128\n",
      "Step 8  Loss: 0.3727733790874481\n",
      "Step 9  Loss: 0.3808051645755768\n",
      "Step 10  Loss: 0.6804829835891724\n",
      "total Loss of epoch  118  is  4.367108464241028\n",
      "Step 0  Loss: 0.3356952369213104\n",
      "Step 1  Loss: 0.5058909058570862\n",
      "Step 2  Loss: 0.38871556520462036\n",
      "Step 3  Loss: 0.4148455560207367\n",
      "Step 4  Loss: 0.38467463850975037\n",
      "Step 5  Loss: 0.3399708867073059\n",
      "Step 6  Loss: 0.4238578975200653\n",
      "Step 7  Loss: 0.45308634638786316\n",
      "Step 8  Loss: 0.5192107558250427\n",
      "Step 9  Loss: 0.4222617447376251\n",
      "Step 10  Loss: 0.3357364237308502\n",
      "total Loss of epoch  119  is  4.5239459574222565\n",
      "Step 0  Loss: 0.472888708114624\n",
      "Step 1  Loss: 0.4378802478313446\n",
      "Step 2  Loss: 0.4249846041202545\n",
      "Step 3  Loss: 0.507560133934021\n",
      "Step 4  Loss: 0.34611940383911133\n",
      "Step 5  Loss: 0.41975897550582886\n",
      "Step 6  Loss: 0.3540074825286865\n",
      "Step 7  Loss: 0.23853467404842377\n",
      "Step 8  Loss: 0.30464375019073486\n",
      "Step 9  Loss: 0.32056936621665955\n",
      "Step 10  Loss: 0.4051917493343353\n",
      "total Loss of epoch  120  is  4.232139095664024\n",
      "Step 0  Loss: 0.3652822971343994\n",
      "Step 1  Loss: 0.3863427937030792\n",
      "Step 2  Loss: 0.3052480220794678\n",
      "Step 3  Loss: 0.2914179265499115\n",
      "Step 4  Loss: 0.2755276560783386\n",
      "Step 5  Loss: 0.363625168800354\n",
      "Step 6  Loss: 0.40984711050987244\n",
      "Step 7  Loss: 0.45200690627098083\n",
      "Step 8  Loss: 0.37566325068473816\n",
      "Step 9  Loss: 0.3920084238052368\n",
      "Step 10  Loss: 0.5421720743179321\n",
      "total Loss of epoch  121  is  4.159141629934311\n",
      "Step 0  Loss: 0.40392521023750305\n",
      "Step 1  Loss: 0.4991346001625061\n",
      "Step 2  Loss: 0.33669859170913696\n",
      "Step 3  Loss: 0.3634902238845825\n",
      "Step 4  Loss: 0.3425227999687195\n",
      "Step 5  Loss: 0.4532144069671631\n",
      "Step 6  Loss: 0.38539355993270874\n",
      "Step 7  Loss: 0.3600844442844391\n",
      "Step 8  Loss: 0.3679889738559723\n",
      "Step 9  Loss: 0.3388357162475586\n",
      "Step 10  Loss: 0.39729124307632446\n",
      "total Loss of epoch  122  is  4.248579770326614\n",
      "Step 0  Loss: 0.5235108137130737\n",
      "Step 1  Loss: 0.41846880316734314\n",
      "Step 2  Loss: 0.3922117054462433\n",
      "Step 3  Loss: 0.34325823187828064\n",
      "Step 4  Loss: 0.42855721712112427\n",
      "Step 5  Loss: 0.37345996499061584\n",
      "Step 6  Loss: 0.3222023546695709\n",
      "Step 7  Loss: 0.4226475954055786\n",
      "Step 8  Loss: 0.5060200095176697\n",
      "Step 9  Loss: 0.3878052830696106\n",
      "Step 10  Loss: 0.28507375717163086\n",
      "total Loss of epoch  123  is  4.403215736150742\n",
      "Step 0  Loss: 0.40726718306541443\n",
      "Step 1  Loss: 0.5134028792381287\n",
      "Step 2  Loss: 0.40196698904037476\n",
      "Step 3  Loss: 0.3268994390964508\n",
      "Step 4  Loss: 0.43169036507606506\n",
      "Step 5  Loss: 0.3037334084510803\n",
      "Step 6  Loss: 0.3878832757472992\n",
      "Step 7  Loss: 0.5298247337341309\n",
      "Step 8  Loss: 0.39334648847579956\n",
      "Step 9  Loss: 0.4418121576309204\n",
      "Step 10  Loss: 0.4294387698173523\n",
      "total Loss of epoch  124  is  4.567265689373016\n",
      "Step 0  Loss: 0.4116394519805908\n",
      "Step 1  Loss: 0.34859463572502136\n",
      "Step 2  Loss: 0.37494319677352905\n",
      "Step 3  Loss: 0.3578327000141144\n",
      "Step 4  Loss: 0.413945734500885\n",
      "Step 5  Loss: 0.5409931540489197\n",
      "Step 6  Loss: 0.35092893242836\n",
      "Step 7  Loss: 0.36078372597694397\n",
      "Step 8  Loss: 0.36086952686309814\n",
      "Step 9  Loss: 0.4677707254886627\n",
      "Step 10  Loss: 0.4871060252189636\n",
      "total Loss of epoch  125  is  4.475407809019089\n",
      "Step 0  Loss: 0.4261064827442169\n",
      "Step 1  Loss: 0.38915207982063293\n",
      "Step 2  Loss: 0.3485126197338104\n",
      "Step 3  Loss: 0.4287469685077667\n",
      "Step 4  Loss: 0.49854639172554016\n",
      "Step 5  Loss: 0.5008219480514526\n",
      "Step 6  Loss: 0.4576127827167511\n",
      "Step 7  Loss: 0.3955644369125366\n",
      "Step 8  Loss: 0.4368651211261749\n",
      "Step 9  Loss: 0.3883233666419983\n",
      "Step 10  Loss: 0.41846737265586853\n",
      "total Loss of epoch  126  is  4.688719570636749\n",
      "Step 0  Loss: 0.48547327518463135\n",
      "Step 1  Loss: 0.34164801239967346\n",
      "Step 2  Loss: 0.4407515227794647\n",
      "Step 3  Loss: 0.3896232843399048\n",
      "Step 4  Loss: 0.3754105567932129\n",
      "Step 5  Loss: 0.4038573205471039\n",
      "Step 6  Loss: 0.37436625361442566\n",
      "Step 7  Loss: 0.29510578513145447\n",
      "Step 8  Loss: 0.4462239146232605\n",
      "Step 9  Loss: 0.3541005849838257\n",
      "Step 10  Loss: 0.3432232439517975\n",
      "total Loss of epoch  127  is  4.249783754348755\n",
      "Step 0  Loss: 0.40957188606262207\n",
      "Step 1  Loss: 0.41332435607910156\n",
      "Step 2  Loss: 0.4962120056152344\n",
      "Step 3  Loss: 0.4424259066581726\n",
      "Step 4  Loss: 0.41840121150016785\n",
      "Step 5  Loss: 0.3912152945995331\n",
      "Step 6  Loss: 0.31581398844718933\n",
      "Step 7  Loss: 0.4314540922641754\n",
      "Step 8  Loss: 0.44777917861938477\n",
      "Step 9  Loss: 0.3942330479621887\n",
      "Step 10  Loss: 0.4049152731895447\n",
      "total Loss of epoch  128  is  4.5653462409973145\n",
      "Step 0  Loss: 0.3177560567855835\n",
      "Step 1  Loss: 0.41868242621421814\n",
      "Step 2  Loss: 0.46675652265548706\n",
      "Step 3  Loss: 0.3915332853794098\n",
      "Step 4  Loss: 0.3318631649017334\n",
      "Step 5  Loss: 0.4587816298007965\n",
      "Step 6  Loss: 0.4227106273174286\n",
      "Step 7  Loss: 0.49726250767707825\n",
      "Step 8  Loss: 0.3471686840057373\n",
      "Step 9  Loss: 0.35509517788887024\n",
      "Step 10  Loss: 0.45334628224372864\n",
      "total Loss of epoch  129  is  4.460956364870071\n",
      "Step 0  Loss: 0.3312171697616577\n",
      "Step 1  Loss: 0.48490840196609497\n",
      "Step 2  Loss: 0.44863489270210266\n",
      "Step 3  Loss: 0.3683827519416809\n",
      "Step 4  Loss: 0.4424988031387329\n",
      "Step 5  Loss: 0.3022097051143646\n",
      "Step 6  Loss: 0.3564438223838806\n",
      "Step 7  Loss: 0.41235989332199097\n",
      "Step 8  Loss: 0.4665966033935547\n",
      "Step 9  Loss: 0.37428656220436096\n",
      "Step 10  Loss: 0.4860609769821167\n",
      "total Loss of epoch  130  is  4.473599582910538\n",
      "Step 0  Loss: 0.4734511077404022\n",
      "Step 1  Loss: 0.37658655643463135\n",
      "Step 2  Loss: 0.38904380798339844\n",
      "Step 3  Loss: 0.4671225845813751\n",
      "Step 4  Loss: 0.5630494356155396\n",
      "Step 5  Loss: 0.42635273933410645\n",
      "Step 6  Loss: 0.46231141686439514\n",
      "Step 7  Loss: 0.4839506447315216\n",
      "Step 8  Loss: 0.4802408218383789\n",
      "Step 9  Loss: 0.4130631685256958\n",
      "Step 10  Loss: 0.3445304036140442\n",
      "total Loss of epoch  131  is  4.879702687263489\n",
      "Step 0  Loss: 0.36480215191841125\n",
      "Step 1  Loss: 0.4817996919155121\n",
      "Step 2  Loss: 0.39412468671798706\n",
      "Step 3  Loss: 0.4729090631008148\n",
      "Step 4  Loss: 0.46277332305908203\n",
      "Step 5  Loss: 0.346537709236145\n",
      "Step 6  Loss: 0.43351200222969055\n",
      "Step 7  Loss: 0.4271775484085083\n",
      "Step 8  Loss: 0.45987650752067566\n",
      "Step 9  Loss: 0.3710499405860901\n",
      "Step 10  Loss: 0.2673106789588928\n",
      "total Loss of epoch  132  is  4.48187330365181\n",
      "Step 0  Loss: 0.4547622501850128\n",
      "Step 1  Loss: 0.45112523436546326\n",
      "Step 2  Loss: 0.41820648312568665\n",
      "Step 3  Loss: 0.4636019170284271\n",
      "Step 4  Loss: 0.3254534602165222\n",
      "Step 5  Loss: 0.42796948552131653\n",
      "Step 6  Loss: 0.4372759759426117\n",
      "Step 7  Loss: 0.5164121389389038\n",
      "Step 8  Loss: 0.4076722264289856\n",
      "Step 9  Loss: 0.3218059241771698\n",
      "Step 10  Loss: 0.4285534620285034\n",
      "total Loss of epoch  133  is  4.652838557958603\n",
      "Step 0  Loss: 0.3175555169582367\n",
      "Step 1  Loss: 0.34957247972488403\n",
      "Step 2  Loss: 0.3815145194530487\n",
      "Step 3  Loss: 0.42422518134117126\n",
      "Step 4  Loss: 0.4033968448638916\n",
      "Step 5  Loss: 0.4700496792793274\n",
      "Step 6  Loss: 0.4095357656478882\n",
      "Step 7  Loss: 0.31318604946136475\n",
      "Step 8  Loss: 0.4659700393676758\n",
      "Step 9  Loss: 0.5097606778144836\n",
      "Step 10  Loss: 0.4222922921180725\n",
      "total Loss of epoch  134  is  4.4670590460300446\n",
      "Step 0  Loss: 0.45183899998664856\n",
      "Step 1  Loss: 0.4048044979572296\n",
      "Step 2  Loss: 0.4779409170150757\n",
      "Step 3  Loss: 0.3275696337223053\n",
      "Step 4  Loss: 0.33190470933914185\n",
      "Step 5  Loss: 0.35666507482528687\n",
      "Step 6  Loss: 0.4744704067707062\n",
      "Step 7  Loss: 0.46456971764564514\n",
      "Step 8  Loss: 0.43419307470321655\n",
      "Step 9  Loss: 0.4278072416782379\n",
      "Step 10  Loss: 0.2674504518508911\n",
      "total Loss of epoch  135  is  4.419214725494385\n",
      "Step 0  Loss: 0.39927199482917786\n",
      "Step 1  Loss: 0.3274790048599243\n",
      "Step 2  Loss: 0.4187023937702179\n",
      "Step 3  Loss: 0.46885642409324646\n",
      "Step 4  Loss: 0.38910284638404846\n",
      "Step 5  Loss: 0.36156994104385376\n",
      "Step 6  Loss: 0.4474833905696869\n",
      "Step 7  Loss: 0.32223984599113464\n",
      "Step 8  Loss: 0.3768686354160309\n",
      "Step 9  Loss: 0.3410404324531555\n",
      "Step 10  Loss: 0.26682576537132263\n",
      "total Loss of epoch  136  is  4.119440674781799\n",
      "Step 0  Loss: 0.4024430513381958\n",
      "Step 1  Loss: 0.3792549967765808\n",
      "Step 2  Loss: 0.34808677434921265\n",
      "Step 3  Loss: 0.41639426350593567\n",
      "Step 4  Loss: 0.2961764931678772\n",
      "Step 5  Loss: 0.4254171550273895\n",
      "Step 6  Loss: 0.2946185767650604\n",
      "Step 7  Loss: 0.37277743220329285\n",
      "Step 8  Loss: 0.30966031551361084\n",
      "Step 9  Loss: 0.5221436023712158\n",
      "Step 10  Loss: 0.3371312916278839\n",
      "total Loss of epoch  137  is  4.1041039526462555\n",
      "Step 0  Loss: 0.4056223928928375\n",
      "Step 1  Loss: 0.4330660402774811\n",
      "Step 2  Loss: 0.4070929288864136\n",
      "Step 3  Loss: 0.44666826725006104\n",
      "Step 4  Loss: 0.5009498000144958\n",
      "Step 5  Loss: 0.38912078738212585\n",
      "Step 6  Loss: 0.24968761205673218\n",
      "Step 7  Loss: 0.4634327292442322\n",
      "Step 8  Loss: 0.4468139410018921\n",
      "Step 9  Loss: 0.5109901428222656\n",
      "Step 10  Loss: 0.3339897394180298\n",
      "total Loss of epoch  138  is  4.587434381246567\n",
      "Step 0  Loss: 0.3173994719982147\n",
      "Step 1  Loss: 0.36021196842193604\n",
      "Step 2  Loss: 0.45918500423431396\n",
      "Step 3  Loss: 0.44306060671806335\n",
      "Step 4  Loss: 0.5059000849723816\n",
      "Step 5  Loss: 0.2894577085971832\n",
      "Step 6  Loss: 0.4881042540073395\n",
      "Step 7  Loss: 0.5172734260559082\n",
      "Step 8  Loss: 0.38127362728118896\n",
      "Step 9  Loss: 0.41606757044792175\n",
      "Step 10  Loss: 0.49982529878616333\n",
      "total Loss of epoch  139  is  4.677759021520615\n",
      "Step 0  Loss: 0.43496549129486084\n",
      "Step 1  Loss: 0.36590060591697693\n",
      "Step 2  Loss: 0.3519093990325928\n",
      "Step 3  Loss: 0.36082419753074646\n",
      "Step 4  Loss: 0.3836204409599304\n",
      "Step 5  Loss: 0.4601154029369354\n",
      "Step 6  Loss: 0.3896021544933319\n",
      "Step 7  Loss: 0.38119858503341675\n",
      "Step 8  Loss: 0.36037132143974304\n",
      "Step 9  Loss: 0.2768348455429077\n",
      "Step 10  Loss: 0.39185017347335815\n",
      "total Loss of epoch  140  is  4.1571926176548\n",
      "Step 0  Loss: 0.33089524507522583\n",
      "Step 1  Loss: 0.4218067526817322\n",
      "Step 2  Loss: 0.40901634097099304\n",
      "Step 3  Loss: 0.4035130739212036\n",
      "Step 4  Loss: 0.44926556944847107\n",
      "Step 5  Loss: 0.44719159603118896\n",
      "Step 6  Loss: 0.4184846580028534\n",
      "Step 7  Loss: 0.39067932963371277\n",
      "Step 8  Loss: 0.37089240550994873\n",
      "Step 9  Loss: 0.43369659781455994\n",
      "Step 10  Loss: 0.4797321557998657\n",
      "total Loss of epoch  141  is  4.555173724889755\n",
      "Step 0  Loss: 0.34910306334495544\n",
      "Step 1  Loss: 0.4288376569747925\n",
      "Step 2  Loss: 0.43659406900405884\n",
      "Step 3  Loss: 0.4077836871147156\n",
      "Step 4  Loss: 0.37035778164863586\n",
      "Step 5  Loss: 0.4575885236263275\n",
      "Step 6  Loss: 0.42150983214378357\n",
      "Step 7  Loss: 0.4584929645061493\n",
      "Step 8  Loss: 0.4387293756008148\n",
      "Step 9  Loss: 0.3643878698348999\n",
      "Step 10  Loss: 0.44595012068748474\n",
      "total Loss of epoch  142  is  4.579334944486618\n",
      "Step 0  Loss: 0.4624565839767456\n",
      "Step 1  Loss: 0.3681388199329376\n",
      "Step 2  Loss: 0.21685351431369781\n",
      "Step 3  Loss: 0.4493619203567505\n",
      "Step 4  Loss: 0.2991204559803009\n",
      "Step 5  Loss: 0.4418953061103821\n",
      "Step 6  Loss: 0.3712652027606964\n",
      "Step 7  Loss: 0.46232256293296814\n",
      "Step 8  Loss: 0.29595452547073364\n",
      "Step 9  Loss: 0.41369393467903137\n",
      "Step 10  Loss: 0.3175049424171448\n",
      "total Loss of epoch  143  is  4.098567768931389\n",
      "Step 0  Loss: 0.3022802174091339\n",
      "Step 1  Loss: 0.43180450797080994\n",
      "Step 2  Loss: 0.5576937198638916\n",
      "Step 3  Loss: 0.45292168855667114\n",
      "Step 4  Loss: 0.3418380916118622\n",
      "Step 5  Loss: 0.5014014840126038\n",
      "Step 6  Loss: 0.42126959562301636\n",
      "Step 7  Loss: 0.3986194431781769\n",
      "Step 8  Loss: 0.31349194049835205\n",
      "Step 9  Loss: 0.4341099262237549\n",
      "Step 10  Loss: 0.3783700466156006\n",
      "total Loss of epoch  144  is  4.533800661563873\n",
      "Step 0  Loss: 0.45219525694847107\n",
      "Step 1  Loss: 0.40544894337654114\n",
      "Step 2  Loss: 0.3548195958137512\n",
      "Step 3  Loss: 0.2615692913532257\n",
      "Step 4  Loss: 0.4777959883213043\n",
      "Step 5  Loss: 0.3437681496143341\n",
      "Step 6  Loss: 0.48994746804237366\n",
      "Step 7  Loss: 0.2965390980243683\n",
      "Step 8  Loss: 0.44878026843070984\n",
      "Step 9  Loss: 0.33934804797172546\n",
      "Step 10  Loss: 0.28879809379577637\n",
      "total Loss of epoch  145  is  4.159010201692581\n",
      "Step 0  Loss: 0.4585736393928528\n",
      "Step 1  Loss: 0.40919652581214905\n",
      "Step 2  Loss: 0.46499428153038025\n",
      "Step 3  Loss: 0.3275371193885803\n",
      "Step 4  Loss: 0.45331820845603943\n",
      "Step 5  Loss: 0.5823500752449036\n",
      "Step 6  Loss: 0.4178595542907715\n",
      "Step 7  Loss: 0.31612253189086914\n",
      "Step 8  Loss: 0.46409618854522705\n",
      "Step 9  Loss: 0.3449479639530182\n",
      "Step 10  Loss: 0.3925217390060425\n",
      "total Loss of epoch  146  is  4.631517827510834\n",
      "Step 0  Loss: 0.3934035003185272\n",
      "Step 1  Loss: 0.3773576021194458\n",
      "Step 2  Loss: 0.3224443197250366\n",
      "Step 3  Loss: 0.40996405482292175\n",
      "Step 4  Loss: 0.4045543372631073\n",
      "Step 5  Loss: 0.3097590506076813\n",
      "Step 6  Loss: 0.4210827350616455\n",
      "Step 7  Loss: 0.340979665517807\n",
      "Step 8  Loss: 0.4092046022415161\n",
      "Step 9  Loss: 0.44342514872550964\n",
      "Step 10  Loss: 0.6202971339225769\n",
      "total Loss of epoch  147  is  4.452472150325775\n",
      "Step 0  Loss: 0.3481844365596771\n",
      "Step 1  Loss: 0.405683696269989\n",
      "Step 2  Loss: 0.38514554500579834\n",
      "Step 3  Loss: 0.2708875834941864\n",
      "Step 4  Loss: 0.4219718277454376\n",
      "Step 5  Loss: 0.27839112281799316\n",
      "Step 6  Loss: 0.29698821902275085\n",
      "Step 7  Loss: 0.38236624002456665\n",
      "Step 8  Loss: 0.45867684483528137\n",
      "Step 9  Loss: 0.47398099303245544\n",
      "Step 10  Loss: 0.3825702369213104\n",
      "total Loss of epoch  148  is  4.104846745729446\n",
      "Step 0  Loss: 0.3475184142589569\n",
      "Step 1  Loss: 0.32164937257766724\n",
      "Step 2  Loss: 0.37244004011154175\n",
      "Step 3  Loss: 0.38929739594459534\n",
      "Step 4  Loss: 0.4045296907424927\n",
      "Step 5  Loss: 0.3740915358066559\n",
      "Step 6  Loss: 0.3428603708744049\n",
      "Step 7  Loss: 0.3316064774990082\n",
      "Step 8  Loss: 0.4637691378593445\n",
      "Step 9  Loss: 0.3659130930900574\n",
      "Step 10  Loss: 0.20671136677265167\n",
      "total Loss of epoch  149  is  3.9203868955373764\n",
      "Step 0  Loss: 0.406648188829422\n",
      "Step 1  Loss: 0.31584492325782776\n",
      "Step 2  Loss: 0.37558576464653015\n",
      "Step 3  Loss: 0.33912065625190735\n",
      "Step 4  Loss: 0.33740007877349854\n",
      "Step 5  Loss: 0.42489075660705566\n",
      "Step 6  Loss: 0.368502676486969\n",
      "Step 7  Loss: 0.4375414550304413\n",
      "Step 8  Loss: 0.3971039354801178\n",
      "Step 9  Loss: 0.4736267328262329\n",
      "Step 10  Loss: 0.44092002511024475\n",
      "total Loss of epoch  150  is  4.317185193300247\n",
      "Step 0  Loss: 0.3701850473880768\n",
      "Step 1  Loss: 0.4209883511066437\n",
      "Step 2  Loss: 0.4494531452655792\n",
      "Step 3  Loss: 0.35121095180511475\n",
      "Step 4  Loss: 0.4032920002937317\n",
      "Step 5  Loss: 0.4721010625362396\n",
      "Step 6  Loss: 0.3605055510997772\n",
      "Step 7  Loss: 0.36160433292388916\n",
      "Step 8  Loss: 0.3365497589111328\n",
      "Step 9  Loss: 0.37295106053352356\n",
      "Step 10  Loss: 0.31797850131988525\n",
      "total Loss of epoch  151  is  4.216819763183594\n",
      "Step 0  Loss: 0.3407336175441742\n",
      "Step 1  Loss: 0.29003196954727173\n",
      "Step 2  Loss: 0.4346250593662262\n",
      "Step 3  Loss: 0.44781309366226196\n",
      "Step 4  Loss: 0.30554506182670593\n",
      "Step 5  Loss: 0.5002046823501587\n",
      "Step 6  Loss: 0.43684589862823486\n",
      "Step 7  Loss: 0.4826279282569885\n",
      "Step 8  Loss: 0.39700520038604736\n",
      "Step 9  Loss: 0.3407353162765503\n",
      "Step 10  Loss: 0.48534971475601196\n",
      "total Loss of epoch  152  is  4.461517542600632\n",
      "Step 0  Loss: 0.35854047536849976\n",
      "Step 1  Loss: 0.28926560282707214\n",
      "Step 2  Loss: 0.4817759096622467\n",
      "Step 3  Loss: 0.30238473415374756\n",
      "Step 4  Loss: 0.45757997035980225\n",
      "Step 5  Loss: 0.3727411925792694\n",
      "Step 6  Loss: 0.2265792042016983\n",
      "Step 7  Loss: 0.4274342358112335\n",
      "Step 8  Loss: 0.3817400336265564\n",
      "Step 9  Loss: 0.4783878028392792\n",
      "Step 10  Loss: 0.27442264556884766\n",
      "total Loss of epoch  153  is  4.050851806998253\n",
      "Step 0  Loss: 0.40824881196022034\n",
      "Step 1  Loss: 0.36421000957489014\n",
      "Step 2  Loss: 0.4461820125579834\n",
      "Step 3  Loss: 0.5031884908676147\n",
      "Step 4  Loss: 0.2908943295478821\n",
      "Step 5  Loss: 0.3896864950656891\n",
      "Step 6  Loss: 0.40716180205345154\n",
      "Step 7  Loss: 0.4516923725605011\n",
      "Step 8  Loss: 0.5514477491378784\n",
      "Step 9  Loss: 0.39381903409957886\n",
      "Step 10  Loss: 0.4142919182777405\n",
      "total Loss of epoch  154  is  4.62082302570343\n",
      "Step 0  Loss: 0.522610604763031\n",
      "Step 1  Loss: 0.40882009267807007\n",
      "Step 2  Loss: 0.3708961308002472\n",
      "Step 3  Loss: 0.38877975940704346\n",
      "Step 4  Loss: 0.3641093075275421\n",
      "Step 5  Loss: 0.3459950387477875\n",
      "Step 6  Loss: 0.50321364402771\n",
      "Step 7  Loss: 0.49907463788986206\n",
      "Step 8  Loss: 0.39399591088294983\n",
      "Step 9  Loss: 0.3692114055156708\n",
      "Step 10  Loss: 0.4364009499549866\n",
      "total Loss of epoch  155  is  4.6031074821949005\n",
      "Step 0  Loss: 0.4452855885028839\n",
      "Step 1  Loss: 0.35600095987319946\n",
      "Step 2  Loss: 0.42138075828552246\n",
      "Step 3  Loss: 0.25459030270576477\n",
      "Step 4  Loss: 0.3183862566947937\n",
      "Step 5  Loss: 0.3574937880039215\n",
      "Step 6  Loss: 0.41417673230171204\n",
      "Step 7  Loss: 0.3960482180118561\n",
      "Step 8  Loss: 0.4487181603908539\n",
      "Step 9  Loss: 0.33952394127845764\n",
      "Step 10  Loss: 0.17908604443073273\n",
      "total Loss of epoch  156  is  3.930690750479698\n",
      "Step 0  Loss: 0.33374348282814026\n",
      "Step 1  Loss: 0.450022429227829\n",
      "Step 2  Loss: 0.4664415121078491\n",
      "Step 3  Loss: 0.4057239890098572\n",
      "Step 4  Loss: 0.43363645672798157\n",
      "Step 5  Loss: 0.458333820104599\n",
      "Step 6  Loss: 0.40081602334976196\n",
      "Step 7  Loss: 0.3954096734523773\n",
      "Step 8  Loss: 0.36658018827438354\n",
      "Step 9  Loss: 0.43304115533828735\n",
      "Step 10  Loss: 0.3330210745334625\n",
      "total Loss of epoch  157  is  4.476769804954529\n",
      "Step 0  Loss: 0.398605614900589\n",
      "Step 1  Loss: 0.2911262810230255\n",
      "Step 2  Loss: 0.41162341833114624\n",
      "Step 3  Loss: 0.41826319694519043\n",
      "Step 4  Loss: 0.4001510739326477\n",
      "Step 5  Loss: 0.40794625878334045\n",
      "Step 6  Loss: 0.41755327582359314\n",
      "Step 7  Loss: 0.3467363119125366\n",
      "Step 8  Loss: 0.3880707025527954\n",
      "Step 9  Loss: 0.3138248324394226\n",
      "Step 10  Loss: 0.4079263508319855\n",
      "total Loss of epoch  158  is  4.201827317476273\n",
      "Step 0  Loss: 0.4354133605957031\n",
      "Step 1  Loss: 0.3142925500869751\n",
      "Step 2  Loss: 0.3766320049762726\n",
      "Step 3  Loss: 0.4828835129737854\n",
      "Step 4  Loss: 0.3429368734359741\n",
      "Step 5  Loss: 0.5018877387046814\n",
      "Step 6  Loss: 0.25858932733535767\n",
      "Step 7  Loss: 0.37805745005607605\n",
      "Step 8  Loss: 0.3441101312637329\n",
      "Step 9  Loss: 0.41781115531921387\n",
      "Step 10  Loss: 0.541420042514801\n",
      "total Loss of epoch  159  is  4.394034147262573\n",
      "Step 0  Loss: 0.37755414843559265\n",
      "Step 1  Loss: 0.42031610012054443\n",
      "Step 2  Loss: 0.461213618516922\n",
      "Step 3  Loss: 0.3526235520839691\n",
      "Step 4  Loss: 0.3375571072101593\n",
      "Step 5  Loss: 0.45993268489837646\n",
      "Step 6  Loss: 0.40278375148773193\n",
      "Step 7  Loss: 0.32140016555786133\n",
      "Step 8  Loss: 0.4107309877872467\n",
      "Step 9  Loss: 0.3627246916294098\n",
      "Step 10  Loss: 0.4443046450614929\n",
      "total Loss of epoch  160  is  4.351141452789307\n",
      "Step 0  Loss: 0.41605910658836365\n",
      "Step 1  Loss: 0.3681856393814087\n",
      "Step 2  Loss: 0.2692757546901703\n",
      "Step 3  Loss: 0.42249995470046997\n",
      "Step 4  Loss: 0.37956544756889343\n",
      "Step 5  Loss: 0.44027483463287354\n",
      "Step 6  Loss: 0.2177893966436386\n",
      "Step 7  Loss: 0.5103206634521484\n",
      "Step 8  Loss: 0.3577291965484619\n",
      "Step 9  Loss: 0.4104202389717102\n",
      "Step 10  Loss: 0.2584080696105957\n",
      "total Loss of epoch  161  is  4.050528302788734\n",
      "Step 0  Loss: 0.4714714288711548\n",
      "Step 1  Loss: 0.35455021262168884\n",
      "Step 2  Loss: 0.34456416964530945\n",
      "Step 3  Loss: 0.4266170263290405\n",
      "Step 4  Loss: 0.47737425565719604\n",
      "Step 5  Loss: 0.46821820735931396\n",
      "Step 6  Loss: 0.3328261077404022\n",
      "Step 7  Loss: 0.3848211467266083\n",
      "Step 8  Loss: 0.3966502249240875\n",
      "Step 9  Loss: 0.439114511013031\n",
      "Step 10  Loss: 0.39080843329429626\n",
      "total Loss of epoch  162  is  4.487015724182129\n",
      "Step 0  Loss: 0.4557573199272156\n",
      "Step 1  Loss: 0.3974301815032959\n",
      "Step 2  Loss: 0.4396182596683502\n",
      "Step 3  Loss: 0.35797208547592163\n",
      "Step 4  Loss: 0.38189929723739624\n",
      "Step 5  Loss: 0.3996897041797638\n",
      "Step 6  Loss: 0.37210768461227417\n",
      "Step 7  Loss: 0.38275638222694397\n",
      "Step 8  Loss: 0.5066523551940918\n",
      "Step 9  Loss: 0.38639137148857117\n",
      "Step 10  Loss: 0.4761940538883209\n",
      "total Loss of epoch  163  is  4.556468695402145\n",
      "Step 0  Loss: 0.2152584046125412\n",
      "Step 1  Loss: 0.36258482933044434\n",
      "Step 2  Loss: 0.40059414505958557\n",
      "Step 3  Loss: 0.46188047528266907\n",
      "Step 4  Loss: 0.47672000527381897\n",
      "Step 5  Loss: 0.28398004174232483\n",
      "Step 6  Loss: 0.414874792098999\n",
      "Step 7  Loss: 0.45781415700912476\n",
      "Step 8  Loss: 0.430649071931839\n",
      "Step 9  Loss: 0.4220823049545288\n",
      "Step 10  Loss: 0.41800886392593384\n",
      "total Loss of epoch  164  is  4.344447091221809\n",
      "Step 0  Loss: 0.3404065668582916\n",
      "Step 1  Loss: 0.4116857349872589\n",
      "Step 2  Loss: 0.33874109387397766\n",
      "Step 3  Loss: 0.4255909323692322\n",
      "Step 4  Loss: 0.3997379541397095\n",
      "Step 5  Loss: 0.27933868765830994\n",
      "Step 6  Loss: 0.295990914106369\n",
      "Step 7  Loss: 0.3792504668235779\n",
      "Step 8  Loss: 0.3645693361759186\n",
      "Step 9  Loss: 0.43855398893356323\n",
      "Step 10  Loss: 0.44299307465553284\n",
      "total Loss of epoch  165  is  4.116858750581741\n",
      "Step 0  Loss: 0.34066593647003174\n",
      "Step 1  Loss: 0.29014238715171814\n",
      "Step 2  Loss: 0.33207786083221436\n",
      "Step 3  Loss: 0.42863166332244873\n",
      "Step 4  Loss: 0.42736920714378357\n",
      "Step 5  Loss: 0.3743102252483368\n",
      "Step 6  Loss: 0.3500484526157379\n",
      "Step 7  Loss: 0.3018651604652405\n",
      "Step 8  Loss: 0.24515105783939362\n",
      "Step 9  Loss: 0.4113168716430664\n",
      "Step 10  Loss: 0.4952777922153473\n",
      "total Loss of epoch  166  is  3.996856614947319\n",
      "Step 0  Loss: 0.35609737038612366\n",
      "Step 1  Loss: 0.42370450496673584\n",
      "Step 2  Loss: 0.3386308252811432\n",
      "Step 3  Loss: 0.39588335156440735\n",
      "Step 4  Loss: 0.38311466574668884\n",
      "Step 5  Loss: 0.3714528977870941\n",
      "Step 6  Loss: 0.3097919225692749\n",
      "Step 7  Loss: 0.30920013785362244\n",
      "Step 8  Loss: 0.43881547451019287\n",
      "Step 9  Loss: 0.49830371141433716\n",
      "Step 10  Loss: 0.3089771866798401\n",
      "total Loss of epoch  167  is  4.1339720487594604\n",
      "Step 0  Loss: 0.3439289927482605\n",
      "Step 1  Loss: 0.4107053279876709\n",
      "Step 2  Loss: 0.30241110920906067\n",
      "Step 3  Loss: 0.38642194867134094\n",
      "Step 4  Loss: 0.33099356293678284\n",
      "Step 5  Loss: 0.33316004276275635\n",
      "Step 6  Loss: 0.3869483768939972\n",
      "Step 7  Loss: 0.2927792966365814\n",
      "Step 8  Loss: 0.3102031946182251\n",
      "Step 9  Loss: 0.4776866137981415\n",
      "Step 10  Loss: 0.48112931847572327\n",
      "total Loss of epoch  168  is  4.056367784738541\n",
      "Step 0  Loss: 0.2892545163631439\n",
      "Step 1  Loss: 0.46970492601394653\n",
      "Step 2  Loss: 0.39762261509895325\n",
      "Step 3  Loss: 0.3747114837169647\n",
      "Step 4  Loss: 0.452094167470932\n",
      "Step 5  Loss: 0.3075858950614929\n",
      "Step 6  Loss: 0.42914751172065735\n",
      "Step 7  Loss: 0.4299648106098175\n",
      "Step 8  Loss: 0.39078718423843384\n",
      "Step 9  Loss: 0.3763084411621094\n",
      "Step 10  Loss: 0.4338208734989166\n",
      "total Loss of epoch  169  is  4.351002424955368\n",
      "Step 0  Loss: 0.3166690468788147\n",
      "Step 1  Loss: 0.25032997131347656\n",
      "Step 2  Loss: 0.3332158327102661\n",
      "Step 3  Loss: 0.3053521513938904\n",
      "Step 4  Loss: 0.41997769474983215\n",
      "Step 5  Loss: 0.37500742077827454\n",
      "Step 6  Loss: 0.3707934617996216\n",
      "Step 7  Loss: 0.49781057238578796\n",
      "Step 8  Loss: 0.32785889506340027\n",
      "Step 9  Loss: 0.42275264859199524\n",
      "Step 10  Loss: 0.3602094054222107\n",
      "total Loss of epoch  170  is  3.97997710108757\n",
      "Step 0  Loss: 0.2590087354183197\n",
      "Step 1  Loss: 0.47316691279411316\n",
      "Step 2  Loss: 0.41457441449165344\n",
      "Step 3  Loss: 0.4503123462200165\n",
      "Step 4  Loss: 0.40476900339126587\n",
      "Step 5  Loss: 0.5326163172721863\n",
      "Step 6  Loss: 0.41255566477775574\n",
      "Step 7  Loss: 0.41029107570648193\n",
      "Step 8  Loss: 0.5003713965415955\n",
      "Step 9  Loss: 0.25095435976982117\n",
      "Step 10  Loss: 0.4250483810901642\n",
      "total Loss of epoch  171  is  4.533668607473373\n",
      "Step 0  Loss: 0.2912815809249878\n",
      "Step 1  Loss: 0.3088577091693878\n",
      "Step 2  Loss: 0.35788193345069885\n",
      "Step 3  Loss: 0.5020204782485962\n",
      "Step 4  Loss: 0.44910699129104614\n",
      "Step 5  Loss: 0.4314444959163666\n",
      "Step 6  Loss: 0.36332786083221436\n",
      "Step 7  Loss: 0.37935692071914673\n",
      "Step 8  Loss: 0.44712623953819275\n",
      "Step 9  Loss: 0.48803094029426575\n",
      "Step 10  Loss: 0.41634783148765564\n",
      "total Loss of epoch  172  is  4.434782981872559\n",
      "Step 0  Loss: 0.3594707250595093\n",
      "Step 1  Loss: 0.4559953212738037\n",
      "Step 2  Loss: 0.3354906737804413\n",
      "Step 3  Loss: 0.46222740411758423\n",
      "Step 4  Loss: 0.32369720935821533\n",
      "Step 5  Loss: 0.4651912450790405\n",
      "Step 6  Loss: 0.29186224937438965\n",
      "Step 7  Loss: 0.37608975172042847\n",
      "Step 8  Loss: 0.4268869161605835\n",
      "Step 9  Loss: 0.35088834166526794\n",
      "Step 10  Loss: 0.2682994306087494\n",
      "total Loss of epoch  173  is  4.116099268198013\n",
      "Step 0  Loss: 0.41825711727142334\n",
      "Step 1  Loss: 0.1708722710609436\n",
      "Step 2  Loss: 0.32294684648513794\n",
      "Step 3  Loss: 0.4060690104961395\n",
      "Step 4  Loss: 0.3858742117881775\n",
      "Step 5  Loss: 0.377462238073349\n",
      "Step 6  Loss: 0.3036378026008606\n",
      "Step 7  Loss: 0.29183945059776306\n",
      "Step 8  Loss: 0.3331134021282196\n",
      "Step 9  Loss: 0.39181050658226013\n",
      "Step 10  Loss: 0.33827048540115356\n",
      "total Loss of epoch  174  is  3.740153342485428\n",
      "Step 0  Loss: 0.44977250695228577\n",
      "Step 1  Loss: 0.38649365305900574\n",
      "Step 2  Loss: 0.27801090478897095\n",
      "Step 3  Loss: 0.3311771750450134\n",
      "Step 4  Loss: 0.41359952092170715\n",
      "Step 5  Loss: 0.37444841861724854\n",
      "Step 6  Loss: 0.32958948612213135\n",
      "Step 7  Loss: 0.45190560817718506\n",
      "Step 8  Loss: 0.32656872272491455\n",
      "Step 9  Loss: 0.3764552175998688\n",
      "Step 10  Loss: 0.42699941992759705\n",
      "total Loss of epoch  175  is  4.145020633935928\n",
      "Step 0  Loss: 0.36226800084114075\n",
      "Step 1  Loss: 0.42609041929244995\n",
      "Step 2  Loss: 0.3637683689594269\n",
      "Step 3  Loss: 0.44080695509910583\n",
      "Step 4  Loss: 0.3397115468978882\n",
      "Step 5  Loss: 0.5046714544296265\n",
      "Step 6  Loss: 0.3749793469905853\n",
      "Step 7  Loss: 0.42067810893058777\n",
      "Step 8  Loss: 0.3535080552101135\n",
      "Step 9  Loss: 0.34219810366630554\n",
      "Step 10  Loss: 0.4688844382762909\n",
      "total Loss of epoch  176  is  4.397564798593521\n",
      "Step 0  Loss: 0.3844204545021057\n",
      "Step 1  Loss: 0.41538044810295105\n",
      "Step 2  Loss: 0.3261334002017975\n",
      "Step 3  Loss: 0.28766000270843506\n",
      "Step 4  Loss: 0.40444257855415344\n",
      "Step 5  Loss: 0.3490806818008423\n",
      "Step 6  Loss: 0.4276346266269684\n",
      "Step 7  Loss: 0.3885915279388428\n",
      "Step 8  Loss: 0.42517054080963135\n",
      "Step 9  Loss: 0.43021148443222046\n",
      "Step 10  Loss: 0.2857562303543091\n",
      "total Loss of epoch  177  is  4.124481976032257\n",
      "Step 0  Loss: 0.4421823024749756\n",
      "Step 1  Loss: 0.4609610140323639\n",
      "Step 2  Loss: 0.3698141872882843\n",
      "Step 3  Loss: 0.3905586898326874\n",
      "Step 4  Loss: 0.405892014503479\n",
      "Step 5  Loss: 0.3851144313812256\n",
      "Step 6  Loss: 0.35341572761535645\n",
      "Step 7  Loss: 0.29814571142196655\n",
      "Step 8  Loss: 0.4791564643383026\n",
      "Step 9  Loss: 0.34824615716934204\n",
      "Step 10  Loss: 0.4022625982761383\n",
      "total Loss of epoch  178  is  4.335749298334122\n",
      "Step 0  Loss: 0.3788183331489563\n",
      "Step 1  Loss: 0.36635822057724\n",
      "Step 2  Loss: 0.36712968349456787\n",
      "Step 3  Loss: 0.3737596571445465\n",
      "Step 4  Loss: 0.24634599685668945\n",
      "Step 5  Loss: 0.3019697070121765\n",
      "Step 6  Loss: 0.3155871331691742\n",
      "Step 7  Loss: 0.41203397512435913\n",
      "Step 8  Loss: 0.35863739252090454\n",
      "Step 9  Loss: 0.4572981894016266\n",
      "Step 10  Loss: 0.49481141567230225\n",
      "total Loss of epoch  179  is  4.072749704122543\n",
      "Step 0  Loss: 0.40488582849502563\n",
      "Step 1  Loss: 0.43634337186813354\n",
      "Step 2  Loss: 0.3235740065574646\n",
      "Step 3  Loss: 0.37401866912841797\n",
      "Step 4  Loss: 0.4438386857509613\n",
      "Step 5  Loss: 0.4317219853401184\n",
      "Step 6  Loss: 0.48792901635169983\n",
      "Step 7  Loss: 0.36289170384407043\n",
      "Step 8  Loss: 0.318194717168808\n",
      "Step 9  Loss: 0.3324432969093323\n",
      "Step 10  Loss: 0.30344682931900024\n",
      "total Loss of epoch  180  is  4.219288110733032\n",
      "Step 0  Loss: 0.4367983639240265\n",
      "Step 1  Loss: 0.4033282399177551\n",
      "Step 2  Loss: 0.2948971390724182\n",
      "Step 3  Loss: 0.35572898387908936\n",
      "Step 4  Loss: 0.28623995184898376\n",
      "Step 5  Loss: 0.31376180052757263\n",
      "Step 6  Loss: 0.39495712518692017\n",
      "Step 7  Loss: 0.36277633905410767\n",
      "Step 8  Loss: 0.3561772108078003\n",
      "Step 9  Loss: 0.43559086322784424\n",
      "Step 10  Loss: 0.3988818824291229\n",
      "total Loss of epoch  181  is  4.039137899875641\n",
      "Step 0  Loss: 0.3603478968143463\n",
      "Step 1  Loss: 0.37240898609161377\n",
      "Step 2  Loss: 0.3353922963142395\n",
      "Step 3  Loss: 0.44810518622398376\n",
      "Step 4  Loss: 0.3684912919998169\n",
      "Step 5  Loss: 0.400347501039505\n",
      "Step 6  Loss: 0.40676257014274597\n",
      "Step 7  Loss: 0.39802590012550354\n",
      "Step 8  Loss: 0.4920823574066162\n",
      "Step 9  Loss: 0.40468862652778625\n",
      "Step 10  Loss: 0.3578709065914154\n",
      "total Loss of epoch  182  is  4.344523519277573\n",
      "Step 0  Loss: 0.36536023020744324\n",
      "Step 1  Loss: 0.33122822642326355\n",
      "Step 2  Loss: 0.48060840368270874\n",
      "Step 3  Loss: 0.39372795820236206\n",
      "Step 4  Loss: 0.3266719579696655\n",
      "Step 5  Loss: 0.4200921952724457\n",
      "Step 6  Loss: 0.3112744688987732\n",
      "Step 7  Loss: 0.4304104447364807\n",
      "Step 8  Loss: 0.3379911184310913\n",
      "Step 9  Loss: 0.5077811479568481\n",
      "Step 10  Loss: 0.36550143361091614\n",
      "total Loss of epoch  183  is  4.270647585391998\n",
      "Step 0  Loss: 0.3513481020927429\n",
      "Step 1  Loss: 0.43896257877349854\n",
      "Step 2  Loss: 0.26387569308280945\n",
      "Step 3  Loss: 0.3188823461532593\n",
      "Step 4  Loss: 0.4790838062763214\n",
      "Step 5  Loss: 0.292776882648468\n",
      "Step 6  Loss: 0.319396048784256\n",
      "Step 7  Loss: 0.3143708109855652\n",
      "Step 8  Loss: 0.35710594058036804\n",
      "Step 9  Loss: 0.40255123376846313\n",
      "Step 10  Loss: 0.34617704153060913\n",
      "total Loss of epoch  184  is  3.884530484676361\n",
      "Step 0  Loss: 0.374545156955719\n",
      "Step 1  Loss: 0.32890796661376953\n",
      "Step 2  Loss: 0.5076766014099121\n",
      "Step 3  Loss: 0.4333724081516266\n",
      "Step 4  Loss: 0.2804768681526184\n",
      "Step 5  Loss: 0.41219907999038696\n",
      "Step 6  Loss: 0.3650359809398651\n",
      "Step 7  Loss: 0.37498152256011963\n",
      "Step 8  Loss: 0.4728122651576996\n",
      "Step 9  Loss: 0.3369893431663513\n",
      "Step 10  Loss: 0.4611165523529053\n",
      "total Loss of epoch  185  is  4.3481137454509735\n",
      "Step 0  Loss: 0.490103542804718\n",
      "Step 1  Loss: 0.4441770613193512\n",
      "Step 2  Loss: 0.5576052665710449\n",
      "Step 3  Loss: 0.48514774441719055\n",
      "Step 4  Loss: 0.4131496548652649\n",
      "Step 5  Loss: 0.4956863224506378\n",
      "Step 6  Loss: 0.33706197142601013\n",
      "Step 7  Loss: 0.44802558422088623\n",
      "Step 8  Loss: 0.4675755500793457\n",
      "Step 9  Loss: 0.4463796019554138\n",
      "Step 10  Loss: 0.3540978729724884\n",
      "total Loss of epoch  186  is  4.939010173082352\n",
      "Step 0  Loss: 0.4257369339466095\n",
      "Step 1  Loss: 0.36793389916419983\n",
      "Step 2  Loss: 0.4042370319366455\n",
      "Step 3  Loss: 0.33232349157333374\n",
      "Step 4  Loss: 0.3676910400390625\n",
      "Step 5  Loss: 0.3720385730266571\n",
      "Step 6  Loss: 0.3893476128578186\n",
      "Step 7  Loss: 0.3546803593635559\n",
      "Step 8  Loss: 0.3961784243583679\n",
      "Step 9  Loss: 0.4544772803783417\n",
      "Step 10  Loss: 0.32400959730148315\n",
      "total Loss of epoch  187  is  4.188654243946075\n",
      "Step 0  Loss: 0.43577438592910767\n",
      "Step 1  Loss: 0.3286401331424713\n",
      "Step 2  Loss: 0.32514670491218567\n",
      "Step 3  Loss: 0.39639100432395935\n",
      "Step 4  Loss: 0.3794637620449066\n",
      "Step 5  Loss: 0.3826184868812561\n",
      "Step 6  Loss: 0.47765305638313293\n",
      "Step 7  Loss: 0.3918169438838959\n",
      "Step 8  Loss: 0.4684631824493408\n",
      "Step 9  Loss: 0.3107425570487976\n",
      "Step 10  Loss: 0.3863215148448944\n",
      "total Loss of epoch  188  is  4.283031731843948\n",
      "Step 0  Loss: 0.3924585282802582\n",
      "Step 1  Loss: 0.3723439574241638\n",
      "Step 2  Loss: 0.35460010170936584\n",
      "Step 3  Loss: 0.5115698575973511\n",
      "Step 4  Loss: 0.37588414549827576\n",
      "Step 5  Loss: 0.3704228699207306\n",
      "Step 6  Loss: 0.33680257201194763\n",
      "Step 7  Loss: 0.35515275597572327\n",
      "Step 8  Loss: 0.4298967719078064\n",
      "Step 9  Loss: 0.3383443355560303\n",
      "Step 10  Loss: 0.3789002597332001\n",
      "total Loss of epoch  189  is  4.216376155614853\n",
      "Step 0  Loss: 0.34355413913726807\n",
      "Step 1  Loss: 0.341590017080307\n",
      "Step 2  Loss: 0.3117290735244751\n",
      "Step 3  Loss: 0.35304781794548035\n",
      "Step 4  Loss: 0.4502386152744293\n",
      "Step 5  Loss: 0.4571685791015625\n",
      "Step 6  Loss: 0.35913771390914917\n",
      "Step 7  Loss: 0.3304761052131653\n",
      "Step 8  Loss: 0.34481075406074524\n",
      "Step 9  Loss: 0.4174068570137024\n",
      "Step 10  Loss: 0.4419260621070862\n",
      "total Loss of epoch  190  is  4.151085734367371\n",
      "Step 0  Loss: 0.24676495790481567\n",
      "Step 1  Loss: 0.3844393193721771\n",
      "Step 2  Loss: 0.4367600679397583\n",
      "Step 3  Loss: 0.38586029410362244\n",
      "Step 4  Loss: 0.39130377769470215\n",
      "Step 5  Loss: 0.38601669669151306\n",
      "Step 6  Loss: 0.4776577353477478\n",
      "Step 7  Loss: 0.4479057192802429\n",
      "Step 8  Loss: 0.43053507804870605\n",
      "Step 9  Loss: 0.37446343898773193\n",
      "Step 10  Loss: 0.3239913284778595\n",
      "total Loss of epoch  191  is  4.285698413848877\n",
      "Step 0  Loss: 0.32347458600997925\n",
      "Step 1  Loss: 0.3274105489253998\n",
      "Step 2  Loss: 0.382623553276062\n",
      "Step 3  Loss: 0.24035830795764923\n",
      "Step 4  Loss: 0.26084190607070923\n",
      "Step 5  Loss: 0.2880101799964905\n",
      "Step 6  Loss: 0.3413868546485901\n",
      "Step 7  Loss: 0.4486892521381378\n",
      "Step 8  Loss: 0.4762699007987976\n",
      "Step 9  Loss: 0.3383423089981079\n",
      "Step 10  Loss: 0.361349493265152\n",
      "total Loss of epoch  192  is  3.7887568920850754\n",
      "Step 0  Loss: 0.4194352924823761\n",
      "Step 1  Loss: 0.3483651280403137\n",
      "Step 2  Loss: 0.38968178629875183\n",
      "Step 3  Loss: 0.38014042377471924\n",
      "Step 4  Loss: 0.4748428165912628\n",
      "Step 5  Loss: 0.45425570011138916\n",
      "Step 6  Loss: 0.3671662211418152\n",
      "Step 7  Loss: 0.3827231228351593\n",
      "Step 8  Loss: 0.35839584469795227\n",
      "Step 9  Loss: 0.46556606888771057\n",
      "Step 10  Loss: 0.33303532004356384\n",
      "total Loss of epoch  193  is  4.373607724905014\n",
      "Step 0  Loss: 0.4320451319217682\n",
      "Step 1  Loss: 0.3691118657588959\n",
      "Step 2  Loss: 0.372854083776474\n",
      "Step 3  Loss: 0.46881476044654846\n",
      "Step 4  Loss: 0.3758714497089386\n",
      "Step 5  Loss: 0.42513307929039\n",
      "Step 6  Loss: 0.4190402328968048\n",
      "Step 7  Loss: 0.31424668431282043\n",
      "Step 8  Loss: 0.3518262803554535\n",
      "Step 9  Loss: 0.3770853281021118\n",
      "Step 10  Loss: 0.25617456436157227\n",
      "total Loss of epoch  194  is  4.162203460931778\n",
      "Step 0  Loss: 0.27761775255203247\n",
      "Step 1  Loss: 0.39676904678344727\n",
      "Step 2  Loss: 0.4310903549194336\n",
      "Step 3  Loss: 0.4696671962738037\n",
      "Step 4  Loss: 0.38583678007125854\n",
      "Step 5  Loss: 0.35555604100227356\n",
      "Step 6  Loss: 0.4235205054283142\n",
      "Step 7  Loss: 0.4644293487071991\n",
      "Step 8  Loss: 0.3967626094818115\n",
      "Step 9  Loss: 0.29736000299453735\n",
      "Step 10  Loss: 0.505704402923584\n",
      "total Loss of epoch  195  is  4.404314041137695\n",
      "Step 0  Loss: 0.43463125824928284\n",
      "Step 1  Loss: 0.42288684844970703\n",
      "Step 2  Loss: 0.39514148235321045\n",
      "Step 3  Loss: 0.4134710133075714\n",
      "Step 4  Loss: 0.227512389421463\n",
      "Step 5  Loss: 0.33621689677238464\n",
      "Step 6  Loss: 0.32857972383499146\n",
      "Step 7  Loss: 0.3368554711341858\n",
      "Step 8  Loss: 0.2854840159416199\n",
      "Step 9  Loss: 0.41443273425102234\n",
      "Step 10  Loss: 0.30123141407966614\n",
      "total Loss of epoch  196  is  3.896443247795105\n",
      "Step 0  Loss: 0.37442710995674133\n",
      "Step 1  Loss: 0.28545308113098145\n",
      "Step 2  Loss: 0.32675445079803467\n",
      "Step 3  Loss: 0.4278384745121002\n",
      "Step 4  Loss: 0.30687060952186584\n",
      "Step 5  Loss: 0.3560739755630493\n",
      "Step 6  Loss: 0.44973981380462646\n",
      "Step 7  Loss: 0.4199199676513672\n",
      "Step 8  Loss: 0.49783816933631897\n",
      "Step 9  Loss: 0.4118953347206116\n",
      "Step 10  Loss: 0.4209703207015991\n",
      "total Loss of epoch  197  is  4.277781307697296\n",
      "Step 0  Loss: 0.37763890624046326\n",
      "Step 1  Loss: 0.3929588198661804\n",
      "Step 2  Loss: 0.31875115633010864\n",
      "Step 3  Loss: 0.26656821370124817\n",
      "Step 4  Loss: 0.3039975166320801\n",
      "Step 5  Loss: 0.5060376524925232\n",
      "Step 6  Loss: 0.43190112709999084\n",
      "Step 7  Loss: 0.4100847542285919\n",
      "Step 8  Loss: 0.4014388620853424\n",
      "Step 9  Loss: 0.393402099609375\n",
      "Step 10  Loss: 0.3277233839035034\n",
      "total Loss of epoch  198  is  4.130502492189407\n",
      "Step 0  Loss: 0.5216487050056458\n",
      "Step 1  Loss: 0.5276578068733215\n",
      "Step 2  Loss: 0.4668229818344116\n",
      "Step 3  Loss: 0.31187817454338074\n",
      "Step 4  Loss: 0.5318366289138794\n",
      "Step 5  Loss: 0.4190278947353363\n",
      "Step 6  Loss: 0.42335501313209534\n",
      "Step 7  Loss: 0.4464063048362732\n",
      "Step 8  Loss: 0.3785034418106079\n",
      "Step 9  Loss: 0.2854365408420563\n",
      "Step 10  Loss: 0.4583625793457031\n",
      "total Loss of epoch  199  is  4.770936071872711\n",
      "Step 0  Loss: 0.38449254631996155\n",
      "Step 1  Loss: 0.31523409485816956\n",
      "Step 2  Loss: 0.34873461723327637\n",
      "Step 3  Loss: 0.27175381779670715\n",
      "Step 4  Loss: 0.34075695276260376\n",
      "Step 5  Loss: 0.43864649534225464\n",
      "Step 6  Loss: 0.404070109128952\n",
      "Step 7  Loss: 0.3950255215167999\n",
      "Step 8  Loss: 0.22061742842197418\n",
      "Step 9  Loss: 0.362824022769928\n",
      "Step 10  Loss: 0.3575427830219269\n",
      "total Loss of epoch  200  is  3.839698389172554\n",
      "Step 0  Loss: 0.3007284998893738\n",
      "Step 1  Loss: 0.4431522488594055\n",
      "Step 2  Loss: 0.46302300691604614\n",
      "Step 3  Loss: 0.4332749843597412\n",
      "Step 4  Loss: 0.42501625418663025\n",
      "Step 5  Loss: 0.3063487708568573\n",
      "Step 6  Loss: 0.3684837222099304\n",
      "Step 7  Loss: 0.3257571756839752\n",
      "Step 8  Loss: 0.2708340287208557\n",
      "Step 9  Loss: 0.2984931468963623\n",
      "Step 10  Loss: 0.2891008257865906\n",
      "total Loss of epoch  201  is  3.9242126643657684\n",
      "Step 0  Loss: 0.4637831151485443\n",
      "Step 1  Loss: 0.4268995225429535\n",
      "Step 2  Loss: 0.42807602882385254\n",
      "Step 3  Loss: 0.39331546425819397\n",
      "Step 4  Loss: 0.4834125339984894\n",
      "Step 5  Loss: 0.29552456736564636\n",
      "Step 6  Loss: 0.32358479499816895\n",
      "Step 7  Loss: 0.4430331289768219\n",
      "Step 8  Loss: 0.41080546379089355\n",
      "Step 9  Loss: 0.4399043023586273\n",
      "Step 10  Loss: 0.3352808952331543\n",
      "total Loss of epoch  202  is  4.443619817495346\n",
      "Step 0  Loss: 0.34767627716064453\n",
      "Step 1  Loss: 0.4631521999835968\n",
      "Step 2  Loss: 0.3397051990032196\n",
      "Step 3  Loss: 0.33926132321357727\n",
      "Step 4  Loss: 0.33641907572746277\n",
      "Step 5  Loss: 0.4303988814353943\n",
      "Step 6  Loss: 0.5423095226287842\n",
      "Step 7  Loss: 0.2832145094871521\n",
      "Step 8  Loss: 0.36916327476501465\n",
      "Step 9  Loss: 0.3984491229057312\n",
      "Step 10  Loss: 0.3633202314376831\n",
      "total Loss of epoch  203  is  4.2130696177482605\n",
      "Step 0  Loss: 0.37068331241607666\n",
      "Step 1  Loss: 0.3437846899032593\n",
      "Step 2  Loss: 0.3148723840713501\n",
      "Step 3  Loss: 0.23715859651565552\n",
      "Step 4  Loss: 0.3839188516139984\n",
      "Step 5  Loss: 0.42157015204429626\n",
      "Step 6  Loss: 0.3627757132053375\n",
      "Step 7  Loss: 0.22639447450637817\n",
      "Step 8  Loss: 0.2227838933467865\n",
      "Step 9  Loss: 0.36049044132232666\n",
      "Step 10  Loss: 0.28239938616752625\n",
      "total Loss of epoch  204  is  3.5268318951129913\n",
      "Step 0  Loss: 0.3496480882167816\n",
      "Step 1  Loss: 0.33281639218330383\n",
      "Step 2  Loss: 0.3098445534706116\n",
      "Step 3  Loss: 0.4751242697238922\n",
      "Step 4  Loss: 0.42914578318595886\n",
      "Step 5  Loss: 0.3467824459075928\n",
      "Step 6  Loss: 0.3826547861099243\n",
      "Step 7  Loss: 0.3494094908237457\n",
      "Step 8  Loss: 0.38350024819374084\n",
      "Step 9  Loss: 0.3452584147453308\n",
      "Step 10  Loss: 0.42675915360450745\n",
      "total Loss of epoch  205  is  4.13094362616539\n",
      "Step 0  Loss: 0.3617743253707886\n",
      "Step 1  Loss: 0.39158007502555847\n",
      "Step 2  Loss: 0.4586232304573059\n",
      "Step 3  Loss: 0.4525538980960846\n",
      "Step 4  Loss: 0.3662692606449127\n",
      "Step 5  Loss: 0.4602804481983185\n",
      "Step 6  Loss: 0.3716529607772827\n",
      "Step 7  Loss: 0.4647613763809204\n",
      "Step 8  Loss: 0.4183744192123413\n",
      "Step 9  Loss: 0.376630574464798\n",
      "Step 10  Loss: 0.46955835819244385\n",
      "total Loss of epoch  206  is  4.592058926820755\n",
      "Step 0  Loss: 0.2441195398569107\n",
      "Step 1  Loss: 0.3078235387802124\n",
      "Step 2  Loss: 0.29413682222366333\n",
      "Step 3  Loss: 0.34468239545822144\n",
      "Step 4  Loss: 0.35894790291786194\n",
      "Step 5  Loss: 0.3210757374763489\n",
      "Step 6  Loss: 0.30469465255737305\n",
      "Step 7  Loss: 0.4344436228275299\n",
      "Step 8  Loss: 0.4228980541229248\n",
      "Step 9  Loss: 0.36314570903778076\n",
      "Step 10  Loss: 0.46443307399749756\n",
      "total Loss of epoch  207  is  3.8604010492563248\n",
      "Step 0  Loss: 0.40899714827537537\n",
      "Step 1  Loss: 0.3076857626438141\n",
      "Step 2  Loss: 0.4867636263370514\n",
      "Step 3  Loss: 0.358237087726593\n",
      "Step 4  Loss: 0.3341839909553528\n",
      "Step 5  Loss: 0.40299922227859497\n",
      "Step 6  Loss: 0.43683794140815735\n",
      "Step 7  Loss: 0.319627046585083\n",
      "Step 8  Loss: 0.47567689418792725\n",
      "Step 9  Loss: 0.3248496651649475\n",
      "Step 10  Loss: 0.5358126163482666\n",
      "total Loss of epoch  208  is  4.391671001911163\n",
      "Step 0  Loss: 0.4516219198703766\n",
      "Step 1  Loss: 0.32628846168518066\n",
      "Step 2  Loss: 0.23320971429347992\n",
      "Step 3  Loss: 0.37374424934387207\n",
      "Step 4  Loss: 0.3374638855457306\n",
      "Step 5  Loss: 0.31507185101509094\n",
      "Step 6  Loss: 0.30858728289604187\n",
      "Step 7  Loss: 0.430713415145874\n",
      "Step 8  Loss: 0.29545512795448303\n",
      "Step 9  Loss: 0.24550123512744904\n",
      "Step 10  Loss: 0.5267304182052612\n",
      "total Loss of epoch  209  is  3.84438756108284\n",
      "Step 0  Loss: 0.34976059198379517\n",
      "Step 1  Loss: 0.36287569999694824\n",
      "Step 2  Loss: 0.3130069077014923\n",
      "Step 3  Loss: 0.4101985692977905\n",
      "Step 4  Loss: 0.27510517835617065\n",
      "Step 5  Loss: 0.4389921724796295\n",
      "Step 6  Loss: 0.3994138538837433\n",
      "Step 7  Loss: 0.3901607394218445\n",
      "Step 8  Loss: 0.40842920541763306\n",
      "Step 9  Loss: 0.3952912986278534\n",
      "Step 10  Loss: 0.23787707090377808\n",
      "total Loss of epoch  210  is  3.9811112880706787\n",
      "Step 0  Loss: 0.4304710030555725\n",
      "Step 1  Loss: 0.39916354417800903\n",
      "Step 2  Loss: 0.33138781785964966\n",
      "Step 3  Loss: 0.41705697774887085\n",
      "Step 4  Loss: 0.3403613567352295\n",
      "Step 5  Loss: 0.36200499534606934\n",
      "Step 6  Loss: 0.35672298073768616\n",
      "Step 7  Loss: 0.3346528708934784\n",
      "Step 8  Loss: 0.46885445713996887\n",
      "Step 9  Loss: 0.5039186477661133\n",
      "Step 10  Loss: 0.43817463517189026\n",
      "total Loss of epoch  211  is  4.382769286632538\n",
      "Step 0  Loss: 0.40195876359939575\n",
      "Step 1  Loss: 0.3039053678512573\n",
      "Step 2  Loss: 0.43125835061073303\n",
      "Step 3  Loss: 0.40577325224876404\n",
      "Step 4  Loss: 0.46202757954597473\n",
      "Step 5  Loss: 0.35330870747566223\n",
      "Step 6  Loss: 0.30296096205711365\n",
      "Step 7  Loss: 0.26280269026756287\n",
      "Step 8  Loss: 0.4112949073314667\n",
      "Step 9  Loss: 0.4842817187309265\n",
      "Step 10  Loss: 0.5123108625411987\n",
      "total Loss of epoch  212  is  4.3318831622600555\n",
      "Step 0  Loss: 0.38596341013908386\n",
      "Step 1  Loss: 0.3405977189540863\n",
      "Step 2  Loss: 0.36531221866607666\n",
      "Step 3  Loss: 0.38371437788009644\n",
      "Step 4  Loss: 0.46768179535865784\n",
      "Step 5  Loss: 0.3562082052230835\n",
      "Step 6  Loss: 0.3132411539554596\n",
      "Step 7  Loss: 0.4374920129776001\n",
      "Step 8  Loss: 0.43729129433631897\n",
      "Step 9  Loss: 0.26761913299560547\n",
      "Step 10  Loss: 0.3533320426940918\n",
      "total Loss of epoch  213  is  4.1084533631801605\n",
      "Step 0  Loss: 0.306854248046875\n",
      "Step 1  Loss: 0.3606370687484741\n",
      "Step 2  Loss: 0.4875199794769287\n",
      "Step 3  Loss: 0.42449751496315\n",
      "Step 4  Loss: 0.39860135316848755\n",
      "Step 5  Loss: 0.45428013801574707\n",
      "Step 6  Loss: 0.32239004969596863\n",
      "Step 7  Loss: 0.4159378111362457\n",
      "Step 8  Loss: 0.27790430188179016\n",
      "Step 9  Loss: 0.4071216583251953\n",
      "Step 10  Loss: 0.46834972500801086\n",
      "total Loss of epoch  214  is  4.324093848466873\n",
      "Step 0  Loss: 0.40581366419792175\n",
      "Step 1  Loss: 0.37413352727890015\n",
      "Step 2  Loss: 0.3336038887500763\n",
      "Step 3  Loss: 0.3241199851036072\n",
      "Step 4  Loss: 0.3537892997264862\n",
      "Step 5  Loss: 0.4685240089893341\n",
      "Step 6  Loss: 0.39561885595321655\n",
      "Step 7  Loss: 0.500058650970459\n",
      "Step 8  Loss: 0.4181106686592102\n",
      "Step 9  Loss: 0.32002881169319153\n",
      "Step 10  Loss: 0.43353164196014404\n",
      "total Loss of epoch  215  is  4.327333003282547\n",
      "Step 0  Loss: 0.4051242172718048\n",
      "Step 1  Loss: 0.3610932528972626\n",
      "Step 2  Loss: 0.2799686789512634\n",
      "Step 3  Loss: 0.33209607005119324\n",
      "Step 4  Loss: 0.23012256622314453\n",
      "Step 5  Loss: 0.3834085166454315\n",
      "Step 6  Loss: 0.3783407509326935\n",
      "Step 7  Loss: 0.3988988697528839\n",
      "Step 8  Loss: 0.3880712687969208\n",
      "Step 9  Loss: 0.4504012167453766\n",
      "Step 10  Loss: 0.3100096881389618\n",
      "total Loss of epoch  216  is  3.9175350964069366\n",
      "Step 0  Loss: 0.3422514498233795\n",
      "Step 1  Loss: 0.42095258831977844\n",
      "Step 2  Loss: 0.34435874223709106\n",
      "Step 3  Loss: 0.3696325123310089\n",
      "Step 4  Loss: 0.30156779289245605\n",
      "Step 5  Loss: 0.39490050077438354\n",
      "Step 6  Loss: 0.4149589538574219\n",
      "Step 7  Loss: 0.3870304226875305\n",
      "Step 8  Loss: 0.3003219962120056\n",
      "Step 9  Loss: 0.3879770040512085\n",
      "Step 10  Loss: 0.3740788698196411\n",
      "total Loss of epoch  217  is  4.038030833005905\n",
      "Step 0  Loss: 0.39255592226982117\n",
      "Step 1  Loss: 0.3098095655441284\n",
      "Step 2  Loss: 0.322980672121048\n",
      "Step 3  Loss: 0.3890533149242401\n",
      "Step 4  Loss: 0.3326375186443329\n",
      "Step 5  Loss: 0.4703643023967743\n",
      "Step 6  Loss: 0.30208176374435425\n",
      "Step 7  Loss: 0.3945668339729309\n",
      "Step 8  Loss: 0.4070685803890228\n",
      "Step 9  Loss: 0.3358420729637146\n",
      "Step 10  Loss: 0.4427674412727356\n",
      "total Loss of epoch  218  is  4.099727988243103\n",
      "Step 0  Loss: 0.3456833064556122\n",
      "Step 1  Loss: 0.49592870473861694\n",
      "Step 2  Loss: 0.4695129990577698\n",
      "Step 3  Loss: 0.3741576373577118\n",
      "Step 4  Loss: 0.4170417785644531\n",
      "Step 5  Loss: 0.18668696284294128\n",
      "Step 6  Loss: 0.48324987292289734\n",
      "Step 7  Loss: 0.5137014985084534\n",
      "Step 8  Loss: 0.3230341374874115\n",
      "Step 9  Loss: 0.3783446252346039\n",
      "Step 10  Loss: 0.5312064290046692\n",
      "total Loss of epoch  219  is  4.51854795217514\n",
      "Step 0  Loss: 0.46803954243659973\n",
      "Step 1  Loss: 0.332712322473526\n",
      "Step 2  Loss: 0.41402536630630493\n",
      "Step 3  Loss: 0.4056943356990814\n",
      "Step 4  Loss: 0.5000637173652649\n",
      "Step 5  Loss: 0.38960880041122437\n",
      "Step 6  Loss: 0.347167044878006\n",
      "Step 7  Loss: 0.38350561261177063\n",
      "Step 8  Loss: 0.32761046290397644\n",
      "Step 9  Loss: 0.3443770110607147\n",
      "Step 10  Loss: 0.4214223325252533\n",
      "total Loss of epoch  220  is  4.334226548671722\n",
      "Step 0  Loss: 0.44784650206565857\n",
      "Step 1  Loss: 0.3432409465312958\n",
      "Step 2  Loss: 0.4188125729560852\n",
      "Step 3  Loss: 0.3970922529697418\n",
      "Step 4  Loss: 0.3534202575683594\n",
      "Step 5  Loss: 0.46534812450408936\n",
      "Step 6  Loss: 0.2784021198749542\n",
      "Step 7  Loss: 0.3522113263607025\n",
      "Step 8  Loss: 0.35555770993232727\n",
      "Step 9  Loss: 0.3542538285255432\n",
      "Step 10  Loss: 0.21413877606391907\n",
      "total Loss of epoch  221  is  3.9803244173526764\n",
      "Step 0  Loss: 0.3151087462902069\n",
      "Step 1  Loss: 0.4374048411846161\n",
      "Step 2  Loss: 0.3841443359851837\n",
      "Step 3  Loss: 0.4431939721107483\n",
      "Step 4  Loss: 0.36932215094566345\n",
      "Step 5  Loss: 0.38209688663482666\n",
      "Step 6  Loss: 0.3688328266143799\n",
      "Step 7  Loss: 0.3657783269882202\n",
      "Step 8  Loss: 0.3791508078575134\n",
      "Step 9  Loss: 0.40184324979782104\n",
      "Step 10  Loss: 0.44071298837661743\n",
      "total Loss of epoch  222  is  4.287589132785797\n",
      "Step 0  Loss: 0.45370686054229736\n",
      "Step 1  Loss: 0.3027172386646271\n",
      "Step 2  Loss: 0.3733571469783783\n",
      "Step 3  Loss: 0.4116581678390503\n",
      "Step 4  Loss: 0.4109010100364685\n",
      "Step 5  Loss: 0.3665004074573517\n",
      "Step 6  Loss: 0.3817293047904968\n",
      "Step 7  Loss: 0.39499396085739136\n",
      "Step 8  Loss: 0.3656654953956604\n",
      "Step 9  Loss: 0.3237821161746979\n",
      "Step 10  Loss: 0.3604578971862793\n",
      "total Loss of epoch  223  is  4.145469605922699\n",
      "Step 0  Loss: 0.4190303385257721\n",
      "Step 1  Loss: 0.38930657505989075\n",
      "Step 2  Loss: 0.42760515213012695\n",
      "Step 3  Loss: 0.4512638449668884\n",
      "Step 4  Loss: 0.22807015478610992\n",
      "Step 5  Loss: 0.3458372950553894\n",
      "Step 6  Loss: 0.3612433969974518\n",
      "Step 7  Loss: 0.31262850761413574\n",
      "Step 8  Loss: 0.33790135383605957\n",
      "Step 9  Loss: 0.3364331126213074\n",
      "Step 10  Loss: 0.236394464969635\n",
      "total Loss of epoch  224  is  3.845714196562767\n",
      "Step 0  Loss: 0.34543001651763916\n",
      "Step 1  Loss: 0.2609986364841461\n",
      "Step 2  Loss: 0.45584219694137573\n",
      "Step 3  Loss: 0.36192870140075684\n",
      "Step 4  Loss: 0.4032733142375946\n",
      "Step 5  Loss: 0.39578545093536377\n",
      "Step 6  Loss: 0.4696079194545746\n",
      "Step 7  Loss: 0.4342445731163025\n",
      "Step 8  Loss: 0.33627381920814514\n",
      "Step 9  Loss: 0.3784288167953491\n",
      "Step 10  Loss: 0.36417633295059204\n",
      "total Loss of epoch  225  is  4.20598977804184\n",
      "Step 0  Loss: 0.4398101270198822\n",
      "Step 1  Loss: 0.37875381112098694\n",
      "Step 2  Loss: 0.28836789727211\n",
      "Step 3  Loss: 0.5230490565299988\n",
      "Step 4  Loss: 0.3693038523197174\n",
      "Step 5  Loss: 0.36815670132637024\n",
      "Step 6  Loss: 0.3892397880554199\n",
      "Step 7  Loss: 0.23911891877651215\n",
      "Step 8  Loss: 0.391580730676651\n",
      "Step 9  Loss: 0.3330761790275574\n",
      "Step 10  Loss: 0.43641144037246704\n",
      "total Loss of epoch  226  is  4.156868502497673\n",
      "Step 0  Loss: 0.5000646114349365\n",
      "Step 1  Loss: 0.34039050340652466\n",
      "Step 2  Loss: 0.32724711298942566\n",
      "Step 3  Loss: 0.3407236337661743\n",
      "Step 4  Loss: 0.36718878149986267\n",
      "Step 5  Loss: 0.20323550701141357\n",
      "Step 6  Loss: 0.3090980648994446\n",
      "Step 7  Loss: 0.4247623682022095\n",
      "Step 8  Loss: 0.3548821806907654\n",
      "Step 9  Loss: 0.32545751333236694\n",
      "Step 10  Loss: 0.3403759300708771\n",
      "total Loss of epoch  227  is  3.833426207304001\n",
      "Step 0  Loss: 0.3858306109905243\n",
      "Step 1  Loss: 0.39510953426361084\n",
      "Step 2  Loss: 0.4254838228225708\n",
      "Step 3  Loss: 0.3881416916847229\n",
      "Step 4  Loss: 0.3805127441883087\n",
      "Step 5  Loss: 0.3201497793197632\n",
      "Step 6  Loss: 0.4111159145832062\n",
      "Step 7  Loss: 0.430446594953537\n",
      "Step 8  Loss: 0.43262606859207153\n",
      "Step 9  Loss: 0.37802061438560486\n",
      "Step 10  Loss: 0.33207306265830994\n",
      "total Loss of epoch  228  is  4.27951043844223\n",
      "Step 0  Loss: 0.36282113194465637\n",
      "Step 1  Loss: 0.38487207889556885\n",
      "Step 2  Loss: 0.35922911763191223\n",
      "Step 3  Loss: 0.3156594932079315\n",
      "Step 4  Loss: 0.29565563797950745\n",
      "Step 5  Loss: 0.3876522481441498\n",
      "Step 6  Loss: 0.43832358717918396\n",
      "Step 7  Loss: 0.41454604268074036\n",
      "Step 8  Loss: 0.3809392750263214\n",
      "Step 9  Loss: 0.33755019307136536\n",
      "Step 10  Loss: 0.47852057218551636\n",
      "total Loss of epoch  229  is  4.155769377946854\n",
      "Step 0  Loss: 0.3985194265842438\n",
      "Step 1  Loss: 0.40320226550102234\n",
      "Step 2  Loss: 0.31064850091934204\n",
      "Step 3  Loss: 0.3841318190097809\n",
      "Step 4  Loss: 0.3758438527584076\n",
      "Step 5  Loss: 0.3152829706668854\n",
      "Step 6  Loss: 0.349458783864975\n",
      "Step 7  Loss: 0.4370429217815399\n",
      "Step 8  Loss: 0.4646936058998108\n",
      "Step 9  Loss: 0.3378854990005493\n",
      "Step 10  Loss: 0.37001562118530273\n",
      "total Loss of epoch  230  is  4.14672526717186\n",
      "Step 0  Loss: 0.39540573954582214\n",
      "Step 1  Loss: 0.42557233572006226\n",
      "Step 2  Loss: 0.33649444580078125\n",
      "Step 3  Loss: 0.30153775215148926\n",
      "Step 4  Loss: 0.4626340866088867\n",
      "Step 5  Loss: 0.40345486998558044\n",
      "Step 6  Loss: 0.4180730879306793\n",
      "Step 7  Loss: 0.31720972061157227\n",
      "Step 8  Loss: 0.4158722460269928\n",
      "Step 9  Loss: 0.2899353504180908\n",
      "Step 10  Loss: 0.5065310001373291\n",
      "total Loss of epoch  231  is  4.272720634937286\n",
      "Step 0  Loss: 0.3588309586048126\n",
      "Step 1  Loss: 0.3991606831550598\n",
      "Step 2  Loss: 0.5107706189155579\n",
      "Step 3  Loss: 0.3707060217857361\n",
      "Step 4  Loss: 0.31482645869255066\n",
      "Step 5  Loss: 0.3363592028617859\n",
      "Step 6  Loss: 0.37753021717071533\n",
      "Step 7  Loss: 0.39671826362609863\n",
      "Step 8  Loss: 0.2755134403705597\n",
      "Step 9  Loss: 0.36621689796447754\n",
      "Step 10  Loss: 0.41207951307296753\n",
      "total Loss of epoch  232  is  4.118712276220322\n",
      "Step 0  Loss: 0.3794838786125183\n",
      "Step 1  Loss: 0.28610703349113464\n",
      "Step 2  Loss: 0.3250485956668854\n",
      "Step 3  Loss: 0.410462349653244\n",
      "Step 4  Loss: 0.2957117259502411\n",
      "Step 5  Loss: 0.3974398076534271\n",
      "Step 6  Loss: 0.37814265489578247\n",
      "Step 7  Loss: 0.40938451886177063\n",
      "Step 8  Loss: 0.426769495010376\n",
      "Step 9  Loss: 0.30296608805656433\n",
      "Step 10  Loss: 0.5688033699989319\n",
      "total Loss of epoch  233  is  4.180319517850876\n",
      "Step 0  Loss: 0.4046984314918518\n",
      "Step 1  Loss: 0.4262346923351288\n",
      "Step 2  Loss: 0.4612331986427307\n",
      "Step 3  Loss: 0.39063990116119385\n",
      "Step 4  Loss: 0.3125635087490082\n",
      "Step 5  Loss: 0.4203243553638458\n",
      "Step 6  Loss: 0.4513969123363495\n",
      "Step 7  Loss: 0.30587533116340637\n",
      "Step 8  Loss: 0.45310571789741516\n",
      "Step 9  Loss: 0.5725294351577759\n",
      "Step 10  Loss: 0.179447203874588\n",
      "total Loss of epoch  234  is  4.378048688173294\n",
      "Step 0  Loss: 0.39050084352493286\n",
      "Step 1  Loss: 0.4156041741371155\n",
      "Step 2  Loss: 0.41048333048820496\n",
      "Step 3  Loss: 0.3919793963432312\n",
      "Step 4  Loss: 0.16854076087474823\n",
      "Step 5  Loss: 0.376359224319458\n",
      "Step 6  Loss: 0.39482247829437256\n",
      "Step 7  Loss: 0.4593920409679413\n",
      "Step 8  Loss: 0.36011382937431335\n",
      "Step 9  Loss: 0.3553331196308136\n",
      "Step 10  Loss: 0.3210306167602539\n",
      "total Loss of epoch  235  is  4.044159814715385\n",
      "Step 0  Loss: 0.3759387135505676\n",
      "Step 1  Loss: 0.2747441232204437\n",
      "Step 2  Loss: 0.45235010981559753\n",
      "Step 3  Loss: 0.422823965549469\n",
      "Step 4  Loss: 0.2469182163476944\n",
      "Step 5  Loss: 0.2781994044780731\n",
      "Step 6  Loss: 0.3748210072517395\n",
      "Step 7  Loss: 0.2749667465686798\n",
      "Step 8  Loss: 0.3743840754032135\n",
      "Step 9  Loss: 0.28948506712913513\n",
      "Step 10  Loss: 0.3767114579677582\n",
      "total Loss of epoch  236  is  3.7413428872823715\n",
      "Step 0  Loss: 0.34324750304222107\n",
      "Step 1  Loss: 0.3238992989063263\n",
      "Step 2  Loss: 0.4590737819671631\n",
      "Step 3  Loss: 0.439454048871994\n",
      "Step 4  Loss: 0.3978203535079956\n",
      "Step 5  Loss: 0.41429153084754944\n",
      "Step 6  Loss: 0.35364022850990295\n",
      "Step 7  Loss: 0.38873594999313354\n",
      "Step 8  Loss: 0.3544658124446869\n",
      "Step 9  Loss: 0.32848674058914185\n",
      "Step 10  Loss: 0.4068169891834259\n",
      "total Loss of epoch  237  is  4.209932237863541\n",
      "Step 0  Loss: 0.3862752318382263\n",
      "Step 1  Loss: 0.38462695479393005\n",
      "Step 2  Loss: 0.3079105615615845\n",
      "Step 3  Loss: 0.29274412989616394\n",
      "Step 4  Loss: 0.44211167097091675\n",
      "Step 5  Loss: 0.38296133279800415\n",
      "Step 6  Loss: 0.4776494801044464\n",
      "Step 7  Loss: 0.2973412275314331\n",
      "Step 8  Loss: 0.370928019285202\n",
      "Step 9  Loss: 0.49555960297584534\n",
      "Step 10  Loss: 0.350411593914032\n",
      "total Loss of epoch  238  is  4.1885198056697845\n",
      "Step 0  Loss: 0.33925360441207886\n",
      "Step 1  Loss: 0.34358441829681396\n",
      "Step 2  Loss: 0.326973021030426\n",
      "Step 3  Loss: 0.3034594655036926\n",
      "Step 4  Loss: 0.30771660804748535\n",
      "Step 5  Loss: 0.5012843012809753\n",
      "Step 6  Loss: 0.395459920167923\n",
      "Step 7  Loss: 0.4483799934387207\n",
      "Step 8  Loss: 0.4060124456882477\n",
      "Step 9  Loss: 0.42701682448387146\n",
      "Step 10  Loss: 0.40088993310928345\n",
      "total Loss of epoch  239  is  4.200030535459518\n",
      "Step 0  Loss: 0.4200096130371094\n",
      "Step 1  Loss: 0.3797503113746643\n",
      "Step 2  Loss: 0.3152335286140442\n",
      "Step 3  Loss: 0.3616812825202942\n",
      "Step 4  Loss: 0.2767782211303711\n",
      "Step 5  Loss: 0.455046683549881\n",
      "Step 6  Loss: 0.40799570083618164\n",
      "Step 7  Loss: 0.4016232490539551\n",
      "Step 8  Loss: 0.26894956827163696\n",
      "Step 9  Loss: 0.3249254524707794\n",
      "Step 10  Loss: 0.4677943289279938\n",
      "total Loss of epoch  240  is  4.079787939786911\n",
      "Step 0  Loss: 0.2778359353542328\n",
      "Step 1  Loss: 0.3501567840576172\n",
      "Step 2  Loss: 0.3973139524459839\n",
      "Step 3  Loss: 0.4436011016368866\n",
      "Step 4  Loss: 0.3835630714893341\n",
      "Step 5  Loss: 0.324713796377182\n",
      "Step 6  Loss: 0.4417358636856079\n",
      "Step 7  Loss: 0.33754467964172363\n",
      "Step 8  Loss: 0.3493780195713043\n",
      "Step 9  Loss: 0.37409281730651855\n",
      "Step 10  Loss: 0.2977653741836548\n",
      "total Loss of epoch  241  is  3.9777013957500458\n",
      "Step 0  Loss: 0.24632495641708374\n",
      "Step 1  Loss: 0.29072922468185425\n",
      "Step 2  Loss: 0.30276864767074585\n",
      "Step 3  Loss: 0.32980966567993164\n",
      "Step 4  Loss: 0.5497802495956421\n",
      "Step 5  Loss: 0.4012768864631653\n",
      "Step 6  Loss: 0.44726377725601196\n",
      "Step 7  Loss: 0.3428853750228882\n",
      "Step 8  Loss: 0.3499656021595001\n",
      "Step 9  Loss: 0.40908047556877136\n",
      "Step 10  Loss: 0.5918481945991516\n",
      "total Loss of epoch  242  is  4.261733055114746\n",
      "Step 0  Loss: 0.29224154353141785\n",
      "Step 1  Loss: 0.3207598030567169\n",
      "Step 2  Loss: 0.31187960505485535\n",
      "Step 3  Loss: 0.2907915413379669\n",
      "Step 4  Loss: 0.2866456210613251\n",
      "Step 5  Loss: 0.4244931638240814\n",
      "Step 6  Loss: 0.3996943533420563\n",
      "Step 7  Loss: 0.4069451689720154\n",
      "Step 8  Loss: 0.3922114074230194\n",
      "Step 9  Loss: 0.24101008474826813\n",
      "Step 10  Loss: 0.36787962913513184\n",
      "total Loss of epoch  243  is  3.7345519214868546\n",
      "Step 0  Loss: 0.39646872878074646\n",
      "Step 1  Loss: 0.41732165217399597\n",
      "Step 2  Loss: 0.30647656321525574\n",
      "Step 3  Loss: 0.4551105499267578\n",
      "Step 4  Loss: 0.35551193356513977\n",
      "Step 5  Loss: 0.34041425585746765\n",
      "Step 6  Loss: 0.5012619495391846\n",
      "Step 7  Loss: 0.4227844476699829\n",
      "Step 8  Loss: 0.2670234739780426\n",
      "Step 9  Loss: 0.4458419382572174\n",
      "Step 10  Loss: 0.33378204703330994\n",
      "total Loss of epoch  244  is  4.241997539997101\n",
      "Step 0  Loss: 0.3721209764480591\n",
      "Step 1  Loss: 0.42078834772109985\n",
      "Step 2  Loss: 0.3392612934112549\n",
      "Step 3  Loss: 0.3444878160953522\n",
      "Step 4  Loss: 0.32382774353027344\n",
      "Step 5  Loss: 0.2732865810394287\n",
      "Step 6  Loss: 0.4100952744483948\n",
      "Step 7  Loss: 0.39993810653686523\n",
      "Step 8  Loss: 0.4086097478866577\n",
      "Step 9  Loss: 0.41744574904441833\n",
      "Step 10  Loss: 0.29955634474754333\n",
      "total Loss of epoch  245  is  4.0094179809093475\n",
      "Step 0  Loss: 0.37006208300590515\n",
      "Step 1  Loss: 0.3283989727497101\n",
      "Step 2  Loss: 0.3484053313732147\n",
      "Step 3  Loss: 0.3884263038635254\n",
      "Step 4  Loss: 0.3133406341075897\n",
      "Step 5  Loss: 0.4201696217060089\n",
      "Step 6  Loss: 0.3065538704395294\n",
      "Step 7  Loss: 0.33523130416870117\n",
      "Step 8  Loss: 0.34228071570396423\n",
      "Step 9  Loss: 0.3483811318874359\n",
      "Step 10  Loss: 0.4603043794631958\n",
      "total Loss of epoch  246  is  3.9615543484687805\n",
      "Step 0  Loss: 0.3970218598842621\n",
      "Step 1  Loss: 0.40026405453681946\n",
      "Step 2  Loss: 0.3983248770236969\n",
      "Step 3  Loss: 0.3282744586467743\n",
      "Step 4  Loss: 0.34874677658081055\n",
      "Step 5  Loss: 0.28555622696876526\n",
      "Step 6  Loss: 0.34075236320495605\n",
      "Step 7  Loss: 0.3244099020957947\n",
      "Step 8  Loss: 0.37726280093193054\n",
      "Step 9  Loss: 0.3519652783870697\n",
      "Step 10  Loss: 0.45781752467155457\n",
      "total Loss of epoch  247  is  4.010396122932434\n",
      "Step 0  Loss: 0.3508441746234894\n",
      "Step 1  Loss: 0.3058922290802002\n",
      "Step 2  Loss: 0.4052618741989136\n",
      "Step 3  Loss: 0.34667742252349854\n",
      "Step 4  Loss: 0.34251710772514343\n",
      "Step 5  Loss: 0.40897101163864136\n",
      "Step 6  Loss: 0.42351388931274414\n",
      "Step 7  Loss: 0.3441885709762573\n",
      "Step 8  Loss: 0.4016297459602356\n",
      "Step 9  Loss: 0.4602086842060089\n",
      "Step 10  Loss: 0.28133949637413025\n",
      "total Loss of epoch  248  is  4.071044206619263\n",
      "Step 0  Loss: 0.2536707818508148\n",
      "Step 1  Loss: 0.3070198893547058\n",
      "Step 2  Loss: 0.3277587890625\n",
      "Step 3  Loss: 0.4060344696044922\n",
      "Step 4  Loss: 0.44346433877944946\n",
      "Step 5  Loss: 0.31622636318206787\n",
      "Step 6  Loss: 0.46610942482948303\n",
      "Step 7  Loss: 0.5099036693572998\n",
      "Step 8  Loss: 0.31779876351356506\n",
      "Step 9  Loss: 0.318448007106781\n",
      "Step 10  Loss: 0.17319358885288239\n",
      "total Loss of epoch  249  is  3.8396280854940414\n",
      "Step 0  Loss: 0.34204164147377014\n",
      "Step 1  Loss: 0.3346475064754486\n",
      "Step 2  Loss: 0.3217966854572296\n",
      "Step 3  Loss: 0.3266776502132416\n",
      "Step 4  Loss: 0.31273984909057617\n",
      "Step 5  Loss: 0.27977269887924194\n",
      "Step 6  Loss: 0.4584049582481384\n",
      "Step 7  Loss: 0.310316801071167\n",
      "Step 8  Loss: 0.390918493270874\n",
      "Step 9  Loss: 0.40221741795539856\n",
      "Step 10  Loss: 0.41295284032821655\n",
      "total Loss of epoch  250  is  3.8924865424633026\n",
      "Step 0  Loss: 0.29010024666786194\n",
      "Step 1  Loss: 0.33819714188575745\n",
      "Step 2  Loss: 0.4049759805202484\n",
      "Step 3  Loss: 0.35857558250427246\n",
      "Step 4  Loss: 0.3957659900188446\n",
      "Step 5  Loss: 0.3031117916107178\n",
      "Step 6  Loss: 0.49172231554985046\n",
      "Step 7  Loss: 0.3411518335342407\n",
      "Step 8  Loss: 0.39436542987823486\n",
      "Step 9  Loss: 0.45120054483413696\n",
      "Step 10  Loss: 0.290563702583313\n",
      "total Loss of epoch  251  is  4.059730559587479\n",
      "Step 0  Loss: 0.2982843220233917\n",
      "Step 1  Loss: 0.3304130434989929\n",
      "Step 2  Loss: 0.3748363256454468\n",
      "Step 3  Loss: 0.3473069667816162\n",
      "Step 4  Loss: 0.3717484474182129\n",
      "Step 5  Loss: 0.5490191578865051\n",
      "Step 6  Loss: 0.34168604016304016\n",
      "Step 7  Loss: 0.33220192790031433\n",
      "Step 8  Loss: 0.2791552245616913\n",
      "Step 9  Loss: 0.29802560806274414\n",
      "Step 10  Loss: 0.33939340710639954\n",
      "total Loss of epoch  252  is  3.862070471048355\n",
      "Step 0  Loss: 0.4561159014701843\n",
      "Step 1  Loss: 0.2746601700782776\n",
      "Step 2  Loss: 0.24013680219650269\n",
      "Step 3  Loss: 0.34550556540489197\n",
      "Step 4  Loss: 0.4318222999572754\n",
      "Step 5  Loss: 0.4160582721233368\n",
      "Step 6  Loss: 0.49915099143981934\n",
      "Step 7  Loss: 0.42559710144996643\n",
      "Step 8  Loss: 0.3322801887989044\n",
      "Step 9  Loss: 0.36859509348869324\n",
      "Step 10  Loss: 0.42233309149742126\n",
      "total Loss of epoch  253  is  4.212255477905273\n",
      "Step 0  Loss: 0.3241178095340729\n",
      "Step 1  Loss: 0.39270684123039246\n",
      "Step 2  Loss: 0.32407689094543457\n",
      "Step 3  Loss: 0.30381014943122864\n",
      "Step 4  Loss: 0.4266235828399658\n",
      "Step 5  Loss: 0.24767953157424927\n",
      "Step 6  Loss: 0.28303617238998413\n",
      "Step 7  Loss: 0.3373454809188843\n",
      "Step 8  Loss: 0.2794579565525055\n",
      "Step 9  Loss: 0.35086503624916077\n",
      "Step 10  Loss: 0.37807661294937134\n",
      "total Loss of epoch  254  is  3.6477960646152496\n",
      "Step 0  Loss: 0.28483620285987854\n",
      "Step 1  Loss: 0.423835813999176\n",
      "Step 2  Loss: 0.24297885596752167\n",
      "Step 3  Loss: 0.41449522972106934\n",
      "Step 4  Loss: 0.2975430190563202\n",
      "Step 5  Loss: 0.2662021219730377\n",
      "Step 6  Loss: 0.38009268045425415\n",
      "Step 7  Loss: 0.42737558484077454\n",
      "Step 8  Loss: 0.413108229637146\n",
      "Step 9  Loss: 0.3051660358905792\n",
      "Step 10  Loss: 0.19529494643211365\n",
      "total Loss of epoch  255  is  3.650928720831871\n",
      "Step 0  Loss: 0.32800012826919556\n",
      "Step 1  Loss: 0.376867413520813\n",
      "Step 2  Loss: 0.37639614939689636\n",
      "Step 3  Loss: 0.34057918190956116\n",
      "Step 4  Loss: 0.2776118218898773\n",
      "Step 5  Loss: 0.37638869881629944\n",
      "Step 6  Loss: 0.26439374685287476\n",
      "Step 7  Loss: 0.3362806439399719\n",
      "Step 8  Loss: 0.4043123722076416\n",
      "Step 9  Loss: 0.42609161138534546\n",
      "Step 10  Loss: 0.20596815645694733\n",
      "total Loss of epoch  256  is  3.712889924645424\n",
      "Step 0  Loss: 0.3344399333000183\n",
      "Step 1  Loss: 0.4438224136829376\n",
      "Step 2  Loss: 0.3884838819503784\n",
      "Step 3  Loss: 0.3108701705932617\n",
      "Step 4  Loss: 0.3561919629573822\n",
      "Step 5  Loss: 0.3528461754322052\n",
      "Step 6  Loss: 0.43181708455085754\n",
      "Step 7  Loss: 0.41730067133903503\n",
      "Step 8  Loss: 0.2951441705226898\n",
      "Step 9  Loss: 0.39429640769958496\n",
      "Step 10  Loss: 0.2983267605304718\n",
      "total Loss of epoch  257  is  4.023539632558823\n",
      "Step 0  Loss: 0.31260794401168823\n",
      "Step 1  Loss: 0.24828697741031647\n",
      "Step 2  Loss: 0.3332446813583374\n",
      "Step 3  Loss: 0.31687578558921814\n",
      "Step 4  Loss: 0.3288077414035797\n",
      "Step 5  Loss: 0.33742406964302063\n",
      "Step 6  Loss: 0.5091413855552673\n",
      "Step 7  Loss: 0.4007384479045868\n",
      "Step 8  Loss: 0.38249680399894714\n",
      "Step 9  Loss: 0.39502525329589844\n",
      "Step 10  Loss: 0.30868685245513916\n",
      "total Loss of epoch  258  is  3.8733359426259995\n",
      "Step 0  Loss: 0.3446584641933441\n",
      "Step 1  Loss: 0.30776897072792053\n",
      "Step 2  Loss: 0.4092530608177185\n",
      "Step 3  Loss: 0.2762078046798706\n",
      "Step 4  Loss: 0.31628289818763733\n",
      "Step 5  Loss: 0.4282474219799042\n",
      "Step 6  Loss: 0.4022659659385681\n",
      "Step 7  Loss: 0.3492673933506012\n",
      "Step 8  Loss: 0.3789253830909729\n",
      "Step 9  Loss: 0.3084034323692322\n",
      "Step 10  Loss: 0.2653871774673462\n",
      "total Loss of epoch  259  is  3.786667972803116\n",
      "Step 0  Loss: 0.2647334933280945\n",
      "Step 1  Loss: 0.311597615480423\n",
      "Step 2  Loss: 0.4874601662158966\n",
      "Step 3  Loss: 0.2887532711029053\n",
      "Step 4  Loss: 0.3707439601421356\n",
      "Step 5  Loss: 0.3692994713783264\n",
      "Step 6  Loss: 0.45342597365379333\n",
      "Step 7  Loss: 0.34441205859184265\n",
      "Step 8  Loss: 0.4325868487358093\n",
      "Step 9  Loss: 0.3508300483226776\n",
      "Step 10  Loss: 0.1763906031847\n",
      "total Loss of epoch  260  is  3.8502335101366043\n",
      "Step 0  Loss: 0.3853360116481781\n",
      "Step 1  Loss: 0.38764312863349915\n",
      "Step 2  Loss: 0.2626487612724304\n",
      "Step 3  Loss: 0.3974536657333374\n",
      "Step 4  Loss: 0.3618585765361786\n",
      "Step 5  Loss: 0.5123817920684814\n",
      "Step 6  Loss: 0.23625637590885162\n",
      "Step 7  Loss: 0.3827037513256073\n",
      "Step 8  Loss: 0.3936993181705475\n",
      "Step 9  Loss: 0.305847704410553\n",
      "Step 10  Loss: 0.3671344220638275\n",
      "total Loss of epoch  261  is  3.992963507771492\n",
      "Step 0  Loss: 0.2922263443470001\n",
      "Step 1  Loss: 0.3863459527492523\n",
      "Step 2  Loss: 0.40653425455093384\n",
      "Step 3  Loss: 0.40137365460395813\n",
      "Step 4  Loss: 0.3921531140804291\n",
      "Step 5  Loss: 0.3658961355686188\n",
      "Step 6  Loss: 0.36989620327949524\n",
      "Step 7  Loss: 0.2791332006454468\n",
      "Step 8  Loss: 0.30306562781333923\n",
      "Step 9  Loss: 0.3168796896934509\n",
      "Step 10  Loss: 0.34514397382736206\n",
      "total Loss of epoch  262  is  3.8586481511592865\n",
      "Step 0  Loss: 0.375916987657547\n",
      "Step 1  Loss: 0.3942107558250427\n",
      "Step 2  Loss: 0.3635152578353882\n",
      "Step 3  Loss: 0.3152066469192505\n",
      "Step 4  Loss: 0.44543468952178955\n",
      "Step 5  Loss: 0.3258465826511383\n",
      "Step 6  Loss: 0.3118566572666168\n",
      "Step 7  Loss: 0.3637755811214447\n",
      "Step 8  Loss: 0.3226684629917145\n",
      "Step 9  Loss: 0.279979944229126\n",
      "Step 10  Loss: 0.49693113565444946\n",
      "total Loss of epoch  263  is  3.9953427016735077\n",
      "Step 0  Loss: 0.38151979446411133\n",
      "Step 1  Loss: 0.3673252761363983\n",
      "Step 2  Loss: 0.36772620677948\n",
      "Step 3  Loss: 0.36038023233413696\n",
      "Step 4  Loss: 0.41965335607528687\n",
      "Step 5  Loss: 0.33594876527786255\n",
      "Step 6  Loss: 0.3530668318271637\n",
      "Step 7  Loss: 0.35939937829971313\n",
      "Step 8  Loss: 0.3995244801044464\n",
      "Step 9  Loss: 0.3179541826248169\n",
      "Step 10  Loss: 0.2980738878250122\n",
      "total Loss of epoch  264  is  3.9605723917484283\n",
      "Step 0  Loss: 0.44732698798179626\n",
      "Step 1  Loss: 0.38272106647491455\n",
      "Step 2  Loss: 0.26659274101257324\n",
      "Step 3  Loss: 0.35268399119377136\n",
      "Step 4  Loss: 0.25294196605682373\n",
      "Step 5  Loss: 0.31167247891426086\n",
      "Step 6  Loss: 0.3434063196182251\n",
      "Step 7  Loss: 0.405927449464798\n",
      "Step 8  Loss: 0.3833664655685425\n",
      "Step 9  Loss: 0.26007646322250366\n",
      "Step 10  Loss: 0.41736286878585815\n",
      "total Loss of epoch  265  is  3.8240787982940674\n",
      "Step 0  Loss: 0.3596556782722473\n",
      "Step 1  Loss: 0.32333558797836304\n",
      "Step 2  Loss: 0.4619238078594208\n",
      "Step 3  Loss: 0.32267940044403076\n",
      "Step 4  Loss: 0.47389841079711914\n",
      "Step 5  Loss: 0.36082178354263306\n",
      "Step 6  Loss: 0.358953058719635\n",
      "Step 7  Loss: 0.4317653477191925\n",
      "Step 8  Loss: 0.23606300354003906\n",
      "Step 9  Loss: 0.5294578671455383\n",
      "Step 10  Loss: 0.38112711906433105\n",
      "total Loss of epoch  266  is  4.23968106508255\n",
      "Step 0  Loss: 0.429043710231781\n",
      "Step 1  Loss: 0.28294268250465393\n",
      "Step 2  Loss: 0.2614979147911072\n",
      "Step 3  Loss: 0.41751629114151\n",
      "Step 4  Loss: 0.36544451117515564\n",
      "Step 5  Loss: 0.4071699380874634\n",
      "Step 6  Loss: 0.445823073387146\n",
      "Step 7  Loss: 0.44755515456199646\n",
      "Step 8  Loss: 0.3312236964702606\n",
      "Step 9  Loss: 0.4356425702571869\n",
      "Step 10  Loss: 0.5240695476531982\n",
      "total Loss of epoch  267  is  4.347929090261459\n",
      "Step 0  Loss: 0.32338571548461914\n",
      "Step 1  Loss: 0.31001394987106323\n",
      "Step 2  Loss: 0.30582407116889954\n",
      "Step 3  Loss: 0.2839307188987732\n",
      "Step 4  Loss: 0.4327354431152344\n",
      "Step 5  Loss: 0.30973532795906067\n",
      "Step 6  Loss: 0.2651403248310089\n",
      "Step 7  Loss: 0.3749041259288788\n",
      "Step 8  Loss: 0.40954455733299255\n",
      "Step 9  Loss: 0.31317177414894104\n",
      "Step 10  Loss: 0.3732362985610962\n",
      "total Loss of epoch  268  is  3.7016223073005676\n",
      "Step 0  Loss: 0.39780911803245544\n",
      "Step 1  Loss: 0.33545196056365967\n",
      "Step 2  Loss: 0.43888548016548157\n",
      "Step 3  Loss: 0.3661586046218872\n",
      "Step 4  Loss: 0.12949500977993011\n",
      "Step 5  Loss: 0.29179951548576355\n",
      "Step 6  Loss: 0.28502097725868225\n",
      "Step 7  Loss: 0.35608842968940735\n",
      "Step 8  Loss: 0.2697610557079315\n",
      "Step 9  Loss: 0.33912599086761475\n",
      "Step 10  Loss: 0.43863311409950256\n",
      "total Loss of epoch  269  is  3.648229256272316\n",
      "Step 0  Loss: 0.3608874976634979\n",
      "Step 1  Loss: 0.30826857686042786\n",
      "Step 2  Loss: 0.34858280420303345\n",
      "Step 3  Loss: 0.4367324411869049\n",
      "Step 4  Loss: 0.24911007285118103\n",
      "Step 5  Loss: 0.27974551916122437\n",
      "Step 6  Loss: 0.3044392466545105\n",
      "Step 7  Loss: 0.3449212610721588\n",
      "Step 8  Loss: 0.37770745158195496\n",
      "Step 9  Loss: 0.3094343841075897\n",
      "Step 10  Loss: 0.46142324805259705\n",
      "total Loss of epoch  270  is  3.7812525033950806\n",
      "Step 0  Loss: 0.3071430027484894\n",
      "Step 1  Loss: 0.28642067313194275\n",
      "Step 2  Loss: 0.3456434905529022\n",
      "Step 3  Loss: 0.4433116018772125\n",
      "Step 4  Loss: 0.5387373566627502\n",
      "Step 5  Loss: 0.45004042983055115\n",
      "Step 6  Loss: 0.38536831736564636\n",
      "Step 7  Loss: 0.34407344460487366\n",
      "Step 8  Loss: 0.44771242141723633\n",
      "Step 9  Loss: 0.4226970374584198\n",
      "Step 10  Loss: 0.5016142129898071\n",
      "total Loss of epoch  271  is  4.4727619886398315\n",
      "Step 0  Loss: 0.255398690700531\n",
      "Step 1  Loss: 0.36516618728637695\n",
      "Step 2  Loss: 0.481618732213974\n",
      "Step 3  Loss: 0.3293585479259491\n",
      "Step 4  Loss: 0.35674288868904114\n",
      "Step 5  Loss: 0.36233919858932495\n",
      "Step 6  Loss: 0.43019428849220276\n",
      "Step 7  Loss: 0.345886766910553\n",
      "Step 8  Loss: 0.38889411091804504\n",
      "Step 9  Loss: 0.36719051003456116\n",
      "Step 10  Loss: 0.4600484073162079\n",
      "total Loss of epoch  272  is  4.142838329076767\n",
      "Step 0  Loss: 0.33272111415863037\n",
      "Step 1  Loss: 0.4561721384525299\n",
      "Step 2  Loss: 0.3185148537158966\n",
      "Step 3  Loss: 0.33404141664505005\n",
      "Step 4  Loss: 0.4324510097503662\n",
      "Step 5  Loss: 0.5159814357757568\n",
      "Step 6  Loss: 0.3421440124511719\n",
      "Step 7  Loss: 0.4105644226074219\n",
      "Step 8  Loss: 0.32557106018066406\n",
      "Step 9  Loss: 0.3194044530391693\n",
      "Step 10  Loss: 0.4383901357650757\n",
      "total Loss of epoch  273  is  4.225956052541733\n",
      "Step 0  Loss: 0.33586740493774414\n",
      "Step 1  Loss: 0.15150554478168488\n",
      "Step 2  Loss: 0.3672819137573242\n",
      "Step 3  Loss: 0.3339366614818573\n",
      "Step 4  Loss: 0.3106594383716583\n",
      "Step 5  Loss: 0.3007887899875641\n",
      "Step 6  Loss: 0.2912941873073578\n",
      "Step 7  Loss: 0.38419264554977417\n",
      "Step 8  Loss: 0.2783975601196289\n",
      "Step 9  Loss: 0.40714943408966064\n",
      "Step 10  Loss: 0.36531659960746765\n",
      "total Loss of epoch  274  is  3.526390179991722\n",
      "Step 0  Loss: 0.5123183727264404\n",
      "Step 1  Loss: 0.35520684719085693\n",
      "Step 2  Loss: 0.3546717166900635\n",
      "Step 3  Loss: 0.4438191056251526\n",
      "Step 4  Loss: 0.34621626138687134\n",
      "Step 5  Loss: 0.4118814468383789\n",
      "Step 6  Loss: 0.38835272192955017\n",
      "Step 7  Loss: 0.3028900623321533\n",
      "Step 8  Loss: 0.36550384759902954\n",
      "Step 9  Loss: 0.3566477298736572\n",
      "Step 10  Loss: 0.33096614480018616\n",
      "total Loss of epoch  275  is  4.16847425699234\n",
      "Step 0  Loss: 0.4479527473449707\n",
      "Step 1  Loss: 0.32030755281448364\n",
      "Step 2  Loss: 0.2895990014076233\n",
      "Step 3  Loss: 0.49173861742019653\n",
      "Step 4  Loss: 0.42607343196868896\n",
      "Step 5  Loss: 0.33895617723464966\n",
      "Step 6  Loss: 0.32002130150794983\n",
      "Step 7  Loss: 0.3891993761062622\n",
      "Step 8  Loss: 0.3761977255344391\n",
      "Step 9  Loss: 0.4946592152118683\n",
      "Step 10  Loss: 0.3540138602256775\n",
      "total Loss of epoch  276  is  4.24871900677681\n",
      "Step 0  Loss: 0.5177686810493469\n",
      "Step 1  Loss: 0.343533456325531\n",
      "Step 2  Loss: 0.41931360960006714\n",
      "Step 3  Loss: 0.33100298047065735\n",
      "Step 4  Loss: 0.4593315124511719\n",
      "Step 5  Loss: 0.34643983840942383\n",
      "Step 6  Loss: 0.24121502041816711\n",
      "Step 7  Loss: 0.34205329418182373\n",
      "Step 8  Loss: 0.39781761169433594\n",
      "Step 9  Loss: 0.36180683970451355\n",
      "Step 10  Loss: 0.4738152325153351\n",
      "total Loss of epoch  277  is  4.2340980768203735\n",
      "Step 0  Loss: 0.43399858474731445\n",
      "Step 1  Loss: 0.3373301923274994\n",
      "Step 2  Loss: 0.3312743008136749\n",
      "Step 3  Loss: 0.4434772729873657\n",
      "Step 4  Loss: 0.3510635495185852\n",
      "Step 5  Loss: 0.32893121242523193\n",
      "Step 6  Loss: 0.36492910981178284\n",
      "Step 7  Loss: 0.39628085494041443\n",
      "Step 8  Loss: 0.2849084436893463\n",
      "Step 9  Loss: 0.4164264500141144\n",
      "Step 10  Loss: 0.327046275138855\n",
      "total Loss of epoch  278  is  4.015666246414185\n",
      "Step 0  Loss: 0.43111419677734375\n",
      "Step 1  Loss: 0.3702864944934845\n",
      "Step 2  Loss: 0.3146953582763672\n",
      "Step 3  Loss: 0.3624219596385956\n",
      "Step 4  Loss: 0.37701326608657837\n",
      "Step 5  Loss: 0.36415761709213257\n",
      "Step 6  Loss: 0.35709553956985474\n",
      "Step 7  Loss: 0.4834192097187042\n",
      "Step 8  Loss: 0.4229573607444763\n",
      "Step 9  Loss: 0.4253682792186737\n",
      "Step 10  Loss: 0.52020663022995\n",
      "total Loss of epoch  279  is  4.428735911846161\n",
      "Step 0  Loss: 0.41621196269989014\n",
      "Step 1  Loss: 0.3948705494403839\n",
      "Step 2  Loss: 0.2816159725189209\n",
      "Step 3  Loss: 0.38051992654800415\n",
      "Step 4  Loss: 0.41138195991516113\n",
      "Step 5  Loss: 0.4248359203338623\n",
      "Step 6  Loss: 0.2969658076763153\n",
      "Step 7  Loss: 0.39181992411613464\n",
      "Step 8  Loss: 0.38197794556617737\n",
      "Step 9  Loss: 0.3488459289073944\n",
      "Step 10  Loss: 0.3464553952217102\n",
      "total Loss of epoch  280  is  4.0755012929439545\n",
      "Step 0  Loss: 0.35152336955070496\n",
      "Step 1  Loss: 0.4161537289619446\n",
      "Step 2  Loss: 0.29300588369369507\n",
      "Step 3  Loss: 0.3082830309867859\n",
      "Step 4  Loss: 0.3728976845741272\n",
      "Step 5  Loss: 0.43577122688293457\n",
      "Step 6  Loss: 0.3382461369037628\n",
      "Step 7  Loss: 0.35352760553359985\n",
      "Step 8  Loss: 0.31673625111579895\n",
      "Step 9  Loss: 0.2900145947933197\n",
      "Step 10  Loss: 0.19795037806034088\n",
      "total Loss of epoch  281  is  3.6741098910570145\n",
      "Step 0  Loss: 0.2710883319377899\n",
      "Step 1  Loss: 0.34990373253822327\n",
      "Step 2  Loss: 0.29487982392311096\n",
      "Step 3  Loss: 0.39933687448501587\n",
      "Step 4  Loss: 0.41751062870025635\n",
      "Step 5  Loss: 0.4481055438518524\n",
      "Step 6  Loss: 0.3182954490184784\n",
      "Step 7  Loss: 0.3342769742012024\n",
      "Step 8  Loss: 0.42376241087913513\n",
      "Step 9  Loss: 0.30159899592399597\n",
      "Step 10  Loss: 0.40072178840637207\n",
      "total Loss of epoch  282  is  3.9594805538654327\n",
      "Step 0  Loss: 0.35571354627609253\n",
      "Step 1  Loss: 0.27695712447166443\n",
      "Step 2  Loss: 0.3791443109512329\n",
      "Step 3  Loss: 0.3106745779514313\n",
      "Step 4  Loss: 0.3383057415485382\n",
      "Step 5  Loss: 0.38198307156562805\n",
      "Step 6  Loss: 0.4899526536464691\n",
      "Step 7  Loss: 0.3598020374774933\n",
      "Step 8  Loss: 0.22591006755828857\n",
      "Step 9  Loss: 0.39697638154029846\n",
      "Step 10  Loss: 0.2566613256931305\n",
      "total Loss of epoch  283  is  3.7720808386802673\n",
      "Step 0  Loss: 0.331495076417923\n",
      "Step 1  Loss: 0.48962435126304626\n",
      "Step 2  Loss: 0.3755183815956116\n",
      "Step 3  Loss: 0.5039240717887878\n",
      "Step 4  Loss: 0.3742489218711853\n",
      "Step 5  Loss: 0.36665138602256775\n",
      "Step 6  Loss: 0.39543044567108154\n",
      "Step 7  Loss: 0.3656158149242401\n",
      "Step 8  Loss: 0.45842912793159485\n",
      "Step 9  Loss: 0.20339618623256683\n",
      "Step 10  Loss: 0.33713600039482117\n",
      "total Loss of epoch  284  is  4.201469764113426\n",
      "Step 0  Loss: 0.4032069742679596\n",
      "Step 1  Loss: 0.46175438165664673\n",
      "Step 2  Loss: 0.43518227338790894\n",
      "Step 3  Loss: 0.3914763927459717\n",
      "Step 4  Loss: 0.4592106342315674\n",
      "Step 5  Loss: 0.4777251183986664\n",
      "Step 6  Loss: 0.24386319518089294\n",
      "Step 7  Loss: 0.2582385540008545\n",
      "Step 8  Loss: 0.3987349569797516\n",
      "Step 9  Loss: 0.3409598171710968\n",
      "Step 10  Loss: 0.17709308862686157\n",
      "total Loss of epoch  285  is  4.047445386648178\n",
      "Step 0  Loss: 0.4080478549003601\n",
      "Step 1  Loss: 0.3988058269023895\n",
      "Step 2  Loss: 0.40474408864974976\n",
      "Step 3  Loss: 0.2534264922142029\n",
      "Step 4  Loss: 0.33213844895362854\n",
      "Step 5  Loss: 0.48266834020614624\n",
      "Step 6  Loss: 0.42835015058517456\n",
      "Step 7  Loss: 0.37442120909690857\n",
      "Step 8  Loss: 0.2788580060005188\n",
      "Step 9  Loss: 0.38529518246650696\n",
      "Step 10  Loss: 0.2943554222583771\n",
      "total Loss of epoch  286  is  4.041111022233963\n",
      "Step 0  Loss: 0.31904539465904236\n",
      "Step 1  Loss: 0.25573766231536865\n",
      "Step 2  Loss: 0.4384024441242218\n",
      "Step 3  Loss: 0.390292763710022\n",
      "Step 4  Loss: 0.4263046979904175\n",
      "Step 5  Loss: 0.3588978052139282\n",
      "Step 6  Loss: 0.5019448399543762\n",
      "Step 7  Loss: 0.26729264855384827\n",
      "Step 8  Loss: 0.3550303876399994\n",
      "Step 9  Loss: 0.3881498873233795\n",
      "Step 10  Loss: 0.3974534273147583\n",
      "total Loss of epoch  287  is  4.098551958799362\n",
      "Step 0  Loss: 0.33558565378189087\n",
      "Step 1  Loss: 0.37376144528388977\n",
      "Step 2  Loss: 0.29389849305152893\n",
      "Step 3  Loss: 0.41466596722602844\n",
      "Step 4  Loss: 0.3280758261680603\n",
      "Step 5  Loss: 0.4189301133155823\n",
      "Step 6  Loss: 0.4069589674472809\n",
      "Step 7  Loss: 0.29658985137939453\n",
      "Step 8  Loss: 0.36906298995018005\n",
      "Step 9  Loss: 0.5522469282150269\n",
      "Step 10  Loss: 0.6621853709220886\n",
      "total Loss of epoch  288  is  4.4519616067409515\n",
      "Step 0  Loss: 0.3668610751628876\n",
      "Step 1  Loss: 0.36710086464881897\n",
      "Step 2  Loss: 0.254779577255249\n",
      "Step 3  Loss: 0.4395744204521179\n",
      "Step 4  Loss: 0.41809019446372986\n",
      "Step 5  Loss: 0.4082290530204773\n",
      "Step 6  Loss: 0.2855565547943115\n",
      "Step 7  Loss: 0.4364513158798218\n",
      "Step 8  Loss: 0.3610166907310486\n",
      "Step 9  Loss: 0.41295355558395386\n",
      "Step 10  Loss: 0.3430413603782654\n",
      "total Loss of epoch  289  is  4.093654662370682\n",
      "Step 0  Loss: 0.420788437128067\n",
      "Step 1  Loss: 0.33072802424430847\n",
      "Step 2  Loss: 0.31070151925086975\n",
      "Step 3  Loss: 0.3518659174442291\n",
      "Step 4  Loss: 0.29490965604782104\n",
      "Step 5  Loss: 0.26188451051712036\n",
      "Step 6  Loss: 0.37820860743522644\n",
      "Step 7  Loss: 0.3935503661632538\n",
      "Step 8  Loss: 0.35930120944976807\n",
      "Step 9  Loss: 0.42075976729393005\n",
      "Step 10  Loss: 0.18936407566070557\n",
      "total Loss of epoch  290  is  3.7120620906352997\n",
      "Step 0  Loss: 0.4256457984447479\n",
      "Step 1  Loss: 0.3290737271308899\n",
      "Step 2  Loss: 0.3626200258731842\n",
      "Step 3  Loss: 0.2804824709892273\n",
      "Step 4  Loss: 0.35171157121658325\n",
      "Step 5  Loss: 0.32476481795310974\n",
      "Step 6  Loss: 0.4337083101272583\n",
      "Step 7  Loss: 0.31852206587791443\n",
      "Step 8  Loss: 0.47880029678344727\n",
      "Step 9  Loss: 0.3669925630092621\n",
      "Step 10  Loss: 0.38198786973953247\n",
      "total Loss of epoch  291  is  4.054309517145157\n",
      "Step 0  Loss: 0.31460389494895935\n",
      "Step 1  Loss: 0.4022308588027954\n",
      "Step 2  Loss: 0.35145944356918335\n",
      "Step 3  Loss: 0.3882982134819031\n",
      "Step 4  Loss: 0.3471924662590027\n",
      "Step 5  Loss: 0.3513474464416504\n",
      "Step 6  Loss: 0.41455334424972534\n",
      "Step 7  Loss: 0.31306177377700806\n",
      "Step 8  Loss: 0.3529389500617981\n",
      "Step 9  Loss: 0.40053337812423706\n",
      "Step 10  Loss: 0.33354640007019043\n",
      "total Loss of epoch  292  is  3.9697661697864532\n",
      "Step 0  Loss: 0.21308547258377075\n",
      "Step 1  Loss: 0.27201947569847107\n",
      "Step 2  Loss: 0.37682387232780457\n",
      "Step 3  Loss: 0.26349109411239624\n",
      "Step 4  Loss: 0.3108227849006653\n",
      "Step 5  Loss: 0.36398494243621826\n",
      "Step 6  Loss: 0.29036250710487366\n",
      "Step 7  Loss: 0.40092340111732483\n",
      "Step 8  Loss: 0.28823912143707275\n",
      "Step 9  Loss: 0.4295472800731659\n",
      "Step 10  Loss: 0.30865177512168884\n",
      "total Loss of epoch  293  is  3.517951726913452\n",
      "Step 0  Loss: 0.2978491485118866\n",
      "Step 1  Loss: 0.29589197039604187\n",
      "Step 2  Loss: 0.4843994379043579\n",
      "Step 3  Loss: 0.37535035610198975\n",
      "Step 4  Loss: 0.3329029977321625\n",
      "Step 5  Loss: 0.37863534688949585\n",
      "Step 6  Loss: 0.37242868542671204\n",
      "Step 7  Loss: 0.340801864862442\n",
      "Step 8  Loss: 0.24493470788002014\n",
      "Step 9  Loss: 0.38389450311660767\n",
      "Step 10  Loss: 0.27487465739250183\n",
      "total Loss of epoch  294  is  3.781963676214218\n",
      "Step 0  Loss: 0.3010369837284088\n",
      "Step 1  Loss: 0.3021811842918396\n",
      "Step 2  Loss: 0.20978623628616333\n",
      "Step 3  Loss: 0.4177275598049164\n",
      "Step 4  Loss: 0.477271169424057\n",
      "Step 5  Loss: 0.3640674352645874\n",
      "Step 6  Loss: 0.42408186197280884\n",
      "Step 7  Loss: 0.25629037618637085\n",
      "Step 8  Loss: 0.3941310942173004\n",
      "Step 9  Loss: 0.36854854226112366\n",
      "Step 10  Loss: 0.21163365244865417\n",
      "total Loss of epoch  295  is  3.7267560958862305\n",
      "Step 0  Loss: 0.3504859209060669\n",
      "Step 1  Loss: 0.3097977638244629\n",
      "Step 2  Loss: 0.3868038058280945\n",
      "Step 3  Loss: 0.22143349051475525\n",
      "Step 4  Loss: 0.33474910259246826\n",
      "Step 5  Loss: 0.35902732610702515\n",
      "Step 6  Loss: 0.35926932096481323\n",
      "Step 7  Loss: 0.33041512966156006\n",
      "Step 8  Loss: 0.2628019452095032\n",
      "Step 9  Loss: 0.35866108536720276\n",
      "Step 10  Loss: 0.3784727454185486\n",
      "total Loss of epoch  296  is  3.6519176363945007\n",
      "Step 0  Loss: 0.33171603083610535\n",
      "Step 1  Loss: 0.32214799523353577\n",
      "Step 2  Loss: 0.3830419182777405\n",
      "Step 3  Loss: 0.35336947441101074\n",
      "Step 4  Loss: 0.3148839473724365\n",
      "Step 5  Loss: 0.44235700368881226\n",
      "Step 6  Loss: 0.32919570803642273\n",
      "Step 7  Loss: 0.3881340026855469\n",
      "Step 8  Loss: 0.2758880853652954\n",
      "Step 9  Loss: 0.46551597118377686\n",
      "Step 10  Loss: 0.4106539487838745\n",
      "total Loss of epoch  297  is  4.0169040858745575\n",
      "Step 0  Loss: 0.3135567307472229\n",
      "Step 1  Loss: 0.2870965898036957\n",
      "Step 2  Loss: 0.4117967486381531\n",
      "Step 3  Loss: 0.32152631878852844\n",
      "Step 4  Loss: 0.22361116111278534\n",
      "Step 5  Loss: 0.3236418664455414\n",
      "Step 6  Loss: 0.32892873883247375\n",
      "Step 7  Loss: 0.2731621563434601\n",
      "Step 8  Loss: 0.401602566242218\n",
      "Step 9  Loss: 0.3716035485267639\n",
      "Step 10  Loss: 0.31749361753463745\n",
      "total Loss of epoch  298  is  3.57402004301548\n",
      "Step 0  Loss: 0.34101158380508423\n",
      "Step 1  Loss: 0.34257256984710693\n",
      "Step 2  Loss: 0.2775304317474365\n",
      "Step 3  Loss: 0.40676459670066833\n",
      "Step 4  Loss: 0.48408570885658264\n",
      "Step 5  Loss: 0.323592871427536\n",
      "Step 6  Loss: 0.36842235922813416\n",
      "Step 7  Loss: 0.35280171036720276\n",
      "Step 8  Loss: 0.33114728331565857\n",
      "Step 9  Loss: 0.37444835901260376\n",
      "Step 10  Loss: 0.4026377201080322\n",
      "total Loss of epoch  299  is  4.005015194416046\n",
      "Step 0  Loss: 0.3104899525642395\n",
      "Step 1  Loss: 0.35929200053215027\n",
      "Step 2  Loss: 0.3710577189922333\n",
      "Step 3  Loss: 0.4007674753665924\n",
      "Step 4  Loss: 0.31544196605682373\n",
      "Step 5  Loss: 0.3807504177093506\n",
      "Step 6  Loss: 0.2940635681152344\n",
      "Step 7  Loss: 0.39511212706565857\n",
      "Step 8  Loss: 0.3212560713291168\n",
      "Step 9  Loss: 0.3791123926639557\n",
      "Step 10  Loss: 0.20573189854621887\n",
      "total Loss of epoch  300  is  3.733075588941574\n",
      "Step 0  Loss: 0.40256935358047485\n",
      "Step 1  Loss: 0.3131697475910187\n",
      "Step 2  Loss: 0.32395753264427185\n",
      "Step 3  Loss: 0.4126073718070984\n",
      "Step 4  Loss: 0.2866570055484772\n",
      "Step 5  Loss: 0.41628050804138184\n",
      "Step 6  Loss: 0.3428172767162323\n",
      "Step 7  Loss: 0.4130550026893616\n",
      "Step 8  Loss: 0.345132052898407\n",
      "Step 9  Loss: 0.3536090850830078\n",
      "Step 10  Loss: 0.3957732617855072\n",
      "total Loss of epoch  301  is  4.005628198385239\n",
      "Step 0  Loss: 0.32792529463768005\n",
      "Step 1  Loss: 0.36943891644477844\n",
      "Step 2  Loss: 0.3960352838039398\n",
      "Step 3  Loss: 0.3195372521877289\n",
      "Step 4  Loss: 0.30099987983703613\n",
      "Step 5  Loss: 0.37546077370643616\n",
      "Step 6  Loss: 0.29638534784317017\n",
      "Step 7  Loss: 0.44673895835876465\n",
      "Step 8  Loss: 0.2820202112197876\n",
      "Step 9  Loss: 0.43715524673461914\n",
      "Step 10  Loss: 0.31728294491767883\n",
      "total Loss of epoch  302  is  3.86898010969162\n",
      "Step 0  Loss: 0.3360711634159088\n",
      "Step 1  Loss: 0.5034762024879456\n",
      "Step 2  Loss: 0.3327154815196991\n",
      "Step 3  Loss: 0.317261666059494\n",
      "Step 4  Loss: 0.344374418258667\n",
      "Step 5  Loss: 0.3603040874004364\n",
      "Step 6  Loss: 0.38110655546188354\n",
      "Step 7  Loss: 0.39698246121406555\n",
      "Step 8  Loss: 0.41364195942878723\n",
      "Step 9  Loss: 0.3959183692932129\n",
      "Step 10  Loss: 0.4821661412715912\n",
      "total Loss of epoch  303  is  4.264018505811691\n",
      "Step 0  Loss: 0.3417782783508301\n",
      "Step 1  Loss: 0.3839877247810364\n",
      "Step 2  Loss: 0.2967149317264557\n",
      "Step 3  Loss: 0.3790843188762665\n",
      "Step 4  Loss: 0.29432162642478943\n",
      "Step 5  Loss: 0.350163072347641\n",
      "Step 6  Loss: 0.34861457347869873\n",
      "Step 7  Loss: 0.4995037019252777\n",
      "Step 8  Loss: 0.39453238248825073\n",
      "Step 9  Loss: 0.3383933901786804\n",
      "Step 10  Loss: 0.24663463234901428\n",
      "total Loss of epoch  304  is  3.873728632926941\n",
      "Step 0  Loss: 0.371681272983551\n",
      "Step 1  Loss: 0.3454951345920563\n",
      "Step 2  Loss: 0.386532723903656\n",
      "Step 3  Loss: 0.42190882563591003\n",
      "Step 4  Loss: 0.2984218895435333\n",
      "Step 5  Loss: 0.40305349230766296\n",
      "Step 6  Loss: 0.3170125484466553\n",
      "Step 7  Loss: 0.4133388102054596\n",
      "Step 8  Loss: 0.23990611732006073\n",
      "Step 9  Loss: 0.34827569127082825\n",
      "Step 10  Loss: 0.3930744230747223\n",
      "total Loss of epoch  305  is  3.9387009292840958\n",
      "Step 0  Loss: 0.3167080581188202\n",
      "Step 1  Loss: 0.31729796528816223\n",
      "Step 2  Loss: 0.3599816560745239\n",
      "Step 3  Loss: 0.373102605342865\n",
      "Step 4  Loss: 0.42070838809013367\n",
      "Step 5  Loss: 0.35970667004585266\n",
      "Step 6  Loss: 0.43216627836227417\n",
      "Step 7  Loss: 0.35964712500572205\n",
      "Step 8  Loss: 0.31697550415992737\n",
      "Step 9  Loss: 0.3550870716571808\n",
      "Step 10  Loss: 0.33948197960853577\n",
      "total Loss of epoch  306  is  3.950863301753998\n",
      "Step 0  Loss: 0.3324615955352783\n",
      "Step 1  Loss: 0.34865373373031616\n",
      "Step 2  Loss: 0.26776430010795593\n",
      "Step 3  Loss: 0.3794665038585663\n",
      "Step 4  Loss: 0.3676449656486511\n",
      "Step 5  Loss: 0.3987451195716858\n",
      "Step 6  Loss: 0.35485324263572693\n",
      "Step 7  Loss: 0.2830103933811188\n",
      "Step 8  Loss: 0.44554999470710754\n",
      "Step 9  Loss: 0.323378324508667\n",
      "Step 10  Loss: 0.3135069012641907\n",
      "total Loss of epoch  307  is  3.8150350749492645\n",
      "Step 0  Loss: 0.41545578837394714\n",
      "Step 1  Loss: 0.34217432141304016\n",
      "Step 2  Loss: 0.3630615174770355\n",
      "Step 3  Loss: 0.3595391809940338\n",
      "Step 4  Loss: 0.37332555651664734\n",
      "Step 5  Loss: 0.39329013228416443\n",
      "Step 6  Loss: 0.30070170760154724\n",
      "Step 7  Loss: 0.34622228145599365\n",
      "Step 8  Loss: 0.3325541615486145\n",
      "Step 9  Loss: 0.3259495496749878\n",
      "Step 10  Loss: 0.2670932114124298\n",
      "total Loss of epoch  308  is  3.8193674087524414\n",
      "Step 0  Loss: 0.34166932106018066\n",
      "Step 1  Loss: 0.38984763622283936\n",
      "Step 2  Loss: 0.3888795077800751\n",
      "Step 3  Loss: 0.16316716372966766\n",
      "Step 4  Loss: 0.34559008479118347\n",
      "Step 5  Loss: 0.3052138388156891\n",
      "Step 6  Loss: 0.4234354496002197\n",
      "Step 7  Loss: 0.3746047616004944\n",
      "Step 8  Loss: 0.30881401896476746\n",
      "Step 9  Loss: 0.4151941239833832\n",
      "Step 10  Loss: 0.3838064968585968\n",
      "total Loss of epoch  309  is  3.840222403407097\n",
      "Step 0  Loss: 0.42829063534736633\n",
      "Step 1  Loss: 0.3623761832714081\n",
      "Step 2  Loss: 0.4049892723560333\n",
      "Step 3  Loss: 0.3202285170555115\n",
      "Step 4  Loss: 0.42600035667419434\n",
      "Step 5  Loss: 0.31226056814193726\n",
      "Step 6  Loss: 0.2880939543247223\n",
      "Step 7  Loss: 0.28873035311698914\n",
      "Step 8  Loss: 0.3192501962184906\n",
      "Step 9  Loss: 0.4267568290233612\n",
      "Step 10  Loss: 0.22911542654037476\n",
      "total Loss of epoch  310  is  3.806092292070389\n",
      "Step 0  Loss: 0.23786699771881104\n",
      "Step 1  Loss: 0.29260143637657166\n",
      "Step 2  Loss: 0.3978334665298462\n",
      "Step 3  Loss: 0.3787088692188263\n",
      "Step 4  Loss: 0.46902647614479065\n",
      "Step 5  Loss: 0.46339964866638184\n",
      "Step 6  Loss: 0.3952985107898712\n",
      "Step 7  Loss: 0.22128675878047943\n",
      "Step 8  Loss: 0.30732986330986023\n",
      "Step 9  Loss: 0.3472942113876343\n",
      "Step 10  Loss: 0.33735963702201843\n",
      "total Loss of epoch  311  is  3.8480058759450912\n",
      "Step 0  Loss: 0.4022309184074402\n",
      "Step 1  Loss: 0.4102988541126251\n",
      "Step 2  Loss: 0.33747828006744385\n",
      "Step 3  Loss: 0.25027382373809814\n",
      "Step 4  Loss: 0.39444687962532043\n",
      "Step 5  Loss: 0.3386998772621155\n",
      "Step 6  Loss: 0.44003039598464966\n",
      "Step 7  Loss: 0.4365882873535156\n",
      "Step 8  Loss: 0.5488573908805847\n",
      "Step 9  Loss: 0.3708494007587433\n",
      "Step 10  Loss: 0.29591473937034607\n",
      "total Loss of epoch  312  is  4.225668847560883\n",
      "Step 0  Loss: 0.5146579146385193\n",
      "Step 1  Loss: 0.3256796896457672\n",
      "Step 2  Loss: 0.30631163716316223\n",
      "Step 3  Loss: 0.3935737609863281\n",
      "Step 4  Loss: 0.3274697959423065\n",
      "Step 5  Loss: 0.318291038274765\n",
      "Step 6  Loss: 0.27039653062820435\n",
      "Step 7  Loss: 0.523594081401825\n",
      "Step 8  Loss: 0.4472394585609436\n",
      "Step 9  Loss: 0.34540268778800964\n",
      "Step 10  Loss: 0.2826954424381256\n",
      "total Loss of epoch  313  is  4.0553120374679565\n",
      "Step 0  Loss: 0.3514096438884735\n",
      "Step 1  Loss: 0.397865891456604\n",
      "Step 2  Loss: 0.40388023853302\n",
      "Step 3  Loss: 0.304694801568985\n",
      "Step 4  Loss: 0.29549530148506165\n",
      "Step 5  Loss: 0.221012145280838\n",
      "Step 6  Loss: 0.3646678030490875\n",
      "Step 7  Loss: 0.36330273747444153\n",
      "Step 8  Loss: 0.2779233455657959\n",
      "Step 9  Loss: 0.3801049292087555\n",
      "Step 10  Loss: 0.3148450255393982\n",
      "total Loss of epoch  314  is  3.675201863050461\n",
      "Step 0  Loss: 0.3697350025177002\n",
      "Step 1  Loss: 0.3693183660507202\n",
      "Step 2  Loss: 0.34735649824142456\n",
      "Step 3  Loss: 0.39892444014549255\n",
      "Step 4  Loss: 0.388370156288147\n",
      "Step 5  Loss: 0.33624669909477234\n",
      "Step 6  Loss: 0.3875691294670105\n",
      "Step 7  Loss: 0.2810737192630768\n",
      "Step 8  Loss: 0.38792043924331665\n",
      "Step 9  Loss: 0.30035510659217834\n",
      "Step 10  Loss: 0.3762097954750061\n",
      "total Loss of epoch  315  is  3.943079352378845\n",
      "Step 0  Loss: 0.2177753448486328\n",
      "Step 1  Loss: 0.2568860650062561\n",
      "Step 2  Loss: 0.3226439952850342\n",
      "Step 3  Loss: 0.42524659633636475\n",
      "Step 4  Loss: 0.251003623008728\n",
      "Step 5  Loss: 0.3601977825164795\n",
      "Step 6  Loss: 0.2662142515182495\n",
      "Step 7  Loss: 0.3304300606250763\n",
      "Step 8  Loss: 0.4095184803009033\n",
      "Step 9  Loss: 0.41516244411468506\n",
      "Step 10  Loss: 0.34823623299598694\n",
      "total Loss of epoch  316  is  3.6033148765563965\n",
      "Step 0  Loss: 0.3999652862548828\n",
      "Step 1  Loss: 0.4660009443759918\n",
      "Step 2  Loss: 0.3801771104335785\n",
      "Step 3  Loss: 0.23277051746845245\n",
      "Step 4  Loss: 0.2794943153858185\n",
      "Step 5  Loss: 0.3260245621204376\n",
      "Step 6  Loss: 0.3412255644798279\n",
      "Step 7  Loss: 0.4652004837989807\n",
      "Step 8  Loss: 0.4305728077888489\n",
      "Step 9  Loss: 0.40322187542915344\n",
      "Step 10  Loss: 0.40444791316986084\n",
      "total Loss of epoch  317  is  4.129101380705833\n",
      "Step 0  Loss: 0.35493040084838867\n",
      "Step 1  Loss: 0.29964348673820496\n",
      "Step 2  Loss: 0.2812631130218506\n",
      "Step 3  Loss: 0.286142498254776\n",
      "Step 4  Loss: 0.39880645275115967\n",
      "Step 5  Loss: 0.3363981544971466\n",
      "Step 6  Loss: 0.389565110206604\n",
      "Step 7  Loss: 0.381831556558609\n",
      "Step 8  Loss: 0.40096622705459595\n",
      "Step 9  Loss: 0.26220324635505676\n",
      "Step 10  Loss: 0.390704482793808\n",
      "total Loss of epoch  318  is  3.7824547290802\n",
      "Step 0  Loss: 0.2808237671852112\n",
      "Step 1  Loss: 0.30215707421302795\n",
      "Step 2  Loss: 0.44545209407806396\n",
      "Step 3  Loss: 0.37802377343177795\n",
      "Step 4  Loss: 0.36087724566459656\n",
      "Step 5  Loss: 0.4258117377758026\n",
      "Step 6  Loss: 0.30038973689079285\n",
      "Step 7  Loss: 0.402131587266922\n",
      "Step 8  Loss: 0.3966690003871918\n",
      "Step 9  Loss: 0.4103842079639435\n",
      "Step 10  Loss: 0.35474705696105957\n",
      "total Loss of epoch  319  is  4.05746728181839\n",
      "Step 0  Loss: 0.39231565594673157\n",
      "Step 1  Loss: 0.3232809007167816\n",
      "Step 2  Loss: 0.3679293990135193\n",
      "Step 3  Loss: 0.3689610958099365\n",
      "Step 4  Loss: 0.3741104006767273\n",
      "Step 5  Loss: 0.3756432831287384\n",
      "Step 6  Loss: 0.3267218768596649\n",
      "Step 7  Loss: 0.41602739691734314\n",
      "Step 8  Loss: 0.2985095977783203\n",
      "Step 9  Loss: 0.43224936723709106\n",
      "Step 10  Loss: 0.4512745141983032\n",
      "total Loss of epoch  320  is  4.127023488283157\n",
      "Step 0  Loss: 0.3371247947216034\n",
      "Step 1  Loss: 0.35142087936401367\n",
      "Step 2  Loss: 0.29980719089508057\n",
      "Step 3  Loss: 0.3872546851634979\n",
      "Step 4  Loss: 0.32833996415138245\n",
      "Step 5  Loss: 0.42636165022850037\n",
      "Step 6  Loss: 0.3218745291233063\n",
      "Step 7  Loss: 0.33262982964515686\n",
      "Step 8  Loss: 0.34668052196502686\n",
      "Step 9  Loss: 0.38510218262672424\n",
      "Step 10  Loss: 0.44147399067878723\n",
      "total Loss of epoch  321  is  3.95807021856308\n",
      "Step 0  Loss: 0.2862342596054077\n",
      "Step 1  Loss: 0.31433531641960144\n",
      "Step 2  Loss: 0.24053099751472473\n",
      "Step 3  Loss: 0.25121593475341797\n",
      "Step 4  Loss: 0.3268965184688568\n",
      "Step 5  Loss: 0.36778873205184937\n",
      "Step 6  Loss: 0.3442649841308594\n",
      "Step 7  Loss: 0.3262855112552643\n",
      "Step 8  Loss: 0.4069381058216095\n",
      "Step 9  Loss: 0.43587011098861694\n",
      "Step 10  Loss: 0.5028079152107239\n",
      "total Loss of epoch  322  is  3.803168386220932\n",
      "Step 0  Loss: 0.2694752812385559\n",
      "Step 1  Loss: 0.40413376688957214\n",
      "Step 2  Loss: 0.33976420760154724\n",
      "Step 3  Loss: 0.3474607467651367\n",
      "Step 4  Loss: 0.3223675489425659\n",
      "Step 5  Loss: 0.2965734004974365\n",
      "Step 6  Loss: 0.2605960965156555\n",
      "Step 7  Loss: 0.35560235381126404\n",
      "Step 8  Loss: 0.3861096501350403\n",
      "Step 9  Loss: 0.4026460349559784\n",
      "Step 10  Loss: 0.34548255801200867\n",
      "total Loss of epoch  323  is  3.7302116453647614\n",
      "Step 0  Loss: 0.3148272931575775\n",
      "Step 1  Loss: 0.29479700326919556\n",
      "Step 2  Loss: 0.32125499844551086\n",
      "Step 3  Loss: 0.3214899003505707\n",
      "Step 4  Loss: 0.37832096219062805\n",
      "Step 5  Loss: 0.42525699734687805\n",
      "Step 6  Loss: 0.4567720592021942\n",
      "Step 7  Loss: 0.46122804284095764\n",
      "Step 8  Loss: 0.4194912612438202\n",
      "Step 9  Loss: 0.3849605619907379\n",
      "Step 10  Loss: 0.4030734598636627\n",
      "total Loss of epoch  324  is  4.181472539901733\n",
      "Step 0  Loss: 0.3979548513889313\n",
      "Step 1  Loss: 0.2986043095588684\n",
      "Step 2  Loss: 0.4586262106895447\n",
      "Step 3  Loss: 0.3873421549797058\n",
      "Step 4  Loss: 0.37128761410713196\n",
      "Step 5  Loss: 0.2513658106327057\n",
      "Step 6  Loss: 0.34285637736320496\n",
      "Step 7  Loss: 0.3586674630641937\n",
      "Step 8  Loss: 0.3929027318954468\n",
      "Step 9  Loss: 0.291740357875824\n",
      "Step 10  Loss: 0.21162571012973785\n",
      "total Loss of epoch  325  is  3.762973591685295\n",
      "Step 0  Loss: 0.33027786016464233\n",
      "Step 1  Loss: 0.3710894286632538\n",
      "Step 2  Loss: 0.3954464793205261\n",
      "Step 3  Loss: 0.3546925187110901\n",
      "Step 4  Loss: 0.4426953196525574\n",
      "Step 5  Loss: 0.35863205790519714\n",
      "Step 6  Loss: 0.24429193139076233\n",
      "Step 7  Loss: 0.503853976726532\n",
      "Step 8  Loss: 0.3946678638458252\n",
      "Step 9  Loss: 0.4319068491458893\n",
      "Step 10  Loss: 0.34633108973503113\n",
      "total Loss of epoch  326  is  4.173885375261307\n",
      "Step 0  Loss: 0.28680071234703064\n",
      "Step 1  Loss: 0.27034708857536316\n",
      "Step 2  Loss: 0.35783031582832336\n",
      "Step 3  Loss: 0.45709651708602905\n",
      "Step 4  Loss: 0.4451022446155548\n",
      "Step 5  Loss: 0.4320680797100067\n",
      "Step 6  Loss: 0.2552487850189209\n",
      "Step 7  Loss: 0.2733811140060425\n",
      "Step 8  Loss: 0.41287553310394287\n",
      "Step 9  Loss: 0.31809762120246887\n",
      "Step 10  Loss: 0.33182191848754883\n",
      "total Loss of epoch  327  is  3.8406699299812317\n",
      "Step 0  Loss: 0.4309002161026001\n",
      "Step 1  Loss: 0.28137388825416565\n",
      "Step 2  Loss: 0.43697914481163025\n",
      "Step 3  Loss: 0.3663153052330017\n",
      "Step 4  Loss: 0.33541733026504517\n",
      "Step 5  Loss: 0.32533150911331177\n",
      "Step 6  Loss: 0.371966153383255\n",
      "Step 7  Loss: 0.3657897710800171\n",
      "Step 8  Loss: 0.38305673003196716\n",
      "Step 9  Loss: 0.36808544397354126\n",
      "Step 10  Loss: 0.303989052772522\n",
      "total Loss of epoch  328  is  3.969204545021057\n",
      "Step 0  Loss: 0.41146600246429443\n",
      "Step 1  Loss: 0.35134321451187134\n",
      "Step 2  Loss: 0.40063947439193726\n",
      "Step 3  Loss: 0.3030412197113037\n",
      "Step 4  Loss: 0.46581289172172546\n",
      "Step 5  Loss: 0.48192736506462097\n",
      "Step 6  Loss: 0.3536241352558136\n",
      "Step 7  Loss: 0.3494189977645874\n",
      "Step 8  Loss: 0.4746789336204529\n",
      "Step 9  Loss: 0.37698519229888916\n",
      "Step 10  Loss: 0.5018126964569092\n",
      "total Loss of epoch  329  is  4.470750123262405\n",
      "Step 0  Loss: 0.3483227491378784\n",
      "Step 1  Loss: 0.41996607184410095\n",
      "Step 2  Loss: 0.33929505944252014\n",
      "Step 3  Loss: 0.36728036403656006\n",
      "Step 4  Loss: 0.25800472497940063\n",
      "Step 5  Loss: 0.3965604603290558\n",
      "Step 6  Loss: 0.43620413541793823\n",
      "Step 7  Loss: 0.31017664074897766\n",
      "Step 8  Loss: 0.3044353127479553\n",
      "Step 9  Loss: 0.3744848668575287\n",
      "Step 10  Loss: 0.26939550042152405\n",
      "total Loss of epoch  330  is  3.82412588596344\n",
      "Step 0  Loss: 0.40221890807151794\n",
      "Step 1  Loss: 0.3473314642906189\n",
      "Step 2  Loss: 0.42719003558158875\n",
      "Step 3  Loss: 0.3196406066417694\n",
      "Step 4  Loss: 0.3652552664279938\n",
      "Step 5  Loss: 0.47413966059684753\n",
      "Step 6  Loss: 0.36387360095977783\n",
      "Step 7  Loss: 0.3481253683567047\n",
      "Step 8  Loss: 0.39590322971343994\n",
      "Step 9  Loss: 0.3190959692001343\n",
      "Step 10  Loss: 0.32463061809539795\n",
      "total Loss of epoch  331  is  4.087404727935791\n",
      "Step 0  Loss: 0.2291916012763977\n",
      "Step 1  Loss: 0.2945946156978607\n",
      "Step 2  Loss: 0.37864765524864197\n",
      "Step 3  Loss: 0.3180428445339203\n",
      "Step 4  Loss: 0.3553815484046936\n",
      "Step 5  Loss: 0.40178191661834717\n",
      "Step 6  Loss: 0.46000435948371887\n",
      "Step 7  Loss: 0.3148897588253021\n",
      "Step 8  Loss: 0.3117723762989044\n",
      "Step 9  Loss: 0.38471531867980957\n",
      "Step 10  Loss: 0.3481442332267761\n",
      "total Loss of epoch  332  is  3.7971662282943726\n",
      "Step 0  Loss: 0.3123074471950531\n",
      "Step 1  Loss: 0.46136897802352905\n",
      "Step 2  Loss: 0.3473168611526489\n",
      "Step 3  Loss: 0.3825533092021942\n",
      "Step 4  Loss: 0.2953803241252899\n",
      "Step 5  Loss: 0.4242812991142273\n",
      "Step 6  Loss: 0.27859073877334595\n",
      "Step 7  Loss: 0.4112953841686249\n",
      "Step 8  Loss: 0.4351513981819153\n",
      "Step 9  Loss: 0.3840537369251251\n",
      "Step 10  Loss: 0.31130704283714294\n",
      "total Loss of epoch  333  is  4.043606519699097\n",
      "Step 0  Loss: 0.34378474950790405\n",
      "Step 1  Loss: 0.4437970817089081\n",
      "Step 2  Loss: 0.3499627709388733\n",
      "Step 3  Loss: 0.24935397505760193\n",
      "Step 4  Loss: 0.3092348277568817\n",
      "Step 5  Loss: 0.2791297435760498\n",
      "Step 6  Loss: 0.4215589165687561\n",
      "Step 7  Loss: 0.4149841070175171\n",
      "Step 8  Loss: 0.43452706933021545\n",
      "Step 9  Loss: 0.3346366584300995\n",
      "Step 10  Loss: 0.35756322741508484\n",
      "total Loss of epoch  334  is  3.938533127307892\n",
      "Step 0  Loss: 0.3716052770614624\n",
      "Step 1  Loss: 0.32880282402038574\n",
      "Step 2  Loss: 0.3940586745738983\n",
      "Step 3  Loss: 0.2833957076072693\n",
      "Step 4  Loss: 0.28412938117980957\n",
      "Step 5  Loss: 0.3519873321056366\n",
      "Step 6  Loss: 0.3923022747039795\n",
      "Step 7  Loss: 0.3234981596469879\n",
      "Step 8  Loss: 0.37164199352264404\n",
      "Step 9  Loss: 0.39853963255882263\n",
      "Step 10  Loss: 0.1504131406545639\n",
      "total Loss of epoch  335  is  3.65037439763546\n",
      "Step 0  Loss: 0.4113478362560272\n",
      "Step 1  Loss: 0.35981494188308716\n",
      "Step 2  Loss: 0.4235893785953522\n",
      "Step 3  Loss: 0.41475915908813477\n",
      "Step 4  Loss: 0.37236443161964417\n",
      "Step 5  Loss: 0.35065335035324097\n",
      "Step 6  Loss: 0.371352881193161\n",
      "Step 7  Loss: 0.35499176383018494\n",
      "Step 8  Loss: 0.3111034035682678\n",
      "Step 9  Loss: 0.40672567486763\n",
      "Step 10  Loss: 0.409475713968277\n",
      "total Loss of epoch  336  is  4.186178535223007\n",
      "Step 0  Loss: 0.33354419469833374\n",
      "Step 1  Loss: 0.2767103314399719\n",
      "Step 2  Loss: 0.31965580582618713\n",
      "Step 3  Loss: 0.3362240493297577\n",
      "Step 4  Loss: 0.25969353318214417\n",
      "Step 5  Loss: 0.4032835066318512\n",
      "Step 6  Loss: 0.3638874888420105\n",
      "Step 7  Loss: 0.23097620904445648\n",
      "Step 8  Loss: 0.2971775233745575\n",
      "Step 9  Loss: 0.3791826665401459\n",
      "Step 10  Loss: 0.18174222111701965\n",
      "total Loss of epoch  337  is  3.382077530026436\n",
      "Step 0  Loss: 0.27288374304771423\n",
      "Step 1  Loss: 0.348598450422287\n",
      "Step 2  Loss: 0.2650717496871948\n",
      "Step 3  Loss: 0.4219878017902374\n",
      "Step 4  Loss: 0.4025508165359497\n",
      "Step 5  Loss: 0.5091806054115295\n",
      "Step 6  Loss: 0.23232850432395935\n",
      "Step 7  Loss: 0.3327709138393402\n",
      "Step 8  Loss: 0.3713931143283844\n",
      "Step 9  Loss: 0.3309352397918701\n",
      "Step 10  Loss: 0.30987972021102905\n",
      "total Loss of epoch  338  is  3.797580659389496\n",
      "Step 0  Loss: 0.45561444759368896\n",
      "Step 1  Loss: 0.3432249128818512\n",
      "Step 2  Loss: 0.37961551547050476\n",
      "Step 3  Loss: 0.3547162413597107\n",
      "Step 4  Loss: 0.32992780208587646\n",
      "Step 5  Loss: 0.3246932327747345\n",
      "Step 6  Loss: 0.4062331020832062\n",
      "Step 7  Loss: 0.3125630021095276\n",
      "Step 8  Loss: 0.41182830929756165\n",
      "Step 9  Loss: 0.4205503761768341\n",
      "Step 10  Loss: 0.36081957817077637\n",
      "total Loss of epoch  339  is  4.0997865200042725\n",
      "Step 0  Loss: 0.2948603332042694\n",
      "Step 1  Loss: 0.36827507615089417\n",
      "Step 2  Loss: 0.26757004857063293\n",
      "Step 3  Loss: 0.3695092499256134\n",
      "Step 4  Loss: 0.36458539962768555\n",
      "Step 5  Loss: 0.3661363422870636\n",
      "Step 6  Loss: 0.4068038761615753\n",
      "Step 7  Loss: 0.34704187512397766\n",
      "Step 8  Loss: 0.3876176178455353\n",
      "Step 9  Loss: 0.31608596444129944\n",
      "Step 10  Loss: 0.1687345653772354\n",
      "total Loss of epoch  340  is  3.657220348715782\n",
      "Step 0  Loss: 0.41630324721336365\n",
      "Step 1  Loss: 0.277388334274292\n",
      "Step 2  Loss: 0.3854873478412628\n",
      "Step 3  Loss: 0.33312323689460754\n",
      "Step 4  Loss: 0.38697195053100586\n",
      "Step 5  Loss: 0.3701154291629791\n",
      "Step 6  Loss: 0.4683886468410492\n",
      "Step 7  Loss: 0.3752199411392212\n",
      "Step 8  Loss: 0.29624640941619873\n",
      "Step 9  Loss: 0.37063342332839966\n",
      "Step 10  Loss: 0.39362579584121704\n",
      "total Loss of epoch  341  is  4.073503762483597\n",
      "Step 0  Loss: 0.26336953043937683\n",
      "Step 1  Loss: 0.45492687821388245\n",
      "Step 2  Loss: 0.3794196546077728\n",
      "Step 3  Loss: 0.29631099104881287\n",
      "Step 4  Loss: 0.3930383324623108\n",
      "Step 5  Loss: 0.3754176199436188\n",
      "Step 6  Loss: 0.4487375020980835\n",
      "Step 7  Loss: 0.3844144642353058\n",
      "Step 8  Loss: 0.32706117630004883\n",
      "Step 9  Loss: 0.45932894945144653\n",
      "Step 10  Loss: 0.44965967535972595\n",
      "total Loss of epoch  342  is  4.231684774160385\n",
      "Step 0  Loss: 0.31679627299308777\n",
      "Step 1  Loss: 0.28654322028160095\n",
      "Step 2  Loss: 0.37294548749923706\n",
      "Step 3  Loss: 0.4271702468395233\n",
      "Step 4  Loss: 0.27089741826057434\n",
      "Step 5  Loss: 0.4433620572090149\n",
      "Step 6  Loss: 0.36884191632270813\n",
      "Step 7  Loss: 0.28651145100593567\n",
      "Step 8  Loss: 0.45330655574798584\n",
      "Step 9  Loss: 0.2916471064090729\n",
      "Step 10  Loss: 0.3137023448944092\n",
      "total Loss of epoch  343  is  3.83172407746315\n",
      "Step 0  Loss: 0.35972684621810913\n",
      "Step 1  Loss: 0.36215412616729736\n",
      "Step 2  Loss: 0.4790465533733368\n",
      "Step 3  Loss: 0.3867425322532654\n",
      "Step 4  Loss: 0.26970595121383667\n",
      "Step 5  Loss: 0.38833650946617126\n",
      "Step 6  Loss: 0.3275497853755951\n",
      "Step 7  Loss: 0.38915809988975525\n",
      "Step 8  Loss: 0.41452646255493164\n",
      "Step 9  Loss: 0.36249807476997375\n",
      "Step 10  Loss: 0.27454376220703125\n",
      "total Loss of epoch  344  is  4.013988703489304\n",
      "Step 0  Loss: 0.21537388861179352\n",
      "Step 1  Loss: 0.2804532051086426\n",
      "Step 2  Loss: 0.3930746614933014\n",
      "Step 3  Loss: 0.33827298879623413\n",
      "Step 4  Loss: 0.33909696340560913\n",
      "Step 5  Loss: 0.4117998480796814\n",
      "Step 6  Loss: 0.3833528459072113\n",
      "Step 7  Loss: 0.3617658317089081\n",
      "Step 8  Loss: 0.3405067026615143\n",
      "Step 9  Loss: 0.35129883885383606\n",
      "Step 10  Loss: 0.5108851194381714\n",
      "total Loss of epoch  345  is  3.9258808940649033\n",
      "Step 0  Loss: 0.4319627285003662\n",
      "Step 1  Loss: 0.3190663456916809\n",
      "Step 2  Loss: 0.371878981590271\n",
      "Step 3  Loss: 0.3896430730819702\n",
      "Step 4  Loss: 0.5355352759361267\n",
      "Step 5  Loss: 0.3367556035518646\n",
      "Step 6  Loss: 0.22969457507133484\n",
      "Step 7  Loss: 0.3372572958469391\n",
      "Step 8  Loss: 0.35071349143981934\n",
      "Step 9  Loss: 0.32767513394355774\n",
      "Step 10  Loss: 0.5844274759292603\n",
      "total Loss of epoch  346  is  4.214609980583191\n",
      "Step 0  Loss: 0.40496501326560974\n",
      "Step 1  Loss: 0.3343476355075836\n",
      "Step 2  Loss: 0.3775547742843628\n",
      "Step 3  Loss: 0.3799716830253601\n",
      "Step 4  Loss: 0.25514379143714905\n",
      "Step 5  Loss: 0.4570436477661133\n",
      "Step 6  Loss: 0.31622347235679626\n",
      "Step 7  Loss: 0.300086110830307\n",
      "Step 8  Loss: 0.39385879039764404\n",
      "Step 9  Loss: 0.35184016823768616\n",
      "Step 10  Loss: 0.22463591396808624\n",
      "total Loss of epoch  347  is  3.7956710010766983\n",
      "Step 0  Loss: 0.31690502166748047\n",
      "Step 1  Loss: 0.27549558877944946\n",
      "Step 2  Loss: 0.3936040699481964\n",
      "Step 3  Loss: 0.3679603636264801\n",
      "Step 4  Loss: 0.23325544595718384\n",
      "Step 5  Loss: 0.4598783552646637\n",
      "Step 6  Loss: 0.4321463406085968\n",
      "Step 7  Loss: 0.21971718966960907\n",
      "Step 8  Loss: 0.39832255244255066\n",
      "Step 9  Loss: 0.27290454506874084\n",
      "Step 10  Loss: 0.17667067050933838\n",
      "total Loss of epoch  348  is  3.5468601435422897\n",
      "Step 0  Loss: 0.373663067817688\n",
      "Step 1  Loss: 0.46441593766212463\n",
      "Step 2  Loss: 0.3383234441280365\n",
      "Step 3  Loss: 0.3815821409225464\n",
      "Step 4  Loss: 0.2994348108768463\n",
      "Step 5  Loss: 0.31561052799224854\n",
      "Step 6  Loss: 0.28387168049812317\n",
      "Step 7  Loss: 0.36086735129356384\n",
      "Step 8  Loss: 0.3981318771839142\n",
      "Step 9  Loss: 0.3503735065460205\n",
      "Step 10  Loss: 0.404427707195282\n",
      "total Loss of epoch  349  is  3.970702052116394\n",
      "Step 0  Loss: 0.37593063712120056\n",
      "Step 1  Loss: 0.28480982780456543\n",
      "Step 2  Loss: 0.32721319794654846\n",
      "Step 3  Loss: 0.41542354226112366\n",
      "Step 4  Loss: 0.43531665205955505\n",
      "Step 5  Loss: 0.5029639005661011\n",
      "Step 6  Loss: 0.29290834069252014\n",
      "Step 7  Loss: 0.47881627082824707\n",
      "Step 8  Loss: 0.360696017742157\n",
      "Step 9  Loss: 0.286735862493515\n",
      "Step 10  Loss: 0.308209627866745\n",
      "total Loss of epoch  350  is  4.069023877382278\n",
      "Step 0  Loss: 0.3100476861000061\n",
      "Step 1  Loss: 0.2973811626434326\n",
      "Step 2  Loss: 0.44162431359291077\n",
      "Step 3  Loss: 0.23127718269824982\n",
      "Step 4  Loss: 0.4203898012638092\n",
      "Step 5  Loss: 0.3547489643096924\n",
      "Step 6  Loss: 0.34516191482543945\n",
      "Step 7  Loss: 0.3867572247982025\n",
      "Step 8  Loss: 0.34541192650794983\n",
      "Step 9  Loss: 0.358905553817749\n",
      "Step 10  Loss: 0.43908438086509705\n",
      "total Loss of epoch  351  is  3.9307901114225388\n",
      "Step 0  Loss: 0.3088958263397217\n",
      "Step 1  Loss: 0.24549038708209991\n",
      "Step 2  Loss: 0.43124788999557495\n",
      "Step 3  Loss: 0.36702051758766174\n",
      "Step 4  Loss: 0.5081078410148621\n",
      "Step 5  Loss: 0.5369427800178528\n",
      "Step 6  Loss: 0.48674869537353516\n",
      "Step 7  Loss: 0.36185500025749207\n",
      "Step 8  Loss: 0.31211915612220764\n",
      "Step 9  Loss: 0.35474544763565063\n",
      "Step 10  Loss: 0.32602861523628235\n",
      "total Loss of epoch  352  is  4.239202156662941\n",
      "Step 0  Loss: 0.43092820048332214\n",
      "Step 1  Loss: 0.3793458044528961\n",
      "Step 2  Loss: 0.4638887345790863\n",
      "Step 3  Loss: 0.2964082658290863\n",
      "Step 4  Loss: 0.24699902534484863\n",
      "Step 5  Loss: 0.4879462420940399\n",
      "Step 6  Loss: 0.35214996337890625\n",
      "Step 7  Loss: 0.40793269872665405\n",
      "Step 8  Loss: 0.24208280444145203\n",
      "Step 9  Loss: 0.3305315673351288\n",
      "Step 10  Loss: 0.3588729202747345\n",
      "total Loss of epoch  353  is  3.997086226940155\n",
      "Step 0  Loss: 0.46893683075904846\n",
      "Step 1  Loss: 0.3438970744609833\n",
      "Step 2  Loss: 0.42243674397468567\n",
      "Step 3  Loss: 0.4036021828651428\n",
      "Step 4  Loss: 0.34884628653526306\n",
      "Step 5  Loss: 0.36103492975234985\n",
      "Step 6  Loss: 0.3858833312988281\n",
      "Step 7  Loss: 0.2870800495147705\n",
      "Step 8  Loss: 0.4354698061943054\n",
      "Step 9  Loss: 0.47553589940071106\n",
      "Step 10  Loss: 0.34663212299346924\n",
      "total Loss of epoch  354  is  4.2793552577495575\n",
      "Step 0  Loss: 0.24969425797462463\n",
      "Step 1  Loss: 0.4485580325126648\n",
      "Step 2  Loss: 0.44446033239364624\n",
      "Step 3  Loss: 0.4649055600166321\n",
      "Step 4  Loss: 0.39706510305404663\n",
      "Step 5  Loss: 0.5197703242301941\n",
      "Step 6  Loss: 0.35892215371131897\n",
      "Step 7  Loss: 0.22208131849765778\n",
      "Step 8  Loss: 0.3397756516933441\n",
      "Step 9  Loss: 0.3658933639526367\n",
      "Step 10  Loss: 0.3827447295188904\n",
      "total Loss of epoch  355  is  4.193870827555656\n",
      "Step 0  Loss: 0.4153488278388977\n",
      "Step 1  Loss: 0.36084553599357605\n",
      "Step 2  Loss: 0.31103670597076416\n",
      "Step 3  Loss: 0.4314784109592438\n",
      "Step 4  Loss: 0.49034804105758667\n",
      "Step 5  Loss: 0.3415633738040924\n",
      "Step 6  Loss: 0.4142778217792511\n",
      "Step 7  Loss: 0.33692699670791626\n",
      "Step 8  Loss: 0.3577519357204437\n",
      "Step 9  Loss: 0.2925984859466553\n",
      "Step 10  Loss: 0.3814341425895691\n",
      "total Loss of epoch  356  is  4.133610278367996\n",
      "Step 0  Loss: 0.2213405966758728\n",
      "Step 1  Loss: 0.2976357936859131\n",
      "Step 2  Loss: 0.36883845925331116\n",
      "Step 3  Loss: 0.3359523117542267\n",
      "Step 4  Loss: 0.30664631724357605\n",
      "Step 5  Loss: 0.20618468523025513\n",
      "Step 6  Loss: 0.29136568307876587\n",
      "Step 7  Loss: 0.37051790952682495\n",
      "Step 8  Loss: 0.2857276499271393\n",
      "Step 9  Loss: 0.3817019760608673\n",
      "Step 10  Loss: 0.2081371247768402\n",
      "total Loss of epoch  357  is  3.2740485072135925\n",
      "Step 0  Loss: 0.2987253963947296\n",
      "Step 1  Loss: 0.3144001364707947\n",
      "Step 2  Loss: 0.43043771386146545\n",
      "Step 3  Loss: 0.26595214009284973\n",
      "Step 4  Loss: 0.35690271854400635\n",
      "Step 5  Loss: 0.4121553301811218\n",
      "Step 6  Loss: 0.37525197863578796\n",
      "Step 7  Loss: 0.26116877794265747\n",
      "Step 8  Loss: 0.34840264916419983\n",
      "Step 9  Loss: 0.3773629665374756\n",
      "Step 10  Loss: 0.35704106092453003\n",
      "total Loss of epoch  358  is  3.7978008687496185\n",
      "Step 0  Loss: 0.45916518568992615\n",
      "Step 1  Loss: 0.39523330330848694\n",
      "Step 2  Loss: 0.3943064212799072\n",
      "Step 3  Loss: 0.3112936317920685\n",
      "Step 4  Loss: 0.24370107054710388\n",
      "Step 5  Loss: 0.3496426045894623\n",
      "Step 6  Loss: 0.3750729560852051\n",
      "Step 7  Loss: 0.4014745354652405\n",
      "Step 8  Loss: 0.3989662528038025\n",
      "Step 9  Loss: 0.32994407415390015\n",
      "Step 10  Loss: 0.38185760378837585\n",
      "total Loss of epoch  359  is  4.040657639503479\n",
      "Step 0  Loss: 0.4120393395423889\n",
      "Step 1  Loss: 0.37663769721984863\n",
      "Step 2  Loss: 0.3005521595478058\n",
      "Step 3  Loss: 0.3152216970920563\n",
      "Step 4  Loss: 0.3407464027404785\n",
      "Step 5  Loss: 0.4188416004180908\n",
      "Step 6  Loss: 0.27694347500801086\n",
      "Step 7  Loss: 0.412330687046051\n",
      "Step 8  Loss: 0.40748080611228943\n",
      "Step 9  Loss: 0.49205100536346436\n",
      "Step 10  Loss: 0.5117210745811462\n",
      "total Loss of epoch  360  is  4.264565944671631\n",
      "Step 0  Loss: 0.32894837856292725\n",
      "Step 1  Loss: 0.25372859835624695\n",
      "Step 2  Loss: 0.35136356949806213\n",
      "Step 3  Loss: 0.21509017050266266\n",
      "Step 4  Loss: 0.477154403924942\n",
      "Step 5  Loss: 0.3201965093612671\n",
      "Step 6  Loss: 0.2939586639404297\n",
      "Step 7  Loss: 0.3119339644908905\n",
      "Step 8  Loss: 0.36450642347335815\n",
      "Step 9  Loss: 0.2655377984046936\n",
      "Step 10  Loss: 0.38117796182632446\n",
      "total Loss of epoch  361  is  3.5635964423418045\n",
      "Step 0  Loss: 0.2196682095527649\n",
      "Step 1  Loss: 0.3455026149749756\n",
      "Step 2  Loss: 0.2347683608531952\n",
      "Step 3  Loss: 0.2710568904876709\n",
      "Step 4  Loss: 0.3406497538089752\n",
      "Step 5  Loss: 0.3422577381134033\n",
      "Step 6  Loss: 0.39860227704048157\n",
      "Step 7  Loss: 0.29745253920555115\n",
      "Step 8  Loss: 0.2865212559700012\n",
      "Step 9  Loss: 0.33065885305404663\n",
      "Step 10  Loss: 0.3576253652572632\n",
      "total Loss of epoch  362  is  3.424763858318329\n",
      "Step 0  Loss: 0.43936240673065186\n",
      "Step 1  Loss: 0.27622631192207336\n",
      "Step 2  Loss: 0.31905314326286316\n",
      "Step 3  Loss: 0.3349314332008362\n",
      "Step 4  Loss: 0.3890620768070221\n",
      "Step 5  Loss: 0.31560513377189636\n",
      "Step 6  Loss: 0.2709839940071106\n",
      "Step 7  Loss: 0.32352757453918457\n",
      "Step 8  Loss: 0.34092026948928833\n",
      "Step 9  Loss: 0.3819587230682373\n",
      "Step 10  Loss: 0.488709956407547\n",
      "total Loss of epoch  363  is  3.880341023206711\n",
      "Step 0  Loss: 0.38345518708229065\n",
      "Step 1  Loss: 0.3297750651836395\n",
      "Step 2  Loss: 0.3341286778450012\n",
      "Step 3  Loss: 0.3448086977005005\n",
      "Step 4  Loss: 0.3884003758430481\n",
      "Step 5  Loss: 0.3780820667743683\n",
      "Step 6  Loss: 0.2933312654495239\n",
      "Step 7  Loss: 0.38214316964149475\n",
      "Step 8  Loss: 0.3561694025993347\n",
      "Step 9  Loss: 0.3159286379814148\n",
      "Step 10  Loss: 0.410232275724411\n",
      "total Loss of epoch  364  is  3.9164548218250275\n",
      "Step 0  Loss: 0.37421131134033203\n",
      "Step 1  Loss: 0.32266005873680115\n",
      "Step 2  Loss: 0.42060261964797974\n",
      "Step 3  Loss: 0.36506402492523193\n",
      "Step 4  Loss: 0.3538353145122528\n",
      "Step 5  Loss: 0.4489627778530121\n",
      "Step 6  Loss: 0.31296226382255554\n",
      "Step 7  Loss: 0.35683685541152954\n",
      "Step 8  Loss: 0.3244911730289459\n",
      "Step 9  Loss: 0.3152722716331482\n",
      "Step 10  Loss: 0.3760237395763397\n",
      "total Loss of epoch  365  is  3.9709224104881287\n",
      "Step 0  Loss: 0.34887459874153137\n",
      "Step 1  Loss: 0.32045215368270874\n",
      "Step 2  Loss: 0.43145307898521423\n",
      "Step 3  Loss: 0.32780131697654724\n",
      "Step 4  Loss: 0.3703562915325165\n",
      "Step 5  Loss: 0.42006951570510864\n",
      "Step 6  Loss: 0.3464750647544861\n",
      "Step 7  Loss: 0.478866845369339\n",
      "Step 8  Loss: 0.34777289628982544\n",
      "Step 9  Loss: 0.5030133128166199\n",
      "Step 10  Loss: 0.36242467164993286\n",
      "total Loss of epoch  366  is  4.25755974650383\n",
      "Step 0  Loss: 0.2801516354084015\n",
      "Step 1  Loss: 0.4537309408187866\n",
      "Step 2  Loss: 0.3281796872615814\n",
      "Step 3  Loss: 0.4530905783176422\n",
      "Step 4  Loss: 0.36073726415634155\n",
      "Step 5  Loss: 0.2654428482055664\n",
      "Step 6  Loss: 0.21042928099632263\n",
      "Step 7  Loss: 0.3749605119228363\n",
      "Step 8  Loss: 0.39312416315078735\n",
      "Step 9  Loss: 0.3530791997909546\n",
      "Step 10  Loss: 0.35635921359062195\n",
      "total Loss of epoch  367  is  3.8292853236198425\n",
      "Step 0  Loss: 0.30205997824668884\n",
      "Step 1  Loss: 0.4239867031574249\n",
      "Step 2  Loss: 0.2689221501350403\n",
      "Step 3  Loss: 0.2812606394290924\n",
      "Step 4  Loss: 0.3504168689250946\n",
      "Step 5  Loss: 0.24364234507083893\n",
      "Step 6  Loss: 0.3445874750614166\n",
      "Step 7  Loss: 0.30393996834754944\n",
      "Step 8  Loss: 0.40868744254112244\n",
      "Step 9  Loss: 0.3175393342971802\n",
      "Step 10  Loss: 0.39845016598701477\n",
      "total Loss of epoch  368  is  3.6434930711984634\n",
      "Step 0  Loss: 0.31430554389953613\n",
      "Step 1  Loss: 0.32072994112968445\n",
      "Step 2  Loss: 0.45156675577163696\n",
      "Step 3  Loss: 0.33127519488334656\n",
      "Step 4  Loss: 0.21600796282291412\n",
      "Step 5  Loss: 0.43750664591789246\n",
      "Step 6  Loss: 0.3691023588180542\n",
      "Step 7  Loss: 0.32032904028892517\n",
      "Step 8  Loss: 0.31532129645347595\n",
      "Step 9  Loss: 0.35965967178344727\n",
      "Step 10  Loss: 0.3774944841861725\n",
      "total Loss of epoch  369  is  3.8132988959550858\n",
      "Step 0  Loss: 0.3292698264122009\n",
      "Step 1  Loss: 0.4016924500465393\n",
      "Step 2  Loss: 0.46293383836746216\n",
      "Step 3  Loss: 0.25487545132637024\n",
      "Step 4  Loss: 0.38176265358924866\n",
      "Step 5  Loss: 0.4140239953994751\n",
      "Step 6  Loss: 0.38272929191589355\n",
      "Step 7  Loss: 0.32809576392173767\n",
      "Step 8  Loss: 0.41716933250427246\n",
      "Step 9  Loss: 0.31065064668655396\n",
      "Step 10  Loss: 0.3528122305870056\n",
      "total Loss of epoch  370  is  4.03601548075676\n",
      "Step 0  Loss: 0.3349300026893616\n",
      "Step 1  Loss: 0.3109005093574524\n",
      "Step 2  Loss: 0.35772478580474854\n",
      "Step 3  Loss: 0.3790128529071808\n",
      "Step 4  Loss: 0.34177637100219727\n",
      "Step 5  Loss: 0.3403432071208954\n",
      "Step 6  Loss: 0.4158378541469574\n",
      "Step 7  Loss: 0.3520347476005554\n",
      "Step 8  Loss: 0.4024454355239868\n",
      "Step 9  Loss: 0.3039880394935608\n",
      "Step 10  Loss: 0.4320462942123413\n",
      "total Loss of epoch  371  is  3.9710400998592377\n",
      "Step 0  Loss: 0.2425161898136139\n",
      "Step 1  Loss: 0.3652048408985138\n",
      "Step 2  Loss: 0.34616363048553467\n",
      "Step 3  Loss: 0.39605337381362915\n",
      "Step 4  Loss: 0.32583481073379517\n",
      "Step 5  Loss: 0.3073619604110718\n",
      "Step 6  Loss: 0.3254680335521698\n",
      "Step 7  Loss: 0.4394914507865906\n",
      "Step 8  Loss: 0.39511317014694214\n",
      "Step 9  Loss: 0.3873307704925537\n",
      "Step 10  Loss: 0.3625016212463379\n",
      "total Loss of epoch  372  is  3.8930398523807526\n",
      "Step 0  Loss: 0.3373502492904663\n",
      "Step 1  Loss: 0.3838280141353607\n",
      "Step 2  Loss: 0.3361678421497345\n",
      "Step 3  Loss: 0.27449846267700195\n",
      "Step 4  Loss: 0.3794522285461426\n",
      "Step 5  Loss: 0.40909263491630554\n",
      "Step 6  Loss: 0.4310438632965088\n",
      "Step 7  Loss: 0.31439146399497986\n",
      "Step 8  Loss: 0.27860912680625916\n",
      "Step 9  Loss: 0.39010533690452576\n",
      "Step 10  Loss: 0.25809189677238464\n",
      "total Loss of epoch  373  is  3.79263111948967\n",
      "Step 0  Loss: 0.4648224115371704\n",
      "Step 1  Loss: 0.3291369378566742\n",
      "Step 2  Loss: 0.4462551474571228\n",
      "Step 3  Loss: 0.34186968207359314\n",
      "Step 4  Loss: 0.364865243434906\n",
      "Step 5  Loss: 0.3512899875640869\n",
      "Step 6  Loss: 0.3767133057117462\n",
      "Step 7  Loss: 0.35057976841926575\n",
      "Step 8  Loss: 0.3867843449115753\n",
      "Step 9  Loss: 0.5166903734207153\n",
      "Step 10  Loss: 0.32412001490592957\n",
      "total Loss of epoch  374  is  4.253127217292786\n",
      "Step 0  Loss: 0.40679046511650085\n",
      "Step 1  Loss: 0.3794213831424713\n",
      "Step 2  Loss: 0.3536248207092285\n",
      "Step 3  Loss: 0.38821619749069214\n",
      "Step 4  Loss: 0.3903583884239197\n",
      "Step 5  Loss: 0.42269402742385864\n",
      "Step 6  Loss: 0.35637542605400085\n",
      "Step 7  Loss: 0.4370049834251404\n",
      "Step 8  Loss: 0.37336626648902893\n",
      "Step 9  Loss: 0.3851621448993683\n",
      "Step 10  Loss: 0.41992393136024475\n",
      "total Loss of epoch  375  is  4.312938034534454\n",
      "Step 0  Loss: 0.3353789448738098\n",
      "Step 1  Loss: 0.238511860370636\n",
      "Step 2  Loss: 0.3395318388938904\n",
      "Step 3  Loss: 0.42837920784950256\n",
      "Step 4  Loss: 0.3153017461299896\n",
      "Step 5  Loss: 0.42559149861335754\n",
      "Step 6  Loss: 0.35419031977653503\n",
      "Step 7  Loss: 0.285662978887558\n",
      "Step 8  Loss: 0.3570643961429596\n",
      "Step 9  Loss: 0.34040626883506775\n",
      "Step 10  Loss: 0.3695991337299347\n",
      "total Loss of epoch  376  is  3.789618194103241\n",
      "Step 0  Loss: 0.27488625049591064\n",
      "Step 1  Loss: 0.32117435336112976\n",
      "Step 2  Loss: 0.5434693098068237\n",
      "Step 3  Loss: 0.3643305003643036\n",
      "Step 4  Loss: 0.1513890027999878\n",
      "Step 5  Loss: 0.33581891655921936\n",
      "Step 6  Loss: 0.46114444732666016\n",
      "Step 7  Loss: 0.3204019367694855\n",
      "Step 8  Loss: 0.3813745081424713\n",
      "Step 9  Loss: 0.3202502429485321\n",
      "Step 10  Loss: 0.38655567169189453\n",
      "total Loss of epoch  377  is  3.8607951402664185\n",
      "Step 0  Loss: 0.41169893741607666\n",
      "Step 1  Loss: 0.3165525496006012\n",
      "Step 2  Loss: 0.3182644844055176\n",
      "Step 3  Loss: 0.3400842249393463\n",
      "Step 4  Loss: 0.4607570767402649\n",
      "Step 5  Loss: 0.4062339663505554\n",
      "Step 6  Loss: 0.2826741337776184\n",
      "Step 7  Loss: 0.2806815505027771\n",
      "Step 8  Loss: 0.3192838728427887\n",
      "Step 9  Loss: 0.4304969310760498\n",
      "Step 10  Loss: 0.48563387989997864\n",
      "total Loss of epoch  378  is  4.052361607551575\n",
      "Step 0  Loss: 0.31314849853515625\n",
      "Step 1  Loss: 0.3992660939693451\n",
      "Step 2  Loss: 0.43102002143859863\n",
      "Step 3  Loss: 0.35668450593948364\n",
      "Step 4  Loss: 0.5234881639480591\n",
      "Step 5  Loss: 0.36348971724510193\n",
      "Step 6  Loss: 0.35228630900382996\n",
      "Step 7  Loss: 0.3656467795372009\n",
      "Step 8  Loss: 0.391354501247406\n",
      "Step 9  Loss: 0.3169165253639221\n",
      "Step 10  Loss: 0.31249287724494934\n",
      "total Loss of epoch  379  is  4.125793993473053\n",
      "Step 0  Loss: 0.4118311405181885\n",
      "Step 1  Loss: 0.39815759658813477\n",
      "Step 2  Loss: 0.38643065094947815\n",
      "Step 3  Loss: 0.27652508020401\n",
      "Step 4  Loss: 0.28458601236343384\n",
      "Step 5  Loss: 0.3338468074798584\n",
      "Step 6  Loss: 0.34849607944488525\n",
      "Step 7  Loss: 0.37465399503707886\n",
      "Step 8  Loss: 0.3248898983001709\n",
      "Step 9  Loss: 0.264693945646286\n",
      "Step 10  Loss: 0.3244532346725464\n",
      "total Loss of epoch  380  is  3.728564441204071\n",
      "Step 0  Loss: 0.4512997269630432\n",
      "Step 1  Loss: 0.23236535489559174\n",
      "Step 2  Loss: 0.3254888951778412\n",
      "Step 3  Loss: 0.4361514151096344\n",
      "Step 4  Loss: 0.44312533736228943\n",
      "Step 5  Loss: 0.34715890884399414\n",
      "Step 6  Loss: 0.3748326301574707\n",
      "Step 7  Loss: 0.42531895637512207\n",
      "Step 8  Loss: 0.30898207426071167\n",
      "Step 9  Loss: 0.3789426386356354\n",
      "Step 10  Loss: 0.2812630236148834\n",
      "total Loss of epoch  381  is  4.004928961396217\n",
      "Step 0  Loss: 0.31823134422302246\n",
      "Step 1  Loss: 0.3217412531375885\n",
      "Step 2  Loss: 0.3940069377422333\n",
      "Step 3  Loss: 0.37426069378852844\n",
      "Step 4  Loss: 0.43941107392311096\n",
      "Step 5  Loss: 0.36087167263031006\n",
      "Step 6  Loss: 0.3734632134437561\n",
      "Step 7  Loss: 0.374946653842926\n",
      "Step 8  Loss: 0.4533345103263855\n",
      "Step 9  Loss: 0.26834505796432495\n",
      "Step 10  Loss: 0.29423168301582336\n",
      "total Loss of epoch  382  is  3.9728440940380096\n",
      "Step 0  Loss: 0.3100701868534088\n",
      "Step 1  Loss: 0.37496986985206604\n",
      "Step 2  Loss: 0.37147292494773865\n",
      "Step 3  Loss: 0.2919776439666748\n",
      "Step 4  Loss: 0.3107284903526306\n",
      "Step 5  Loss: 0.437808632850647\n",
      "Step 6  Loss: 0.39093315601348877\n",
      "Step 7  Loss: 0.2457970827817917\n",
      "Step 8  Loss: 0.3906835615634918\n",
      "Step 9  Loss: 0.4143616557121277\n",
      "Step 10  Loss: 0.30035117268562317\n",
      "total Loss of epoch  383  is  3.839154377579689\n",
      "Step 0  Loss: 0.3807491064071655\n",
      "Step 1  Loss: 0.2511640191078186\n",
      "Step 2  Loss: 0.3150625228881836\n",
      "Step 3  Loss: 0.26325714588165283\n",
      "Step 4  Loss: 0.49459436535835266\n",
      "Step 5  Loss: 0.3361775875091553\n",
      "Step 6  Loss: 0.41845759749412537\n",
      "Step 7  Loss: 0.33418846130371094\n",
      "Step 8  Loss: 0.3020083010196686\n",
      "Step 9  Loss: 0.36840248107910156\n",
      "Step 10  Loss: 0.3682434558868408\n",
      "total Loss of epoch  384  is  3.8323050439357758\n",
      "Step 0  Loss: 0.338507741689682\n",
      "Step 1  Loss: 0.4027418792247772\n",
      "Step 2  Loss: 0.34107568860054016\n",
      "Step 3  Loss: 0.27636221051216125\n",
      "Step 4  Loss: 0.45833417773246765\n",
      "Step 5  Loss: 0.3181111812591553\n",
      "Step 6  Loss: 0.32898637652397156\n",
      "Step 7  Loss: 0.2665790915489197\n",
      "Step 8  Loss: 0.29218095541000366\n",
      "Step 9  Loss: 0.42415088415145874\n",
      "Step 10  Loss: 0.31257933378219604\n",
      "total Loss of epoch  385  is  3.7596095204353333\n",
      "Step 0  Loss: 0.41939428448677063\n",
      "Step 1  Loss: 0.28643256425857544\n",
      "Step 2  Loss: 0.29143255949020386\n",
      "Step 3  Loss: 0.3303210437297821\n",
      "Step 4  Loss: 0.37516844272613525\n",
      "Step 5  Loss: 0.4656330347061157\n",
      "Step 6  Loss: 0.3134266138076782\n",
      "Step 7  Loss: 0.3001203238964081\n",
      "Step 8  Loss: 0.37164637446403503\n",
      "Step 9  Loss: 0.29428762197494507\n",
      "Step 10  Loss: 0.2414337396621704\n",
      "total Loss of epoch  386  is  3.68929660320282\n",
      "Step 0  Loss: 0.43162959814071655\n",
      "Step 1  Loss: 0.3763628900051117\n",
      "Step 2  Loss: 0.3967176079750061\n",
      "Step 3  Loss: 0.361581951379776\n",
      "Step 4  Loss: 0.4601219892501831\n",
      "Step 5  Loss: 0.4737716019153595\n",
      "Step 6  Loss: 0.38107290863990784\n",
      "Step 7  Loss: 0.4068315923213959\n",
      "Step 8  Loss: 0.33532366156578064\n",
      "Step 9  Loss: 0.4775981903076172\n",
      "Step 10  Loss: 0.49624598026275635\n",
      "total Loss of epoch  387  is  4.597257971763611\n",
      "Step 0  Loss: 0.2729608714580536\n",
      "Step 1  Loss: 0.3140077292919159\n",
      "Step 2  Loss: 0.39414510130882263\n",
      "Step 3  Loss: 0.2824020981788635\n",
      "Step 4  Loss: 0.2894320785999298\n",
      "Step 5  Loss: 0.3568514287471771\n",
      "Step 6  Loss: 0.3535640835762024\n",
      "Step 7  Loss: 0.32067936658859253\n",
      "Step 8  Loss: 0.3167836368083954\n",
      "Step 9  Loss: 0.40858590602874756\n",
      "Step 10  Loss: 0.4319087266921997\n",
      "total Loss of epoch  388  is  3.7413210272789\n",
      "Step 0  Loss: 0.38254162669181824\n",
      "Step 1  Loss: 0.2894100248813629\n",
      "Step 2  Loss: 0.2994869351387024\n",
      "Step 3  Loss: 0.31051793694496155\n",
      "Step 4  Loss: 0.30241090059280396\n",
      "Step 5  Loss: 0.314139187335968\n",
      "Step 6  Loss: 0.23130716383457184\n",
      "Step 7  Loss: 0.45156893134117126\n",
      "Step 8  Loss: 0.4266008138656616\n",
      "Step 9  Loss: 0.328792929649353\n",
      "Step 10  Loss: 0.4694068133831024\n",
      "total Loss of epoch  389  is  3.8061832636594772\n",
      "Step 0  Loss: 0.32012712955474854\n",
      "Step 1  Loss: 0.28996986150741577\n",
      "Step 2  Loss: 0.540589451789856\n",
      "Step 3  Loss: 0.3983350694179535\n",
      "Step 4  Loss: 0.2897477149963379\n",
      "Step 5  Loss: 0.45409920811653137\n",
      "Step 6  Loss: 0.34966930747032166\n",
      "Step 7  Loss: 0.29615604877471924\n",
      "Step 8  Loss: 0.31595709919929504\n",
      "Step 9  Loss: 0.4269393980503082\n",
      "Step 10  Loss: 0.32153502106666565\n",
      "total Loss of epoch  390  is  4.003125309944153\n",
      "Step 0  Loss: 0.44615209102630615\n",
      "Step 1  Loss: 0.39100420475006104\n",
      "Step 2  Loss: 0.41161197423934937\n",
      "Step 3  Loss: 0.3794967532157898\n",
      "Step 4  Loss: 0.364623486995697\n",
      "Step 5  Loss: 0.414372980594635\n",
      "Step 6  Loss: 0.34545817971229553\n",
      "Step 7  Loss: 0.43831562995910645\n",
      "Step 8  Loss: 0.41215068101882935\n",
      "Step 9  Loss: 0.358577698469162\n",
      "Step 10  Loss: 0.3710368871688843\n",
      "total Loss of epoch  391  is  4.332800567150116\n",
      "Step 0  Loss: 0.2700434625148773\n",
      "Step 1  Loss: 0.4251247048377991\n",
      "Step 2  Loss: 0.35293567180633545\n",
      "Step 3  Loss: 0.34811824560165405\n",
      "Step 4  Loss: 0.38646045327186584\n",
      "Step 5  Loss: 0.42728564143180847\n",
      "Step 6  Loss: 0.21954511106014252\n",
      "Step 7  Loss: 0.36539995670318604\n",
      "Step 8  Loss: 0.3298594057559967\n",
      "Step 9  Loss: 0.41290804743766785\n",
      "Step 10  Loss: 0.41277003288269043\n",
      "total Loss of epoch  392  is  3.9504507333040237\n",
      "Step 0  Loss: 0.45817819237709045\n",
      "Step 1  Loss: 0.33860108256340027\n",
      "Step 2  Loss: 0.282866507768631\n",
      "Step 3  Loss: 0.38282641768455505\n",
      "Step 4  Loss: 0.2701491713523865\n",
      "Step 5  Loss: 0.3004396855831146\n",
      "Step 6  Loss: 0.38897672295570374\n",
      "Step 7  Loss: 0.448855996131897\n",
      "Step 8  Loss: 0.44678163528442383\n",
      "Step 9  Loss: 0.4172200560569763\n",
      "Step 10  Loss: 0.381168931722641\n",
      "total Loss of epoch  393  is  4.11606439948082\n",
      "Step 0  Loss: 0.38166770339012146\n",
      "Step 1  Loss: 0.3623879551887512\n",
      "Step 2  Loss: 0.36565178632736206\n",
      "Step 3  Loss: 0.3974545896053314\n",
      "Step 4  Loss: 0.4903794527053833\n",
      "Step 5  Loss: 0.3914858400821686\n",
      "Step 6  Loss: 0.3700510263442993\n",
      "Step 7  Loss: 0.3692169189453125\n",
      "Step 8  Loss: 0.37898874282836914\n",
      "Step 9  Loss: 0.3879585862159729\n",
      "Step 10  Loss: 0.46401071548461914\n",
      "total Loss of epoch  394  is  4.359253317117691\n",
      "Step 0  Loss: 0.3611636459827423\n",
      "Step 1  Loss: 0.2706359326839447\n",
      "Step 2  Loss: 0.3652542233467102\n",
      "Step 3  Loss: 0.36222898960113525\n",
      "Step 4  Loss: 0.3080495595932007\n",
      "Step 5  Loss: 0.3323158025741577\n",
      "Step 6  Loss: 0.44209250807762146\n",
      "Step 7  Loss: 0.4048507511615753\n",
      "Step 8  Loss: 0.40368303656578064\n",
      "Step 9  Loss: 0.37760695815086365\n",
      "Step 10  Loss: 0.2081325799226761\n",
      "total Loss of epoch  395  is  3.836013987660408\n",
      "Step 0  Loss: 0.2886633276939392\n",
      "Step 1  Loss: 0.3511686623096466\n",
      "Step 2  Loss: 0.3413846790790558\n",
      "Step 3  Loss: 0.3377370536327362\n",
      "Step 4  Loss: 0.36138778924942017\n",
      "Step 5  Loss: 0.30508360266685486\n",
      "Step 6  Loss: 0.3451816141605377\n",
      "Step 7  Loss: 0.2384900003671646\n",
      "Step 8  Loss: 0.26804307103157043\n",
      "Step 9  Loss: 0.2724195122718811\n",
      "Step 10  Loss: 0.5077541470527649\n",
      "total Loss of epoch  396  is  3.6173134595155716\n",
      "Step 0  Loss: 0.38647574186325073\n",
      "Step 1  Loss: 0.27409452199935913\n",
      "Step 2  Loss: 0.2908991277217865\n",
      "Step 3  Loss: 0.3171907067298889\n",
      "Step 4  Loss: 0.28416910767555237\n",
      "Step 5  Loss: 0.4063483476638794\n",
      "Step 6  Loss: 0.3914440870285034\n",
      "Step 7  Loss: 0.4002007246017456\n",
      "Step 8  Loss: 0.32043901085853577\n",
      "Step 9  Loss: 0.36623311042785645\n",
      "Step 10  Loss: 0.3803558647632599\n",
      "total Loss of epoch  397  is  3.817850351333618\n",
      "Step 0  Loss: 0.27025526762008667\n",
      "Step 1  Loss: 0.33831292390823364\n",
      "Step 2  Loss: 0.33500972390174866\n",
      "Step 3  Loss: 0.34134986996650696\n",
      "Step 4  Loss: 0.4412054121494293\n",
      "Step 5  Loss: 0.28853970766067505\n",
      "Step 6  Loss: 0.28283974528312683\n",
      "Step 7  Loss: 0.3678983449935913\n",
      "Step 8  Loss: 0.4322216510772705\n",
      "Step 9  Loss: 0.3894035220146179\n",
      "Step 10  Loss: 0.43941834568977356\n",
      "total Loss of epoch  398  is  3.9264545142650604\n",
      "Step 0  Loss: 0.26649072766304016\n",
      "Step 1  Loss: 0.350225031375885\n",
      "Step 2  Loss: 0.3351873457431793\n",
      "Step 3  Loss: 0.4574485719203949\n",
      "Step 4  Loss: 0.27896130084991455\n",
      "Step 5  Loss: 0.35802051424980164\n",
      "Step 6  Loss: 0.3644952178001404\n",
      "Step 7  Loss: 0.3665764033794403\n",
      "Step 8  Loss: 0.36507633328437805\n",
      "Step 9  Loss: 0.28823116421699524\n",
      "Step 10  Loss: 0.31708720326423645\n",
      "total Loss of epoch  399  is  3.747799813747406\n",
      "Step 0  Loss: 0.3178543150424957\n",
      "Step 1  Loss: 0.42426928877830505\n",
      "Step 2  Loss: 0.34590965509414673\n",
      "Step 3  Loss: 0.3572208881378174\n",
      "Step 4  Loss: 0.39323028922080994\n",
      "Step 5  Loss: 0.38523346185684204\n",
      "Step 6  Loss: 0.252849280834198\n",
      "Step 7  Loss: 0.3890456557273865\n",
      "Step 8  Loss: 0.36626100540161133\n",
      "Step 9  Loss: 0.43038803339004517\n",
      "Step 10  Loss: 0.46076056361198425\n",
      "total Loss of epoch  400  is  4.123022437095642\n",
      "Step 0  Loss: 0.30434340238571167\n",
      "Step 1  Loss: 0.36485686898231506\n",
      "Step 2  Loss: 0.28825902938842773\n",
      "Step 3  Loss: 0.3555563986301422\n",
      "Step 4  Loss: 0.31855934858322144\n",
      "Step 5  Loss: 0.41031166911125183\n",
      "Step 6  Loss: 0.3567594289779663\n",
      "Step 7  Loss: 0.34941941499710083\n",
      "Step 8  Loss: 0.38356339931488037\n",
      "Step 9  Loss: 0.37692323327064514\n",
      "Step 10  Loss: 0.32511070370674133\n",
      "total Loss of epoch  401  is  3.833662897348404\n",
      "Step 0  Loss: 0.2923663854598999\n",
      "Step 1  Loss: 0.38706618547439575\n",
      "Step 2  Loss: 0.43036410212516785\n",
      "Step 3  Loss: 0.37059253454208374\n",
      "Step 4  Loss: 0.2593561112880707\n",
      "Step 5  Loss: 0.30098235607147217\n",
      "Step 6  Loss: 0.36846134066581726\n",
      "Step 7  Loss: 0.3616265654563904\n",
      "Step 8  Loss: 0.23331065475940704\n",
      "Step 9  Loss: 0.2708541452884674\n",
      "Step 10  Loss: 0.34070590138435364\n",
      "total Loss of epoch  402  is  3.615686282515526\n",
      "Step 0  Loss: 0.3064154088497162\n",
      "Step 1  Loss: 0.3229641616344452\n",
      "Step 2  Loss: 0.45425865054130554\n",
      "Step 3  Loss: 0.3998454809188843\n",
      "Step 4  Loss: 0.3517249822616577\n",
      "Step 5  Loss: 0.34608104825019836\n",
      "Step 6  Loss: 0.3211309313774109\n",
      "Step 7  Loss: 0.2570584714412689\n",
      "Step 8  Loss: 0.3965795934200287\n",
      "Step 9  Loss: 0.3638880252838135\n",
      "Step 10  Loss: 0.5590159296989441\n",
      "total Loss of epoch  403  is  4.078962683677673\n",
      "Step 0  Loss: 0.326582670211792\n",
      "Step 1  Loss: 0.4173065423965454\n",
      "Step 2  Loss: 0.36829525232315063\n",
      "Step 3  Loss: 0.20715412497520447\n",
      "Step 4  Loss: 0.3252636790275574\n",
      "Step 5  Loss: 0.40843304991722107\n",
      "Step 6  Loss: 0.3650117814540863\n",
      "Step 7  Loss: 0.28495272994041443\n",
      "Step 8  Loss: 0.36930182576179504\n",
      "Step 9  Loss: 0.3110935688018799\n",
      "Step 10  Loss: 0.24613504111766815\n",
      "total Loss of epoch  404  is  3.6295302659273148\n",
      "Step 0  Loss: 0.36511653661727905\n",
      "Step 1  Loss: 0.3970869183540344\n",
      "Step 2  Loss: 0.35191094875335693\n",
      "Step 3  Loss: 0.4370875060558319\n",
      "Step 4  Loss: 0.38842087984085083\n",
      "Step 5  Loss: 0.36235031485557556\n",
      "Step 6  Loss: 0.346650093793869\n",
      "Step 7  Loss: 0.40742233395576477\n",
      "Step 8  Loss: 0.3290393352508545\n",
      "Step 9  Loss: 0.4059712290763855\n",
      "Step 10  Loss: 0.2583344876766205\n",
      "total Loss of epoch  405  is  4.049390584230423\n",
      "Step 0  Loss: 0.4034471809864044\n",
      "Step 1  Loss: 0.34674468636512756\n",
      "Step 2  Loss: 0.4569028615951538\n",
      "Step 3  Loss: 0.3491639792919159\n",
      "Step 4  Loss: 0.37230348587036133\n",
      "Step 5  Loss: 0.4813750684261322\n",
      "Step 6  Loss: 0.3355296552181244\n",
      "Step 7  Loss: 0.3579920828342438\n",
      "Step 8  Loss: 0.3266545534133911\n",
      "Step 9  Loss: 0.5218683481216431\n",
      "Step 10  Loss: 0.35689589381217957\n",
      "total Loss of epoch  406  is  4.308877795934677\n",
      "Step 0  Loss: 0.2598934471607208\n",
      "Step 1  Loss: 0.27306872606277466\n",
      "Step 2  Loss: 0.28853222727775574\n",
      "Step 3  Loss: 0.37405890226364136\n",
      "Step 4  Loss: 0.3722282648086548\n",
      "Step 5  Loss: 0.4282882511615753\n",
      "Step 6  Loss: 0.40231892466545105\n",
      "Step 7  Loss: 0.3488304316997528\n",
      "Step 8  Loss: 0.2854022681713104\n",
      "Step 9  Loss: 0.29126104712486267\n",
      "Step 10  Loss: 0.3509223759174347\n",
      "total Loss of epoch  407  is  3.6748048663139343\n",
      "Step 0  Loss: 0.32166436314582825\n",
      "Step 1  Loss: 0.37843549251556396\n",
      "Step 2  Loss: 0.24176812171936035\n",
      "Step 3  Loss: 0.33359190821647644\n",
      "Step 4  Loss: 0.4597663879394531\n",
      "Step 5  Loss: 0.2237977534532547\n",
      "Step 6  Loss: 0.1316230446100235\n",
      "Step 7  Loss: 0.38498517870903015\n",
      "Step 8  Loss: 0.2723329961299896\n",
      "Step 9  Loss: 0.2850724756717682\n",
      "Step 10  Loss: 0.4629630744457245\n",
      "total Loss of epoch  408  is  3.496000796556473\n",
      "Step 0  Loss: 0.3424738943576813\n",
      "Step 1  Loss: 0.3288516402244568\n",
      "Step 2  Loss: 0.38784149289131165\n",
      "Step 3  Loss: 0.4108911156654358\n",
      "Step 4  Loss: 0.3437687158584595\n",
      "Step 5  Loss: 0.3582252860069275\n",
      "Step 6  Loss: 0.4414844214916229\n",
      "Step 7  Loss: 0.3039122521877289\n",
      "Step 8  Loss: 0.3732178807258606\n",
      "Step 9  Loss: 0.3810173273086548\n",
      "Step 10  Loss: 0.32072120904922485\n",
      "total Loss of epoch  409  is  3.9924052357673645\n",
      "Step 0  Loss: 0.23419559001922607\n",
      "Step 1  Loss: 0.37671273946762085\n",
      "Step 2  Loss: 0.3575654923915863\n",
      "Step 3  Loss: 0.3270912766456604\n",
      "Step 4  Loss: 0.3012775480747223\n",
      "Step 5  Loss: 0.2497054487466812\n",
      "Step 6  Loss: 0.39746221899986267\n",
      "Step 7  Loss: 0.30141788721084595\n",
      "Step 8  Loss: 0.2973065972328186\n",
      "Step 9  Loss: 0.408193975687027\n",
      "Step 10  Loss: 0.4096498191356659\n",
      "total Loss of epoch  410  is  3.6605785936117172\n",
      "Step 0  Loss: 0.387211412191391\n",
      "Step 1  Loss: 0.388216495513916\n",
      "Step 2  Loss: 0.44910895824432373\n",
      "Step 3  Loss: 0.28235921263694763\n",
      "Step 4  Loss: 0.34155339002609253\n",
      "Step 5  Loss: 0.3338828384876251\n",
      "Step 6  Loss: 0.3810333013534546\n",
      "Step 7  Loss: 0.30313584208488464\n",
      "Step 8  Loss: 0.40194207429885864\n",
      "Step 9  Loss: 0.3879848122596741\n",
      "Step 10  Loss: 0.38333505392074585\n",
      "total Loss of epoch  411  is  4.039763391017914\n",
      "Step 0  Loss: 0.3022018074989319\n",
      "Step 1  Loss: 0.36222103238105774\n",
      "Step 2  Loss: 0.29978805780410767\n",
      "Step 3  Loss: 0.43742892146110535\n",
      "Step 4  Loss: 0.2828523516654968\n",
      "Step 5  Loss: 0.3433257043361664\n",
      "Step 6  Loss: 0.3843671679496765\n",
      "Step 7  Loss: 0.3288476765155792\n",
      "Step 8  Loss: 0.2826809585094452\n",
      "Step 9  Loss: 0.3360157012939453\n",
      "Step 10  Loss: 0.2872866094112396\n",
      "total Loss of epoch  412  is  3.6470159888267517\n",
      "Step 0  Loss: 0.31111833453178406\n",
      "Step 1  Loss: 0.29887622594833374\n",
      "Step 2  Loss: 0.2958184778690338\n",
      "Step 3  Loss: 0.39740169048309326\n",
      "Step 4  Loss: 0.31933945417404175\n",
      "Step 5  Loss: 0.33136624097824097\n",
      "Step 6  Loss: 0.4699554443359375\n",
      "Step 7  Loss: 0.3197713792324066\n",
      "Step 8  Loss: 0.3480600118637085\n",
      "Step 9  Loss: 0.31462645530700684\n",
      "Step 10  Loss: 0.3617936670780182\n",
      "total Loss of epoch  413  is  3.7681273818016052\n",
      "Step 0  Loss: 0.3793695569038391\n",
      "Step 1  Loss: 0.4231488108634949\n",
      "Step 2  Loss: 0.42327797412872314\n",
      "Step 3  Loss: 0.4302382171154022\n",
      "Step 4  Loss: 0.3834904432296753\n",
      "Step 5  Loss: 0.29686716198921204\n",
      "Step 6  Loss: 0.3494899868965149\n",
      "Step 7  Loss: 0.35121145844459534\n",
      "Step 8  Loss: 0.32544538378715515\n",
      "Step 9  Loss: 0.3675958812236786\n",
      "Step 10  Loss: 0.17813342809677124\n",
      "total Loss of epoch  414  is  3.908268302679062\n",
      "Step 0  Loss: 0.30203378200531006\n",
      "Step 1  Loss: 0.32075947523117065\n",
      "Step 2  Loss: 0.37385648488998413\n",
      "Step 3  Loss: 0.40930065512657166\n",
      "Step 4  Loss: 0.2680145502090454\n",
      "Step 5  Loss: 0.2790589928627014\n",
      "Step 6  Loss: 0.27775177359580994\n",
      "Step 7  Loss: 0.20518159866333008\n",
      "Step 8  Loss: 0.2420143038034439\n",
      "Step 9  Loss: 0.31049132347106934\n",
      "Step 10  Loss: 0.34395313262939453\n",
      "total Loss of epoch  415  is  3.332416072487831\n",
      "Step 0  Loss: 0.2892221510410309\n",
      "Step 1  Loss: 0.2358115017414093\n",
      "Step 2  Loss: 0.38302960991859436\n",
      "Step 3  Loss: 0.3801955282688141\n",
      "Step 4  Loss: 0.23981527984142303\n",
      "Step 5  Loss: 0.2850536108016968\n",
      "Step 6  Loss: 0.31191182136535645\n",
      "Step 7  Loss: 0.3833942115306854\n",
      "Step 8  Loss: 0.3362436592578888\n",
      "Step 9  Loss: 0.3783673644065857\n",
      "Step 10  Loss: 0.31694135069847107\n",
      "total Loss of epoch  416  is  3.539986088871956\n",
      "Step 0  Loss: 0.34418925642967224\n",
      "Step 1  Loss: 0.35522687435150146\n",
      "Step 2  Loss: 0.31689393520355225\n",
      "Step 3  Loss: 0.419015496969223\n",
      "Step 4  Loss: 0.3485979437828064\n",
      "Step 5  Loss: 0.38377809524536133\n",
      "Step 6  Loss: 0.2539616823196411\n",
      "Step 7  Loss: 0.3889840841293335\n",
      "Step 8  Loss: 0.2658396065235138\n",
      "Step 9  Loss: 0.2683238089084625\n",
      "Step 10  Loss: 0.4399208128452301\n",
      "total Loss of epoch  417  is  3.7847315967082977\n",
      "Step 0  Loss: 0.3486871123313904\n",
      "Step 1  Loss: 0.41837915778160095\n",
      "Step 2  Loss: 0.34663042426109314\n",
      "Step 3  Loss: 0.3105383813381195\n",
      "Step 4  Loss: 0.317769318819046\n",
      "Step 5  Loss: 0.4395441710948944\n",
      "Step 6  Loss: 0.354359894990921\n",
      "Step 7  Loss: 0.3928355872631073\n",
      "Step 8  Loss: 0.3695061206817627\n",
      "Step 9  Loss: 0.29377108812332153\n",
      "Step 10  Loss: 0.24971385300159454\n",
      "total Loss of epoch  418  is  3.8417351096868515\n",
      "Step 0  Loss: 0.4286050498485565\n",
      "Step 1  Loss: 0.4416644871234894\n",
      "Step 2  Loss: 0.3242151439189911\n",
      "Step 3  Loss: 0.34589117765426636\n",
      "Step 4  Loss: 0.29732972383499146\n",
      "Step 5  Loss: 0.34568339586257935\n",
      "Step 6  Loss: 0.24701541662216187\n",
      "Step 7  Loss: 0.2993108928203583\n",
      "Step 8  Loss: 0.3415093421936035\n",
      "Step 9  Loss: 0.31489554047584534\n",
      "Step 10  Loss: 0.32774874567985535\n",
      "total Loss of epoch  419  is  3.7138689160346985\n",
      "Step 0  Loss: 0.4052581489086151\n",
      "Step 1  Loss: 0.3269944190979004\n",
      "Step 2  Loss: 0.2978925108909607\n",
      "Step 3  Loss: 0.35436493158340454\n",
      "Step 4  Loss: 0.3851833939552307\n",
      "Step 5  Loss: 0.2833104729652405\n",
      "Step 6  Loss: 0.27537432312965393\n",
      "Step 7  Loss: 0.4661405384540558\n",
      "Step 8  Loss: 0.2500278353691101\n",
      "Step 9  Loss: 0.37286898493766785\n",
      "Step 10  Loss: 0.3636985421180725\n",
      "total Loss of epoch  420  is  3.781114101409912\n",
      "Step 0  Loss: 0.46458739042282104\n",
      "Step 1  Loss: 0.3341042995452881\n",
      "Step 2  Loss: 0.35953834652900696\n",
      "Step 3  Loss: 0.2910468578338623\n",
      "Step 4  Loss: 0.23140479624271393\n",
      "Step 5  Loss: 0.40057024359703064\n",
      "Step 6  Loss: 0.3313281834125519\n",
      "Step 7  Loss: 0.4068397581577301\n",
      "Step 8  Loss: 0.37808936834335327\n",
      "Step 9  Loss: 0.37462425231933594\n",
      "Step 10  Loss: 0.3954445719718933\n",
      "total Loss of epoch  421  is  3.9675780683755875\n",
      "Step 0  Loss: 0.2955332398414612\n",
      "Step 1  Loss: 0.3826345205307007\n",
      "Step 2  Loss: 0.29035651683807373\n",
      "Step 3  Loss: 0.2631426751613617\n",
      "Step 4  Loss: 0.357234925031662\n",
      "Step 5  Loss: 0.3664492070674896\n",
      "Step 6  Loss: 0.3739377558231354\n",
      "Step 7  Loss: 0.3548087179660797\n",
      "Step 8  Loss: 0.30874669551849365\n",
      "Step 9  Loss: 0.2907430827617645\n",
      "Step 10  Loss: 0.5026915669441223\n",
      "total Loss of epoch  422  is  3.7862789034843445\n",
      "Step 0  Loss: 0.38822972774505615\n",
      "Step 1  Loss: 0.3046582341194153\n",
      "Step 2  Loss: 0.3850950300693512\n",
      "Step 3  Loss: 0.38007599115371704\n",
      "Step 4  Loss: 0.3623082935810089\n",
      "Step 5  Loss: 0.39690646529197693\n",
      "Step 6  Loss: 0.399624228477478\n",
      "Step 7  Loss: 0.36382588744163513\n",
      "Step 8  Loss: 0.32795679569244385\n",
      "Step 9  Loss: 0.26303204894065857\n",
      "Step 10  Loss: 0.27380961179733276\n",
      "total Loss of epoch  423  is  3.845522314310074\n",
      "Step 0  Loss: 0.2768479585647583\n",
      "Step 1  Loss: 0.36044201254844666\n",
      "Step 2  Loss: 0.37667909264564514\n",
      "Step 3  Loss: 0.4146105945110321\n",
      "Step 4  Loss: 0.4372667968273163\n",
      "Step 5  Loss: 0.2909230589866638\n",
      "Step 6  Loss: 0.3060382604598999\n",
      "Step 7  Loss: 0.4286825656890869\n",
      "Step 8  Loss: 0.3692720830440521\n",
      "Step 9  Loss: 0.42365002632141113\n",
      "Step 10  Loss: 0.23079922795295715\n",
      "total Loss of epoch  424  is  3.9152116775512695\n",
      "Step 0  Loss: 0.32653459906578064\n",
      "Step 1  Loss: 0.3402167856693268\n",
      "Step 2  Loss: 0.33971643447875977\n",
      "Step 3  Loss: 0.42202433943748474\n",
      "Step 4  Loss: 0.41905122995376587\n",
      "Step 5  Loss: 0.4404906928539276\n",
      "Step 6  Loss: 0.2875325083732605\n",
      "Step 7  Loss: 0.3265283703804016\n",
      "Step 8  Loss: 0.4011358320713043\n",
      "Step 9  Loss: 0.43750685453414917\n",
      "Step 10  Loss: 0.3385586440563202\n",
      "total Loss of epoch  425  is  4.079296290874481\n",
      "Step 0  Loss: 0.3301205635070801\n",
      "Step 1  Loss: 0.3369706869125366\n",
      "Step 2  Loss: 0.32277393341064453\n",
      "Step 3  Loss: 0.29711395502090454\n",
      "Step 4  Loss: 0.29452458024024963\n",
      "Step 5  Loss: 0.3418461084365845\n",
      "Step 6  Loss: 0.34501537680625916\n",
      "Step 7  Loss: 0.3693820536136627\n",
      "Step 8  Loss: 0.30558934807777405\n",
      "Step 9  Loss: 0.41323789954185486\n",
      "Step 10  Loss: 0.4798455536365509\n",
      "total Loss of epoch  426  is  3.8364200592041016\n",
      "Step 0  Loss: 0.3799314498901367\n",
      "Step 1  Loss: 0.33801940083503723\n",
      "Step 2  Loss: 0.40784454345703125\n",
      "Step 3  Loss: 0.355918288230896\n",
      "Step 4  Loss: 0.27018094062805176\n",
      "Step 5  Loss: 0.3052675426006317\n",
      "Step 6  Loss: 0.3569256365299225\n",
      "Step 7  Loss: 0.3109847605228424\n",
      "Step 8  Loss: 0.3675042390823364\n",
      "Step 9  Loss: 0.28246065974235535\n",
      "Step 10  Loss: 0.4140041172504425\n",
      "total Loss of epoch  427  is  3.789041578769684\n",
      "Step 0  Loss: 0.18859216570854187\n",
      "Step 1  Loss: 0.38650521636009216\n",
      "Step 2  Loss: 0.30376511812210083\n",
      "Step 3  Loss: 0.2356945276260376\n",
      "Step 4  Loss: 0.4655599892139435\n",
      "Step 5  Loss: 0.3530034124851227\n",
      "Step 6  Loss: 0.29032114148139954\n",
      "Step 7  Loss: 0.41925105452537537\n",
      "Step 8  Loss: 0.40353983640670776\n",
      "Step 9  Loss: 0.3413617014884949\n",
      "Step 10  Loss: 0.2581266462802887\n",
      "total Loss of epoch  428  is  3.645720809698105\n",
      "Step 0  Loss: 0.1841825693845749\n",
      "Step 1  Loss: 0.36386826634407043\n",
      "Step 2  Loss: 0.2845183312892914\n",
      "Step 3  Loss: 0.28471580147743225\n",
      "Step 4  Loss: 0.34006887674331665\n",
      "Step 5  Loss: 0.42320603132247925\n",
      "Step 6  Loss: 0.24512405693531036\n",
      "Step 7  Loss: 0.3083718717098236\n",
      "Step 8  Loss: 0.34055015444755554\n",
      "Step 9  Loss: 0.3610326051712036\n",
      "Step 10  Loss: 0.4216775894165039\n",
      "total Loss of epoch  429  is  3.557316154241562\n",
      "Step 0  Loss: 0.36760467290878296\n",
      "Step 1  Loss: 0.3495451509952545\n",
      "Step 2  Loss: 0.3705330491065979\n",
      "Step 3  Loss: 0.3216369152069092\n",
      "Step 4  Loss: 0.31486842036247253\n",
      "Step 5  Loss: 0.37855619192123413\n",
      "Step 6  Loss: 0.2955678403377533\n",
      "Step 7  Loss: 0.3699840307235718\n",
      "Step 8  Loss: 0.35349971055984497\n",
      "Step 9  Loss: 0.4041936695575714\n",
      "Step 10  Loss: 0.34427887201309204\n",
      "total Loss of epoch  430  is  3.8702685236930847\n",
      "Step 0  Loss: 0.27148109674453735\n",
      "Step 1  Loss: 0.3404447138309479\n",
      "Step 2  Loss: 0.3851008713245392\n",
      "Step 3  Loss: 0.3787885308265686\n",
      "Step 4  Loss: 0.28995680809020996\n",
      "Step 5  Loss: 0.46877145767211914\n",
      "Step 6  Loss: 0.45763522386550903\n",
      "Step 7  Loss: 0.4331805408000946\n",
      "Step 8  Loss: 0.5193560719490051\n",
      "Step 9  Loss: 0.4470210373401642\n",
      "Step 10  Loss: 0.21374551951885223\n",
      "total Loss of epoch  431  is  4.205481871962547\n",
      "Step 0  Loss: 0.3376627564430237\n",
      "Step 1  Loss: 0.4004152715206146\n",
      "Step 2  Loss: 0.3156221807003021\n",
      "Step 3  Loss: 0.32033586502075195\n",
      "Step 4  Loss: 0.40189284086227417\n",
      "Step 5  Loss: 0.22316133975982666\n",
      "Step 6  Loss: 0.2408199906349182\n",
      "Step 7  Loss: 0.4071427285671234\n",
      "Step 8  Loss: 0.32181182503700256\n",
      "Step 9  Loss: 0.3395024836063385\n",
      "Step 10  Loss: 0.45695605874061584\n",
      "total Loss of epoch  432  is  3.7653233408927917\n",
      "Step 0  Loss: 0.3731309771537781\n",
      "Step 1  Loss: 0.2749646008014679\n",
      "Step 2  Loss: 0.3075915277004242\n",
      "Step 3  Loss: 0.330191969871521\n",
      "Step 4  Loss: 0.3446787893772125\n",
      "Step 5  Loss: 0.4509647488594055\n",
      "Step 6  Loss: 0.3895629644393921\n",
      "Step 7  Loss: 0.4222709536552429\n",
      "Step 8  Loss: 0.38362812995910645\n",
      "Step 9  Loss: 0.38801437616348267\n",
      "Step 10  Loss: 0.3628450334072113\n",
      "total Loss of epoch  433  is  4.027844071388245\n",
      "Step 0  Loss: 0.3196394145488739\n",
      "Step 1  Loss: 0.3734903335571289\n",
      "Step 2  Loss: 0.2915497124195099\n",
      "Step 3  Loss: 0.3187512159347534\n",
      "Step 4  Loss: 0.3633847236633301\n",
      "Step 5  Loss: 0.42345693707466125\n",
      "Step 6  Loss: 0.3329107165336609\n",
      "Step 7  Loss: 0.35234010219573975\n",
      "Step 8  Loss: 0.31963205337524414\n",
      "Step 9  Loss: 0.19324038922786713\n",
      "Step 10  Loss: 0.40183794498443604\n",
      "total Loss of epoch  434  is  3.6902335435152054\n",
      "Step 0  Loss: 0.39888495206832886\n",
      "Step 1  Loss: 0.3403487801551819\n",
      "Step 2  Loss: 0.44220560789108276\n",
      "Step 3  Loss: 0.4231671392917633\n",
      "Step 4  Loss: 0.3513336181640625\n",
      "Step 5  Loss: 0.3727740943431854\n",
      "Step 6  Loss: 0.4524909555912018\n",
      "Step 7  Loss: 0.375620037317276\n",
      "Step 8  Loss: 0.2742881178855896\n",
      "Step 9  Loss: 0.4294866621494293\n",
      "Step 10  Loss: 0.39487412571907043\n",
      "total Loss of epoch  435  is  4.255474090576172\n",
      "Step 0  Loss: 0.3467104732990265\n",
      "Step 1  Loss: 0.379187673330307\n",
      "Step 2  Loss: 0.34505221247673035\n",
      "Step 3  Loss: 0.32730215787887573\n",
      "Step 4  Loss: 0.31173187494277954\n",
      "Step 5  Loss: 0.3156324028968811\n",
      "Step 6  Loss: 0.25559407472610474\n",
      "Step 7  Loss: 0.31467339396476746\n",
      "Step 8  Loss: 0.34514307975769043\n",
      "Step 9  Loss: 0.40243470668792725\n",
      "Step 10  Loss: 0.28834328055381775\n",
      "total Loss of epoch  436  is  3.631805330514908\n",
      "Step 0  Loss: 0.38540077209472656\n",
      "Step 1  Loss: 0.4600397050380707\n",
      "Step 2  Loss: 0.3057149350643158\n",
      "Step 3  Loss: 0.33443328738212585\n",
      "Step 4  Loss: 0.3149150311946869\n",
      "Step 5  Loss: 0.4306083619594574\n",
      "Step 6  Loss: 0.32738858461380005\n",
      "Step 7  Loss: 0.3984028100967407\n",
      "Step 8  Loss: 0.3858695328235626\n",
      "Step 9  Loss: 0.421735554933548\n",
      "Step 10  Loss: 0.38769641518592834\n",
      "total Loss of epoch  437  is  4.152204990386963\n",
      "Step 0  Loss: 0.4195975959300995\n",
      "Step 1  Loss: 0.46636924147605896\n",
      "Step 2  Loss: 0.39196380972862244\n",
      "Step 3  Loss: 0.4240932762622833\n",
      "Step 4  Loss: 0.29106733202934265\n",
      "Step 5  Loss: 0.3230127990245819\n",
      "Step 6  Loss: 0.44027575850486755\n",
      "Step 7  Loss: 0.3469795882701874\n",
      "Step 8  Loss: 0.3095031678676605\n",
      "Step 9  Loss: 0.3263256549835205\n",
      "Step 10  Loss: 0.2605137228965759\n",
      "total Loss of epoch  438  is  3.9997019469738007\n",
      "Step 0  Loss: 0.3191796541213989\n",
      "Step 1  Loss: 0.32585620880126953\n",
      "Step 2  Loss: 0.2192152440547943\n",
      "Step 3  Loss: 0.3688298463821411\n",
      "Step 4  Loss: 0.2694184482097626\n",
      "Step 5  Loss: 0.33334794640541077\n",
      "Step 6  Loss: 0.1851770430803299\n",
      "Step 7  Loss: 0.44276729226112366\n",
      "Step 8  Loss: 0.38692912459373474\n",
      "Step 9  Loss: 0.34244418144226074\n",
      "Step 10  Loss: 0.376444935798645\n",
      "total Loss of epoch  439  is  3.5696099251508713\n",
      "Step 0  Loss: 0.3927030861377716\n",
      "Step 1  Loss: 0.3415515422821045\n",
      "Step 2  Loss: 0.3401203155517578\n",
      "Step 3  Loss: 0.35671818256378174\n",
      "Step 4  Loss: 0.3604455292224884\n",
      "Step 5  Loss: 0.3365512192249298\n",
      "Step 6  Loss: 0.292054682970047\n",
      "Step 7  Loss: 0.35799872875213623\n",
      "Step 8  Loss: 0.4122886657714844\n",
      "Step 9  Loss: 0.3292522132396698\n",
      "Step 10  Loss: 0.30054405331611633\n",
      "total Loss of epoch  440  is  3.8202282190322876\n",
      "Step 0  Loss: 0.360600084066391\n",
      "Step 1  Loss: 0.31172093749046326\n",
      "Step 2  Loss: 0.36132457852363586\n",
      "Step 3  Loss: 0.429117888212204\n",
      "Step 4  Loss: 0.31495141983032227\n",
      "Step 5  Loss: 0.2791120111942291\n",
      "Step 6  Loss: 0.2795315384864807\n",
      "Step 7  Loss: 0.26384177803993225\n",
      "Step 8  Loss: 0.39443179965019226\n",
      "Step 9  Loss: 0.40522539615631104\n",
      "Step 10  Loss: 0.2765099108219147\n",
      "total Loss of epoch  441  is  3.6763673424720764\n",
      "Step 0  Loss: 0.3139224350452423\n",
      "Step 1  Loss: 0.39776891469955444\n",
      "Step 2  Loss: 0.4762286841869354\n",
      "Step 3  Loss: 0.3820864260196686\n",
      "Step 4  Loss: 0.25524258613586426\n",
      "Step 5  Loss: 0.38420161604881287\n",
      "Step 6  Loss: 0.3607294261455536\n",
      "Step 7  Loss: 0.5102465152740479\n",
      "Step 8  Loss: 0.361369788646698\n",
      "Step 9  Loss: 0.3081597685813904\n",
      "Step 10  Loss: 0.3018111288547516\n",
      "total Loss of epoch  442  is  4.051767289638519\n",
      "Step 0  Loss: 0.3837699890136719\n",
      "Step 1  Loss: 0.3468201756477356\n",
      "Step 2  Loss: 0.39321187138557434\n",
      "Step 3  Loss: 0.42111852765083313\n",
      "Step 4  Loss: 0.2679170072078705\n",
      "Step 5  Loss: 0.3964287042617798\n",
      "Step 6  Loss: 0.4290042221546173\n",
      "Step 7  Loss: 0.3136966824531555\n",
      "Step 8  Loss: 0.2753194272518158\n",
      "Step 9  Loss: 0.3945629596710205\n",
      "Step 10  Loss: 0.45032596588134766\n",
      "total Loss of epoch  443  is  4.072175532579422\n",
      "Step 0  Loss: 0.3371446132659912\n",
      "Step 1  Loss: 0.2939899265766144\n",
      "Step 2  Loss: 0.25711607933044434\n",
      "Step 3  Loss: 0.3418803811073303\n",
      "Step 4  Loss: 0.3112356960773468\n",
      "Step 5  Loss: 0.36210495233535767\n",
      "Step 6  Loss: 0.2996852993965149\n",
      "Step 7  Loss: 0.323110431432724\n",
      "Step 8  Loss: 0.2690110504627228\n",
      "Step 9  Loss: 0.36340847611427307\n",
      "Step 10  Loss: 0.32564255595207214\n",
      "total Loss of epoch  444  is  3.4843294620513916\n",
      "Step 0  Loss: 0.3787536919116974\n",
      "Step 1  Loss: 0.34651175141334534\n",
      "Step 2  Loss: 0.3150594234466553\n",
      "Step 3  Loss: 0.4555150270462036\n",
      "Step 4  Loss: 0.33258429169654846\n",
      "Step 5  Loss: 0.3498508334159851\n",
      "Step 6  Loss: 0.41329890489578247\n",
      "Step 7  Loss: 0.31389719247817993\n",
      "Step 8  Loss: 0.3495595455169678\n",
      "Step 9  Loss: 0.48457109928131104\n",
      "Step 10  Loss: 0.3497433364391327\n",
      "total Loss of epoch  445  is  4.089345097541809\n",
      "Step 0  Loss: 0.30113568902015686\n",
      "Step 1  Loss: 0.35551029443740845\n",
      "Step 2  Loss: 0.29646047949790955\n",
      "Step 3  Loss: 0.34545645117759705\n",
      "Step 4  Loss: 0.4333968460559845\n",
      "Step 5  Loss: 0.3206748068332672\n",
      "Step 6  Loss: 0.34120216965675354\n",
      "Step 7  Loss: 0.28012001514434814\n",
      "Step 8  Loss: 0.24406595528125763\n",
      "Step 9  Loss: 0.4124574065208435\n",
      "Step 10  Loss: 0.2815987169742584\n",
      "total Loss of epoch  446  is  3.612078830599785\n",
      "Step 0  Loss: 0.3514758050441742\n",
      "Step 1  Loss: 0.3404988944530487\n",
      "Step 2  Loss: 0.37314462661743164\n",
      "Step 3  Loss: 0.3411208987236023\n",
      "Step 4  Loss: 0.3944258987903595\n",
      "Step 5  Loss: 0.44576960802078247\n",
      "Step 6  Loss: 0.3833783268928528\n",
      "Step 7  Loss: 0.3158458173274994\n",
      "Step 8  Loss: 0.38014695048332214\n",
      "Step 9  Loss: 0.29058489203453064\n",
      "Step 10  Loss: 0.2750326693058014\n",
      "total Loss of epoch  447  is  3.891424387693405\n",
      "Step 0  Loss: 0.35871800780296326\n",
      "Step 1  Loss: 0.30641674995422363\n",
      "Step 2  Loss: 0.36818233132362366\n",
      "Step 3  Loss: 0.24035443365573883\n",
      "Step 4  Loss: 0.38328641653060913\n",
      "Step 5  Loss: 0.4909186065196991\n",
      "Step 6  Loss: 0.21521984040737152\n",
      "Step 7  Loss: 0.24182118475437164\n",
      "Step 8  Loss: 0.33239614963531494\n",
      "Step 9  Loss: 0.36434611678123474\n",
      "Step 10  Loss: 0.3760068416595459\n",
      "total Loss of epoch  448  is  3.6776666790246964\n",
      "Step 0  Loss: 0.2750126123428345\n",
      "Step 1  Loss: 0.40794214606285095\n",
      "Step 2  Loss: 0.3259042501449585\n",
      "Step 3  Loss: 0.4035404920578003\n",
      "Step 4  Loss: 0.3695220649242401\n",
      "Step 5  Loss: 0.344939261674881\n",
      "Step 6  Loss: 0.42783665657043457\n",
      "Step 7  Loss: 0.2800620496273041\n",
      "Step 8  Loss: 0.3754998743534088\n",
      "Step 9  Loss: 0.3687646985054016\n",
      "Step 10  Loss: 0.3212262690067291\n",
      "total Loss of epoch  449  is  3.9002503752708435\n",
      "Step 0  Loss: 0.3857921361923218\n",
      "Step 1  Loss: 0.4630851447582245\n",
      "Step 2  Loss: 0.22917714715003967\n",
      "Step 3  Loss: 0.37303394079208374\n",
      "Step 4  Loss: 0.36973127722740173\n",
      "Step 5  Loss: 0.30442729592323303\n",
      "Step 6  Loss: 0.4679071605205536\n",
      "Step 7  Loss: 0.39404699206352234\n",
      "Step 8  Loss: 0.4007168114185333\n",
      "Step 9  Loss: 0.393023282289505\n",
      "Step 10  Loss: 0.4975891709327698\n",
      "total Loss of epoch  450  is  4.2785303592681885\n",
      "Step 0  Loss: 0.3081532418727875\n",
      "Step 1  Loss: 0.46813011169433594\n",
      "Step 2  Loss: 0.3314287066459656\n",
      "Step 3  Loss: 0.3529365062713623\n",
      "Step 4  Loss: 0.33936822414398193\n",
      "Step 5  Loss: 0.18295401334762573\n",
      "Step 6  Loss: 0.26625490188598633\n",
      "Step 7  Loss: 0.3642841577529907\n",
      "Step 8  Loss: 0.31152647733688354\n",
      "Step 9  Loss: 0.4132069945335388\n",
      "Step 10  Loss: 0.39391636848449707\n",
      "total Loss of epoch  451  is  3.7321597039699554\n",
      "Step 0  Loss: 0.4646218419075012\n",
      "Step 1  Loss: 0.28245264291763306\n",
      "Step 2  Loss: 0.28197336196899414\n",
      "Step 3  Loss: 0.23139016330242157\n",
      "Step 4  Loss: 0.2871348261833191\n",
      "Step 5  Loss: 0.3318878412246704\n",
      "Step 6  Loss: 0.35118329524993896\n",
      "Step 7  Loss: 0.34742966294288635\n",
      "Step 8  Loss: 0.3245472311973572\n",
      "Step 9  Loss: 0.2675967514514923\n",
      "Step 10  Loss: 0.4319794774055481\n",
      "total Loss of epoch  452  is  3.6021970957517624\n",
      "Step 0  Loss: 0.36529991030693054\n",
      "Step 1  Loss: 0.2583453953266144\n",
      "Step 2  Loss: 0.3974023461341858\n",
      "Step 3  Loss: 0.31335005164146423\n",
      "Step 4  Loss: 0.3718003034591675\n",
      "Step 5  Loss: 0.28124549984931946\n",
      "Step 6  Loss: 0.34922972321510315\n",
      "Step 7  Loss: 0.3224957585334778\n",
      "Step 8  Loss: 0.3952814042568207\n",
      "Step 9  Loss: 0.3930194675922394\n",
      "Step 10  Loss: 0.22386029362678528\n",
      "total Loss of epoch  453  is  3.671330153942108\n",
      "Step 0  Loss: 0.3251343369483948\n",
      "Step 1  Loss: 0.43597856163978577\n",
      "Step 2  Loss: 0.4240472614765167\n",
      "Step 3  Loss: 0.2641919255256653\n",
      "Step 4  Loss: 0.33768022060394287\n",
      "Step 5  Loss: 0.3350474536418915\n",
      "Step 6  Loss: 0.5182898640632629\n",
      "Step 7  Loss: 0.3596416115760803\n",
      "Step 8  Loss: 0.3293496370315552\n",
      "Step 9  Loss: 0.42233213782310486\n",
      "Step 10  Loss: 0.34668776392936707\n",
      "total Loss of epoch  454  is  4.098380774259567\n",
      "Step 0  Loss: 0.38557443022727966\n",
      "Step 1  Loss: 0.3642829358577728\n",
      "Step 2  Loss: 0.32870638370513916\n",
      "Step 3  Loss: 0.31630682945251465\n",
      "Step 4  Loss: 0.2583920955657959\n",
      "Step 5  Loss: 0.3682595491409302\n",
      "Step 6  Loss: 0.43445268273353577\n",
      "Step 7  Loss: 0.4528217911720276\n",
      "Step 8  Loss: 0.34735268354415894\n",
      "Step 9  Loss: 0.441782683134079\n",
      "Step 10  Loss: 0.40781548619270325\n",
      "total Loss of epoch  455  is  4.105747550725937\n",
      "Step 0  Loss: 0.35935571789741516\n",
      "Step 1  Loss: 0.3763057291507721\n",
      "Step 2  Loss: 0.3683395981788635\n",
      "Step 3  Loss: 0.2997741103172302\n",
      "Step 4  Loss: 0.3187060058116913\n",
      "Step 5  Loss: 0.27391165494918823\n",
      "Step 6  Loss: 0.434572696685791\n",
      "Step 7  Loss: 0.3317256271839142\n",
      "Step 8  Loss: 0.4875755310058594\n",
      "Step 9  Loss: 0.391383558511734\n",
      "Step 10  Loss: 0.32008108496665955\n",
      "total Loss of epoch  456  is  3.9617313146591187\n",
      "Step 0  Loss: 0.3101193904876709\n",
      "Step 1  Loss: 0.3046590983867645\n",
      "Step 2  Loss: 0.3790373206138611\n",
      "Step 3  Loss: 0.3080389201641083\n",
      "Step 4  Loss: 0.3672913908958435\n",
      "Step 5  Loss: 0.3979613482952118\n",
      "Step 6  Loss: 0.33241742849349976\n",
      "Step 7  Loss: 0.3446906805038452\n",
      "Step 8  Loss: 0.3347182869911194\n",
      "Step 9  Loss: 0.3591044247150421\n",
      "Step 10  Loss: 0.3458794355392456\n",
      "total Loss of epoch  457  is  3.783917725086212\n",
      "Step 0  Loss: 0.38333624601364136\n",
      "Step 1  Loss: 0.38471296429634094\n",
      "Step 2  Loss: 0.3197430670261383\n",
      "Step 3  Loss: 0.3246154487133026\n",
      "Step 4  Loss: 0.3407721221446991\n",
      "Step 5  Loss: 0.398395299911499\n",
      "Step 6  Loss: 0.30025362968444824\n",
      "Step 7  Loss: 0.34534695744514465\n",
      "Step 8  Loss: 0.31386256217956543\n",
      "Step 9  Loss: 0.361331582069397\n",
      "Step 10  Loss: 0.3809806704521179\n",
      "total Loss of epoch  458  is  3.8533505499362946\n",
      "Step 0  Loss: 0.29764628410339355\n",
      "Step 1  Loss: 0.33991172909736633\n",
      "Step 2  Loss: 0.33805811405181885\n",
      "Step 3  Loss: 0.3015044629573822\n",
      "Step 4  Loss: 0.41710686683654785\n",
      "Step 5  Loss: 0.4896089434623718\n",
      "Step 6  Loss: 0.3352871537208557\n",
      "Step 7  Loss: 0.3513157069683075\n",
      "Step 8  Loss: 0.447799950838089\n",
      "Step 9  Loss: 0.3898424804210663\n",
      "Step 10  Loss: 0.4236428141593933\n",
      "total Loss of epoch  459  is  4.131724506616592\n",
      "Step 0  Loss: 0.37176457047462463\n",
      "Step 1  Loss: 0.3209281265735626\n",
      "Step 2  Loss: 0.38737937808036804\n",
      "Step 3  Loss: 0.4664694368839264\n",
      "Step 4  Loss: 0.41774415969848633\n",
      "Step 5  Loss: 0.33631521463394165\n",
      "Step 6  Loss: 0.2614167332649231\n",
      "Step 7  Loss: 0.2981363832950592\n",
      "Step 8  Loss: 0.356786847114563\n",
      "Step 9  Loss: 0.3524331748485565\n",
      "Step 10  Loss: 0.510718584060669\n",
      "total Loss of epoch  460  is  4.08009260892868\n",
      "Step 0  Loss: 0.3146432638168335\n",
      "Step 1  Loss: 0.3770803213119507\n",
      "Step 2  Loss: 0.2239151895046234\n",
      "Step 3  Loss: 0.3580784499645233\n",
      "Step 4  Loss: 0.3779754042625427\n",
      "Step 5  Loss: 0.31777989864349365\n",
      "Step 6  Loss: 0.2889587879180908\n",
      "Step 7  Loss: 0.411679744720459\n",
      "Step 8  Loss: 0.2282337099313736\n",
      "Step 9  Loss: 0.3668002188205719\n",
      "Step 10  Loss: 0.34929823875427246\n",
      "total Loss of epoch  461  is  3.614443227648735\n",
      "Step 0  Loss: 0.2869599461555481\n",
      "Step 1  Loss: 0.2957819998264313\n",
      "Step 2  Loss: 0.35149168968200684\n",
      "Step 3  Loss: 0.26573681831359863\n",
      "Step 4  Loss: 0.42427802085876465\n",
      "Step 5  Loss: 0.26377445459365845\n",
      "Step 6  Loss: 0.3496380150318146\n",
      "Step 7  Loss: 0.2574518024921417\n",
      "Step 8  Loss: 0.36168423295021057\n",
      "Step 9  Loss: 0.3057766556739807\n",
      "Step 10  Loss: 0.3013986051082611\n",
      "total Loss of epoch  462  is  3.4639722406864166\n",
      "Step 0  Loss: 0.3141014575958252\n",
      "Step 1  Loss: 0.33389654755592346\n",
      "Step 2  Loss: 0.418075293302536\n",
      "Step 3  Loss: 0.3243884742259979\n",
      "Step 4  Loss: 0.2803422808647156\n",
      "Step 5  Loss: 0.3751937747001648\n",
      "Step 6  Loss: 0.3549845218658447\n",
      "Step 7  Loss: 0.34156954288482666\n",
      "Step 8  Loss: 0.3210222125053406\n",
      "Step 9  Loss: 0.371061772108078\n",
      "Step 10  Loss: 0.42170774936676025\n",
      "total Loss of epoch  463  is  3.856343626976013\n",
      "Step 0  Loss: 0.27868539094924927\n",
      "Step 1  Loss: 0.4320354163646698\n",
      "Step 2  Loss: 0.48687291145324707\n",
      "Step 3  Loss: 0.2965272068977356\n",
      "Step 4  Loss: 0.34852728247642517\n",
      "Step 5  Loss: 0.4871149957180023\n",
      "Step 6  Loss: 0.1992277204990387\n",
      "Step 7  Loss: 0.31790611147880554\n",
      "Step 8  Loss: 0.3765060305595398\n",
      "Step 9  Loss: 0.30389493703842163\n",
      "Step 10  Loss: 0.2587127089500427\n",
      "total Loss of epoch  464  is  3.7860107123851776\n",
      "Step 0  Loss: 0.39215588569641113\n",
      "Step 1  Loss: 0.22823068499565125\n",
      "Step 2  Loss: 0.33166757225990295\n",
      "Step 3  Loss: 0.3676755428314209\n",
      "Step 4  Loss: 0.2517850399017334\n",
      "Step 5  Loss: 0.3336242437362671\n",
      "Step 6  Loss: 0.20358826220035553\n",
      "Step 7  Loss: 0.3105368912220001\n",
      "Step 8  Loss: 0.31085288524627686\n",
      "Step 9  Loss: 0.24750567972660065\n",
      "Step 10  Loss: 0.37121647596359253\n",
      "total Loss of epoch  465  is  3.3488391637802124\n",
      "Step 0  Loss: 0.33055946230888367\n",
      "Step 1  Loss: 0.38137462735176086\n",
      "Step 2  Loss: 0.3328722417354584\n",
      "Step 3  Loss: 0.3876186013221741\n",
      "Step 4  Loss: 0.3019612431526184\n",
      "Step 5  Loss: 0.3486686944961548\n",
      "Step 6  Loss: 0.3283975124359131\n",
      "Step 7  Loss: 0.37558260560035706\n",
      "Step 8  Loss: 0.43421122431755066\n",
      "Step 9  Loss: 0.36721423268318176\n",
      "Step 10  Loss: 0.386463463306427\n",
      "total Loss of epoch  466  is  3.9749239087104797\n",
      "Step 0  Loss: 0.4219655692577362\n",
      "Step 1  Loss: 0.33260685205459595\n",
      "Step 2  Loss: 0.33746427297592163\n",
      "Step 3  Loss: 0.4059799909591675\n",
      "Step 4  Loss: 0.32303985953330994\n",
      "Step 5  Loss: 0.23488111793994904\n",
      "Step 6  Loss: 0.279293417930603\n",
      "Step 7  Loss: 0.41801756620407104\n",
      "Step 8  Loss: 0.22921352088451385\n",
      "Step 9  Loss: 0.44690102338790894\n",
      "Step 10  Loss: 0.43229103088378906\n",
      "total Loss of epoch  467  is  3.861654222011566\n",
      "Step 0  Loss: 0.2454853653907776\n",
      "Step 1  Loss: 0.3692554235458374\n",
      "Step 2  Loss: 0.389510840177536\n",
      "Step 3  Loss: 0.2791813611984253\n",
      "Step 4  Loss: 0.4678908884525299\n",
      "Step 5  Loss: 0.5064772367477417\n",
      "Step 6  Loss: 0.3022281527519226\n",
      "Step 7  Loss: 0.28464189171791077\n",
      "Step 8  Loss: 0.31258389353752136\n",
      "Step 9  Loss: 0.4321824312210083\n",
      "Step 10  Loss: 0.26970598101615906\n",
      "total Loss of epoch  468  is  3.85914346575737\n",
      "Step 0  Loss: 0.4139632284641266\n",
      "Step 1  Loss: 0.41219010949134827\n",
      "Step 2  Loss: 0.35972803831100464\n",
      "Step 3  Loss: 0.41226667165756226\n",
      "Step 4  Loss: 0.287014901638031\n",
      "Step 5  Loss: 0.48126354813575745\n",
      "Step 6  Loss: 0.34331777691841125\n",
      "Step 7  Loss: 0.4367476999759674\n",
      "Step 8  Loss: 0.3936471939086914\n",
      "Step 9  Loss: 0.4744237959384918\n",
      "Step 10  Loss: 0.29482465982437134\n",
      "total Loss of epoch  469  is  4.309387624263763\n",
      "Step 0  Loss: 0.4418540894985199\n",
      "Step 1  Loss: 0.4141380786895752\n",
      "Step 2  Loss: 0.1981532722711563\n",
      "Step 3  Loss: 0.33095088601112366\n",
      "Step 4  Loss: 0.3012349605560303\n",
      "Step 5  Loss: 0.40271657705307007\n",
      "Step 6  Loss: 0.3676295280456543\n",
      "Step 7  Loss: 0.23986247181892395\n",
      "Step 8  Loss: 0.33644580841064453\n",
      "Step 9  Loss: 0.34037113189697266\n",
      "Step 10  Loss: 0.35387709736824036\n",
      "total Loss of epoch  470  is  3.727233901619911\n",
      "Step 0  Loss: 0.34103405475616455\n",
      "Step 1  Loss: 0.471833735704422\n",
      "Step 2  Loss: 0.31131821870803833\n",
      "Step 3  Loss: 0.4124376177787781\n",
      "Step 4  Loss: 0.4807274341583252\n",
      "Step 5  Loss: 0.2195809930562973\n",
      "Step 6  Loss: 0.3196773827075958\n",
      "Step 7  Loss: 0.4124664068222046\n",
      "Step 8  Loss: 0.3667142987251282\n",
      "Step 9  Loss: 0.3446711301803589\n",
      "Step 10  Loss: 0.3682762384414673\n",
      "total Loss of epoch  471  is  4.04873751103878\n",
      "Step 0  Loss: 0.40037888288497925\n",
      "Step 1  Loss: 0.3221954107284546\n",
      "Step 2  Loss: 0.2830931544303894\n",
      "Step 3  Loss: 0.2610990107059479\n",
      "Step 4  Loss: 0.2540930211544037\n",
      "Step 5  Loss: 0.28465932607650757\n",
      "Step 6  Loss: 0.2455148547887802\n",
      "Step 7  Loss: 0.3205011785030365\n",
      "Step 8  Loss: 0.2754581570625305\n",
      "Step 9  Loss: 0.3057957589626312\n",
      "Step 10  Loss: 0.3954913020133972\n",
      "total Loss of epoch  472  is  3.348280057311058\n",
      "Step 0  Loss: 0.36315175890922546\n",
      "Step 1  Loss: 0.2667137384414673\n",
      "Step 2  Loss: 0.25501149892807007\n",
      "Step 3  Loss: 0.31619182229042053\n",
      "Step 4  Loss: 0.3103295564651489\n",
      "Step 5  Loss: 0.349793016910553\n",
      "Step 6  Loss: 0.262664258480072\n",
      "Step 7  Loss: 0.3445124328136444\n",
      "Step 8  Loss: 0.38544923067092896\n",
      "Step 9  Loss: 0.2816145718097687\n",
      "Step 10  Loss: 0.3954630494117737\n",
      "total Loss of epoch  473  is  3.530894935131073\n",
      "Step 0  Loss: 0.41281870007514954\n",
      "Step 1  Loss: 0.39320918917655945\n",
      "Step 2  Loss: 0.31455039978027344\n",
      "Step 3  Loss: 0.38256749510765076\n",
      "Step 4  Loss: 0.4416602849960327\n",
      "Step 5  Loss: 0.19586075842380524\n",
      "Step 6  Loss: 0.3267620801925659\n",
      "Step 7  Loss: 0.29327091574668884\n",
      "Step 8  Loss: 0.4397740960121155\n",
      "Step 9  Loss: 0.5114348530769348\n",
      "Step 10  Loss: 0.2805310785770416\n",
      "total Loss of epoch  474  is  3.992439851164818\n",
      "Step 0  Loss: 0.3059593439102173\n",
      "Step 1  Loss: 0.3496522605419159\n",
      "Step 2  Loss: 0.3332195580005646\n",
      "Step 3  Loss: 0.37925994396209717\n",
      "Step 4  Loss: 0.27563461661338806\n",
      "Step 5  Loss: 0.42507049441337585\n",
      "Step 6  Loss: 0.37541908025741577\n",
      "Step 7  Loss: 0.37984880805015564\n",
      "Step 8  Loss: 0.3518649935722351\n",
      "Step 9  Loss: 0.44632402062416077\n",
      "Step 10  Loss: 0.5468098521232605\n",
      "total Loss of epoch  475  is  4.169062972068787\n",
      "Step 0  Loss: 0.22821277379989624\n",
      "Step 1  Loss: 0.2951180338859558\n",
      "Step 2  Loss: 0.4152752161026001\n",
      "Step 3  Loss: 0.33446231484413147\n",
      "Step 4  Loss: 0.371561735868454\n",
      "Step 5  Loss: 0.29129719734191895\n",
      "Step 6  Loss: 0.36474063992500305\n",
      "Step 7  Loss: 0.3819497227668762\n",
      "Step 8  Loss: 0.3656396269798279\n",
      "Step 9  Loss: 0.3273617625236511\n",
      "Step 10  Loss: 0.2865816354751587\n",
      "total Loss of epoch  476  is  3.6622006595134735\n",
      "Step 0  Loss: 0.24241597950458527\n",
      "Step 1  Loss: 0.44882428646087646\n",
      "Step 2  Loss: 0.3800399899482727\n",
      "Step 3  Loss: 0.3223627209663391\n",
      "Step 4  Loss: 0.44965609908103943\n",
      "Step 5  Loss: 0.39037224650382996\n",
      "Step 6  Loss: 0.2978394031524658\n",
      "Step 7  Loss: 0.3089158535003662\n",
      "Step 8  Loss: 0.5148966908454895\n",
      "Step 9  Loss: 0.30926236510276794\n",
      "Step 10  Loss: 0.4351898431777954\n",
      "total Loss of epoch  477  is  4.099775478243828\n",
      "Step 0  Loss: 0.33668357133865356\n",
      "Step 1  Loss: 0.38582843542099\n",
      "Step 2  Loss: 0.33370187878608704\n",
      "Step 3  Loss: 0.3174617886543274\n",
      "Step 4  Loss: 0.39167705178260803\n",
      "Step 5  Loss: 0.3664960265159607\n",
      "Step 6  Loss: 0.3702651560306549\n",
      "Step 7  Loss: 0.28470101952552795\n",
      "Step 8  Loss: 0.4955420196056366\n",
      "Step 9  Loss: 0.3690074384212494\n",
      "Step 10  Loss: 0.32119759917259216\n",
      "total Loss of epoch  478  is  3.9725619852542877\n",
      "Step 0  Loss: 0.2280234545469284\n",
      "Step 1  Loss: 0.3229801654815674\n",
      "Step 2  Loss: 0.3406100869178772\n",
      "Step 3  Loss: 0.32388588786125183\n",
      "Step 4  Loss: 0.32999277114868164\n",
      "Step 5  Loss: 0.3637702167034149\n",
      "Step 6  Loss: 0.3029056787490845\n",
      "Step 7  Loss: 0.40660667419433594\n",
      "Step 8  Loss: 0.3335348665714264\n",
      "Step 9  Loss: 0.27779754996299744\n",
      "Step 10  Loss: 0.19266550242900848\n",
      "total Loss of epoch  479  is  3.422772854566574\n",
      "Step 0  Loss: 0.49563711881637573\n",
      "Step 1  Loss: 0.2688222825527191\n",
      "Step 2  Loss: 0.28068864345550537\n",
      "Step 3  Loss: 0.3562282621860504\n",
      "Step 4  Loss: 0.4196295142173767\n",
      "Step 5  Loss: 0.35608771443367004\n",
      "Step 6  Loss: 0.4075869023799896\n",
      "Step 7  Loss: 0.42214030027389526\n",
      "Step 8  Loss: 0.3286797106266022\n",
      "Step 9  Loss: 0.37679120898246765\n",
      "Step 10  Loss: 0.41228538751602173\n",
      "total Loss of epoch  480  is  4.124577045440674\n",
      "Step 0  Loss: 0.3988635540008545\n",
      "Step 1  Loss: 0.27082788944244385\n",
      "Step 2  Loss: 0.3508308231830597\n",
      "Step 3  Loss: 0.4141883850097656\n",
      "Step 4  Loss: 0.45904120802879333\n",
      "Step 5  Loss: 0.3378439247608185\n",
      "Step 6  Loss: 0.4583119750022888\n",
      "Step 7  Loss: 0.3195352256298065\n",
      "Step 8  Loss: 0.30220770835876465\n",
      "Step 9  Loss: 0.3904097378253937\n",
      "Step 10  Loss: 0.4069517254829407\n",
      "total Loss of epoch  481  is  4.10901215672493\n",
      "Step 0  Loss: 0.3061702847480774\n",
      "Step 1  Loss: 0.34798339009284973\n",
      "Step 2  Loss: 0.23971813917160034\n",
      "Step 3  Loss: 0.3218356966972351\n",
      "Step 4  Loss: 0.36652684211730957\n",
      "Step 5  Loss: 0.318170964717865\n",
      "Step 6  Loss: 0.406990110874176\n",
      "Step 7  Loss: 0.41749680042266846\n",
      "Step 8  Loss: 0.36009132862091064\n",
      "Step 9  Loss: 0.30278486013412476\n",
      "Step 10  Loss: 0.3392334282398224\n",
      "total Loss of epoch  482  is  3.7270018458366394\n",
      "Step 0  Loss: 0.38797488808631897\n",
      "Step 1  Loss: 0.3002631366252899\n",
      "Step 2  Loss: 0.2844510078430176\n",
      "Step 3  Loss: 0.4554789364337921\n",
      "Step 4  Loss: 0.30035778880119324\n",
      "Step 5  Loss: 0.352579265832901\n",
      "Step 6  Loss: 0.2952454686164856\n",
      "Step 7  Loss: 0.32556596398353577\n",
      "Step 8  Loss: 0.40368616580963135\n",
      "Step 9  Loss: 0.31843701004981995\n",
      "Step 10  Loss: 0.2947220206260681\n",
      "total Loss of epoch  483  is  3.7187616527080536\n",
      "Step 0  Loss: 0.3804871439933777\n",
      "Step 1  Loss: 0.3284667730331421\n",
      "Step 2  Loss: 0.2660573422908783\n",
      "Step 3  Loss: 0.38829007744789124\n",
      "Step 4  Loss: 0.2579007148742676\n",
      "Step 5  Loss: 0.49190977215766907\n",
      "Step 6  Loss: 0.33477309346199036\n",
      "Step 7  Loss: 0.4203443229198456\n",
      "Step 8  Loss: 0.3238341212272644\n",
      "Step 9  Loss: 0.41235244274139404\n",
      "Step 10  Loss: 0.19123396277427673\n",
      "total Loss of epoch  484  is  3.795649766921997\n",
      "Step 0  Loss: 0.36883267760276794\n",
      "Step 1  Loss: 0.43061843514442444\n",
      "Step 2  Loss: 0.4081920385360718\n",
      "Step 3  Loss: 0.31476062536239624\n",
      "Step 4  Loss: 0.42318013310432434\n",
      "Step 5  Loss: 0.36162248253822327\n",
      "Step 6  Loss: 0.3538527488708496\n",
      "Step 7  Loss: 0.41311630606651306\n",
      "Step 8  Loss: 0.2728654444217682\n",
      "Step 9  Loss: 0.4217558801174164\n",
      "Step 10  Loss: 0.3003084063529968\n",
      "total Loss of epoch  485  is  4.069105178117752\n",
      "Step 0  Loss: 0.37632519006729126\n",
      "Step 1  Loss: 0.2832798659801483\n",
      "Step 2  Loss: 0.3451904058456421\n",
      "Step 3  Loss: 0.32691219449043274\n",
      "Step 4  Loss: 0.3070165812969208\n",
      "Step 5  Loss: 0.33160051703453064\n",
      "Step 6  Loss: 0.25176456570625305\n",
      "Step 7  Loss: 0.29986318945884705\n",
      "Step 8  Loss: 0.42582276463508606\n",
      "Step 9  Loss: 0.3209727108478546\n",
      "Step 10  Loss: 0.41857150197029114\n",
      "total Loss of epoch  486  is  3.6873194873332977\n",
      "Step 0  Loss: 0.2440568059682846\n",
      "Step 1  Loss: 0.42881086468696594\n",
      "Step 2  Loss: 0.25508084893226624\n",
      "Step 3  Loss: 0.33600395917892456\n",
      "Step 4  Loss: 0.35076338052749634\n",
      "Step 5  Loss: 0.36369526386260986\n",
      "Step 6  Loss: 0.2441175878047943\n",
      "Step 7  Loss: 0.399293452501297\n",
      "Step 8  Loss: 0.4214276671409607\n",
      "Step 9  Loss: 0.3947156071662903\n",
      "Step 10  Loss: 0.3264544904232025\n",
      "total Loss of epoch  487  is  3.7644199281930923\n",
      "Step 0  Loss: 0.34073883295059204\n",
      "Step 1  Loss: 0.37186720967292786\n",
      "Step 2  Loss: 0.3864319920539856\n",
      "Step 3  Loss: 0.40027835965156555\n",
      "Step 4  Loss: 0.366830974817276\n",
      "Step 5  Loss: 0.3602515161037445\n",
      "Step 6  Loss: 0.3222416639328003\n",
      "Step 7  Loss: 0.33535078167915344\n",
      "Step 8  Loss: 0.2824643552303314\n",
      "Step 9  Loss: 0.387433797121048\n",
      "Step 10  Loss: 0.2895125448703766\n",
      "total Loss of epoch  488  is  3.8434020280838013\n",
      "Step 0  Loss: 0.2767827808856964\n",
      "Step 1  Loss: 0.40223589539527893\n",
      "Step 2  Loss: 0.3685742914676666\n",
      "Step 3  Loss: 0.3975936770439148\n",
      "Step 4  Loss: 0.32460662722587585\n",
      "Step 5  Loss: 0.36794978380203247\n",
      "Step 6  Loss: 0.4904266595840454\n",
      "Step 7  Loss: 0.2981904447078705\n",
      "Step 8  Loss: 0.3379920721054077\n",
      "Step 9  Loss: 0.3175434172153473\n",
      "Step 10  Loss: 0.39212921261787415\n",
      "total Loss of epoch  489  is  3.97402486205101\n",
      "Step 0  Loss: 0.4381341338157654\n",
      "Step 1  Loss: 0.3050258159637451\n",
      "Step 2  Loss: 0.2505407929420471\n",
      "Step 3  Loss: 0.42372676730155945\n",
      "Step 4  Loss: 0.3208726942539215\n",
      "Step 5  Loss: 0.29411250352859497\n",
      "Step 6  Loss: 0.3735096752643585\n",
      "Step 7  Loss: 0.38070929050445557\n",
      "Step 8  Loss: 0.3713032901287079\n",
      "Step 9  Loss: 0.42237362265586853\n",
      "Step 10  Loss: 0.35561442375183105\n",
      "total Loss of epoch  490  is  3.935923010110855\n",
      "Step 0  Loss: 0.2966018319129944\n",
      "Step 1  Loss: 0.41111499071121216\n",
      "Step 2  Loss: 0.4556313157081604\n",
      "Step 3  Loss: 0.2657085359096527\n",
      "Step 4  Loss: 0.4632315933704376\n",
      "Step 5  Loss: 0.33946871757507324\n",
      "Step 6  Loss: 0.378143846988678\n",
      "Step 7  Loss: 0.3750821352005005\n",
      "Step 8  Loss: 0.19618456065654755\n",
      "Step 9  Loss: 0.3098912835121155\n",
      "Step 10  Loss: 0.36834198236465454\n",
      "total Loss of epoch  491  is  3.8594007939100266\n",
      "Step 0  Loss: 0.35552024841308594\n",
      "Step 1  Loss: 0.3545913100242615\n",
      "Step 2  Loss: 0.4479790925979614\n",
      "Step 3  Loss: 0.45557209849357605\n",
      "Step 4  Loss: 0.33300015330314636\n",
      "Step 5  Loss: 0.3990168869495392\n",
      "Step 6  Loss: 0.3157331943511963\n",
      "Step 7  Loss: 0.3238533139228821\n",
      "Step 8  Loss: 0.48798638582229614\n",
      "Step 9  Loss: 0.3369406759738922\n",
      "Step 10  Loss: 0.4073368310928345\n",
      "total Loss of epoch  492  is  4.217530190944672\n",
      "Step 0  Loss: 0.4291301369667053\n",
      "Step 1  Loss: 0.36572301387786865\n",
      "Step 2  Loss: 0.4139680564403534\n",
      "Step 3  Loss: 0.4460684359073639\n",
      "Step 4  Loss: 0.4253447949886322\n",
      "Step 5  Loss: 0.3694016933441162\n",
      "Step 6  Loss: 0.25401464104652405\n",
      "Step 7  Loss: 0.31678929924964905\n",
      "Step 8  Loss: 0.30520302057266235\n",
      "Step 9  Loss: 0.3207496702671051\n",
      "Step 10  Loss: 0.2945278584957123\n",
      "total Loss of epoch  493  is  3.9409206211566925\n",
      "Step 0  Loss: 0.30142316222190857\n",
      "Step 1  Loss: 0.4084445834159851\n",
      "Step 2  Loss: 0.2339818924665451\n",
      "Step 3  Loss: 0.29599428176879883\n",
      "Step 4  Loss: 0.3607794940471649\n",
      "Step 5  Loss: 0.38369056582450867\n",
      "Step 6  Loss: 0.30751991271972656\n",
      "Step 7  Loss: 0.305225133895874\n",
      "Step 8  Loss: 0.4488317668437958\n",
      "Step 9  Loss: 0.3483666181564331\n",
      "Step 10  Loss: 0.25439831614494324\n",
      "total Loss of epoch  494  is  3.648655727505684\n",
      "Step 0  Loss: 0.44228002429008484\n",
      "Step 1  Loss: 0.28233200311660767\n",
      "Step 2  Loss: 0.4242197573184967\n",
      "Step 3  Loss: 0.47334492206573486\n",
      "Step 4  Loss: 0.4428098201751709\n",
      "Step 5  Loss: 0.2763631045818329\n",
      "Step 6  Loss: 0.23909564316272736\n",
      "Step 7  Loss: 0.39074674248695374\n",
      "Step 8  Loss: 0.2873866558074951\n",
      "Step 9  Loss: 0.27230390906333923\n",
      "Step 10  Loss: 0.19165121018886566\n",
      "total Loss of epoch  495  is  3.722533792257309\n",
      "Step 0  Loss: 0.3608470559120178\n",
      "Step 1  Loss: 0.290666788816452\n",
      "Step 2  Loss: 0.49311473965644836\n",
      "Step 3  Loss: 0.33349844813346863\n",
      "Step 4  Loss: 0.34436216950416565\n",
      "Step 5  Loss: 0.45433616638183594\n",
      "Step 6  Loss: 0.3816543221473694\n",
      "Step 7  Loss: 0.4103776812553406\n",
      "Step 8  Loss: 0.317074179649353\n",
      "Step 9  Loss: 0.3246156573295593\n",
      "Step 10  Loss: 0.3890535235404968\n",
      "total Loss of epoch  496  is  4.099600732326508\n",
      "Step 0  Loss: 0.3829498887062073\n",
      "Step 1  Loss: 0.3389544188976288\n",
      "Step 2  Loss: 0.32963892817497253\n",
      "Step 3  Loss: 0.30095693469047546\n",
      "Step 4  Loss: 0.34495627880096436\n",
      "Step 5  Loss: 0.41304558515548706\n",
      "Step 6  Loss: 0.32504427433013916\n",
      "Step 7  Loss: 0.30239054560661316\n",
      "Step 8  Loss: 0.29710379242897034\n",
      "Step 9  Loss: 0.3174825608730316\n",
      "Step 10  Loss: 0.3509818911552429\n",
      "total Loss of epoch  497  is  3.7035050988197327\n",
      "Step 0  Loss: 0.4172162711620331\n",
      "Step 1  Loss: 0.41208067536354065\n",
      "Step 2  Loss: 0.3000396192073822\n",
      "Step 3  Loss: 0.42545801401138306\n",
      "Step 4  Loss: 0.31415891647338867\n",
      "Step 5  Loss: 0.30106768012046814\n",
      "Step 6  Loss: 0.4005517363548279\n",
      "Step 7  Loss: 0.35803136229515076\n",
      "Step 8  Loss: 0.4216918647289276\n",
      "Step 9  Loss: 0.24722512066364288\n",
      "Step 10  Loss: 0.3114405870437622\n",
      "total Loss of epoch  498  is  3.908961847424507\n",
      "Step 0  Loss: 0.3416084051132202\n",
      "Step 1  Loss: 0.38812726736068726\n",
      "Step 2  Loss: 0.4353608787059784\n",
      "Step 3  Loss: 0.343423992395401\n",
      "Step 4  Loss: 0.2681058943271637\n",
      "Step 5  Loss: 0.3114546835422516\n",
      "Step 6  Loss: 0.39629799127578735\n",
      "Step 7  Loss: 0.3798074424266815\n",
      "Step 8  Loss: 0.35732361674308777\n",
      "Step 9  Loss: 0.33562594652175903\n",
      "Step 10  Loss: 0.41600072383880615\n",
      "total Loss of epoch  499  is  3.973136842250824\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(n_epochs)):\n",
    "    spike_gen_obj = get_batches(real_train_trial_spikes_stand,batch_size)\n",
    "    emg_gen_obj = get_batches(real_train_trial_vel_tide,batch_size)\n",
    "    for ii in range(n_batches):\n",
    "        optimizer.zero_grad()\n",
    "        spike_batch = next(spike_gen_obj)\n",
    "        emg_batch = next(emg_gen_obj)\n",
    "\n",
    "        spike_batch = Variable(torch.from_numpy(spike_batch)).float()\n",
    "        emg_batch = Variable(torch.from_numpy(emg_batch)).float()\n",
    "\n",
    "        # Loss\n",
    "        batch_loss = get_loss(model, spike_batch, emg_batch)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_total_loss = get_loss(model, spike_val, emg_val)\n",
    "        loss_list.append(val_total_loss.item())\n",
    "\n",
    "        _, _, train_latents, _ = model(spike_train, train_flag = False)\n",
    "\n",
    "        if val_total_loss < pre_total_loss_: \n",
    "            pre_total_loss_ = val_total_loss\n",
    "            torch.save(model.state_dict(),'model_checkpoints/source_vae_model_new')\n",
    "\n",
    "\n",
    "            np.save(\"./npy_files/train_latents_new.npy\",train_latents)\n",
    "\n",
    "        \n",
    "    train_latents = np.expand_dims(train_latents,1).astype(np.float32)\n",
    "    train_spike_data = train_latents.transpose(0,1,3,2)\n",
    "\n",
    "\n",
    "    dataloader = DataLoader(train_spike_data, batch_size=global_batch_size)\n",
    "\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        dm_optimizer.zero_grad()\n",
    "\n",
    "        batch_size = batch.shape[0]\n",
    "        batch = batch.to(device)\n",
    "\n",
    "\n",
    "        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "        loss = p_losses(dm_model, batch, t)\n",
    "\n",
    "        print(\"Step\", step, \" Loss:\", loss.item())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        dm_optimizer.step()\n",
    "\n",
    "    print(\"total Loss of epoch \", epoch, \" is \", total_loss)\n",
    "\n",
    "    if total_loss < pre_loss:\n",
    "        pre_loss = total_loss\n",
    "        torch.save(dm_model.state_dict(), 'model_checkpoints/source_diffusion_model_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
